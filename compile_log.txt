Command Line Args: Namespace(config_file='configs/cityscapes/panoptic-segmentation/maskformer2_R50_bs16_90k.yaml', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50164', opts=[], cuda=False, compile=True, device=None, sample_factor=1.0, trt_path='model.onnx', trt_res_path='output/predictions_trt.png', res_path='output/predictions_cuda.png')
Command Line Args: Namespace(config_file='configs/cityscapes/panoptic-segmentation/maskformer2_R50_bs16_90k.yaml', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50164', opts=[], cuda=False, compile=True, device=None, sample_factor=1.0, trt_path='model.onnx', trt_res_path='output/predictions_trt.png', res_path='output/predictions_cuda.png')
[05/19 13:47:29 detectron2]: Rank of current process: 0. World size: 1
[05/19 13:47:30 detectron2]: Environment info:
-------------------------------  ------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]
numpy                            2.1.2
detectron2                       0.6 @/home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2
Compiler                         GCC 14.2
CUDA compiler                    CUDA 12.6
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA RTX A6000 (arch=8.6)
GPU 1,2                          NVIDIA RTX A5000 (arch=8.6)
Driver version                   570.133.07
CUDA_HOME                        /opt/cuda
Pillow                           11.0.0
torchvision                      0.20.1+cu121 @/home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  ------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[05/19 13:47:30 detectron2]: Command line arguments: Namespace(config_file='configs/cityscapes/panoptic-segmentation/maskformer2_R50_bs16_90k.yaml', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50164', opts=[], cuda=False, compile=True, device=None, sample_factor=1.0, trt_path='model.onnx', trt_res_path='output/predictions_trt.png', res_path='output/predictions_cuda.png')
[05/19 13:47:30 detectron2]: Contents of args.config_file=configs/cityscapes/panoptic-segmentation/maskformer2_R50_bs16_90k.yaml:
[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-Cityscapes-PanopticSegmentation.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormer[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m19[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;245m# pixel decoder[39m
[38;5;15m    [39m[38;5;204mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;204mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;204mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;204mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;204mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;245m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;204mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;204mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;204mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;204mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;204mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;204mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[05/19 13:47:30 detectron2]: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mREPEAT_SQRT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcityscapes_fine_panoptic_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcityscapes_fine_panoptic_train[39m
[38;5;204mFLOAT32_PRECISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;204mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_panoptic[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;204mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;204mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;204mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;204mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;204mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;204mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;204mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;204mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;204mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;204mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;204mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m19[39m
[38;5;15m    [39m[38;5;204mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;204mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;204mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;204mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;204mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;204mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;204mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;204mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;204mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;204mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;204mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./output[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[05/19 13:47:30 detectron2]: Full config saved to ./output/config.yaml
[05/19 13:47:30 d2.utils.env]: Using a generated random seed 33758337
[05/19 13:47:30 d2.data.datasets.cityscapes]: 3 cities found in 'datasets/cityscapes/leftImg8bit/val/'.
[05/19 13:47:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[05/19 13:47:31 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[05/19 13:47:31 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[05/19 13:47:31 d2.data.common]: Serialized dataset takes 0.12 MiB
[05/19 13:47:31 d2.engine.defaults]: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0-8): 9 x SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0-8): 9 x CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0-8): 9 x FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0-2): 3 x Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=20, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 19
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[05/19 13:47:31 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from output/model_final.pth ...
[05/19 13:47:31 fvcore.common.checkpoint]: [Checkpointer] Loading from output/model_final.pth ...
Exported graph: graph(%input : Float(3, 1024, 2048, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.input_proj.0.0.weight : Float(256, 2048, 1, 1, strides=[2048, 1, 1, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.input_proj.0.0.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.input_proj.1.0.weight : Float(256, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.input_proj.1.0.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.input_proj.2.0.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.input_proj.2.0.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.mask_features.weight : Float(256, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.mask_features.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.adapter_1.weight : Float(256, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.pixel_decoder.layer_1.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.0.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.0.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.1.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.1.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.2.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.2.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.3.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.3.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.4.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.4.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.5.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.5.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.6.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.6.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.7.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.7.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.8.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_self_attention_layers.8.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.0.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.0.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.0.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.0.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.1.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.1.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.1.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.1.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.2.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.2.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.2.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.2.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.3.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.3.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.3.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.3.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.4.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.4.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.4.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.4.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.5.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.5.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.5.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.5.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.6.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.6.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.6.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.6.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.7.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.7.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.7.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.7.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.8.linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.8.linear2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.8.norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.transformer_ffn_layers.8.norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.decoder_norm.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.decoder_norm.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.class_embed.bias : Float(20, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.mask_embed.layers.0.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.mask_embed.layers.1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %model.sem_seg_head.predictor.mask_embed.layers.2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %onnx::Conv_6752 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6753 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6755 : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6756 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6758 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6759 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6761 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6762 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6764 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6765 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6767 : Float(64, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6768 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6770 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6771 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6773 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6774 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6776 : Float(64, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6777 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6779 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6780 : Float(64, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6782 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6783 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6785 : Float(128, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6786 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6788 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6789 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6791 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6792 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6794 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6795 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6797 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6798 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6800 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6801 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6803 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6804 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6806 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6807 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6809 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6810 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6812 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6813 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6815 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6816 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6818 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6819 : Float(128, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6821 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6822 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6824 : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6825 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6827 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6828 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6830 : Float(1024, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6831 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6833 : Float(1024, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6834 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6836 : Float(256, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6837 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6839 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6840 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6842 : Float(1024, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6843 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6845 : Float(256, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6846 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6848 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6849 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6851 : Float(1024, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6852 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6854 : Float(256, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6855 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6857 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6858 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6860 : Float(1024, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6861 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6863 : Float(256, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6864 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6866 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6867 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6869 : Float(1024, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6870 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6872 : Float(256, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6873 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6875 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6876 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6878 : Float(1024, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6879 : Float(1024, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6881 : Float(512, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6882 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6884 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6885 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6887 : Float(2048, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6888 : Float(2048, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6890 : Float(2048, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6891 : Float(2048, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6893 : Float(512, 2048, 1, 1, strides=[2048, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6894 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6896 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6897 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6899 : Float(2048, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6900 : Float(2048, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6902 : Float(512, 2048, 1, 1, strides=[2048, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6903 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6905 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6906 : Float(512, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6908 : Float(2048, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Conv_6909 : Float(2048, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Mul_6916 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_6917 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Mul_6942 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_6943 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Mul_6968 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_6969 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_6995 : Float(1, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_6997 : Float(1, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_6999 : Float(1, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7000 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7003 : Float(256, 192, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7008 : Float(256, 96, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7024 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7025 : Float(256, 1024, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7026 : Float(1024, 256, strides=[1, 1024], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7027 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7030 : Float(256, 192, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7035 : Float(256, 96, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7051 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7052 : Float(256, 1024, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7053 : Float(1024, 256, strides=[1, 1024], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7054 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7057 : Float(256, 192, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7062 : Float(256, 96, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7078 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7079 : Float(256, 1024, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7080 : Float(1024, 256, strides=[1, 1024], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7081 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7084 : Float(256, 192, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7089 : Float(256, 96, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7105 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7106 : Float(256, 1024, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7107 : Float(1024, 256, strides=[1, 1024], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7108 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7111 : Float(256, 192, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7116 : Float(256, 96, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7132 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7133 : Float(256, 1024, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7134 : Float(1024, 256, strides=[1, 1024], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7135 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7138 : Float(256, 192, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7143 : Float(256, 96, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7159 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7160 : Float(256, 1024, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7161 : Float(1024, 256, strides=[1, 1024], requires_grad=0, device=cuda:0),
      %onnx::Mul_7172 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_7173 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Mul_7174 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_7175 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_7202 : Float(1, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_7229 : Float(1, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Add_7256 : Float(1, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cuda:0),
      %onnx::Expand_7257 : Float(100, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0),
      %onnx::Expand_7266 : Float(100, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7267 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7268 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7269 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7286 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7288 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7290 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7291 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7292 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7293 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7311 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7313 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7315 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7316 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7317 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7318 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7319 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7320 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7340 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7342 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7344 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7345 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7346 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7347 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7365 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7367 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7369 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7370 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7371 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7372 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7373 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7374 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7394 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7396 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7398 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7399 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7400 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7401 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7419 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7421 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7423 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7424 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7425 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7426 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7427 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7428 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7448 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7450 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7452 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7453 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7454 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7455 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7473 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7475 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7477 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7478 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7479 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7480 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7481 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7482 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7502 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7504 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7506 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7507 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7508 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7509 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7527 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7529 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7531 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7532 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7533 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7534 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7535 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7536 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7556 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7558 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7560 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7561 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7562 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7563 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7581 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7583 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7585 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7586 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7587 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7588 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7589 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7590 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7610 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7612 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7614 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7615 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7616 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7617 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7635 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7637 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7639 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7640 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7641 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7642 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7643 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7644 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7664 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7666 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7668 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7669 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7670 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7671 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7689 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7691 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7693 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7694 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7695 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7696 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7697 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7698 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::Add_7718 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7720 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7722 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7723 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7724 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7725 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::Add_7743 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7745 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::Add_7747 : Float(256, strides=[1], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7748 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7749 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7750 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7751 : Float(256, 2048, strides=[1, 256], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7752 : Float(2048, 256, strides=[1, 2048], requires_grad=0, device=cuda:0),
      %onnx::MatMul_7753 : Float(256, 20, strides=[1, 256], requires_grad=0, device=cuda:0)):
  %onnx::MatMul_7756 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7755 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7754 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7701 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7700 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7699 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7647 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7646 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7645 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7593 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7592 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7591 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7539 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7538 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7537 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7485 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7484 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7483 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7431 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7430 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7429 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7377 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7376 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7375 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %onnx::MatMul_7323 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7269)
  %onnx::MatMul_7322 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7268)
  %onnx::MatMul_7321 : Float(256, 256, strides=[1, 256], requires_grad=0, device=cuda:0) = onnx::Identity(%onnx::MatMul_7267)
  %/model/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Cast_output_0 : Float(3, 1024, 2048, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/Cast"](%input), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:195:0
  %/model/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_2_output_0 : Float(3, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,.,.) =    123.6750  (2,.,.) =    116.2800  (3,.,.) =    103.5300 [ CUDAFloatType{3,1,1} ], onnx_name="/model/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:196:0
  %/model/Sub_output_0 : Float(3, 1024, 2048, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/Sub"](%/model/Cast_output_0, %/model/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:196:0
  %/model/Constant_3_output_0 : Float(3, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,.,.) =    58.3950  (2,.,.) =    57.1200  (3,.,.) =    57.3750 [ CUDAFloatType{3,1,1} ], onnx_name="/model/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:196:0
  %/model/Div_output_0 : Float(3, 1024, 2048, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/Div"](%/model/Sub_output_0, %/model/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:196:0
  %/model/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_5_output_0 : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 1024  2048 [ CPULongType{1,2} ], onnx_name="/model/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:89:0
  %/model/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:89:0
  %/model/ReduceMax_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::ReduceMax[keepdims=0, onnx_name="/model/ReduceMax"](%/model/Constant_5_output_0, %/model/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:89:0
  %/model/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={31}, onnx_name="/model/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Add_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/model/Add"](%/model/ReduceMax_output_0, %/model/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Div_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Div[onnx_name="/model/Div_1"](%/model/Add_output_0, %/model/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Less_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Less[onnx_name="/model/Less"](%/model/Add_output_0, %/model/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_10_output_0 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Xor_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Xor[onnx_name="/model/Xor"](%/model/Less_output_0, %/model/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Mod_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mod[fmod=0, onnx_name="/model/Mod"](%/model/Add_output_0, %/model/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Equal_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/model/Equal"](%/model/Mod_output_0, %/model/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Not_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Not[onnx_name="/model/Not"](%/model/Equal_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/And_output_0 : Bool(2, strides=[1], device=cpu) = onnx::And[onnx_name="/model/And"](%/model/Xor_output_0, %/model/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Sub_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Sub[onnx_name="/model/Sub_1"](%/model/Div_1_output_0, %/model/Constant_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Where_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/model/Where"](%/model/And_output_0, %/model/Sub_1_output_0, %/model/Div_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_14_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Mul_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/Mul"](%/model/Where_output_0, %/model/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:101:0
  %/model/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Gather_output_0 : Long(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather"](%/model/Mul_output_0, %/model/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:114:0
  %/model/Constant_16_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2048}, onnx_name="/model/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:114:0
  %/model/Sub_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/model/Sub_2"](%/model/Gather_output_0, %/model/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:114:0
  %/model/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={-2}, onnx_name="/model/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Gather_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather_1"](%/model/Mul_output_0, %/model/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:114:0
  %/model/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1024}, onnx_name="/model/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:114:0
  %/model/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/model/Sub_3"](%/model/Gather_1_output_0, %/model/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:114:0
  %/model/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %onnx::Unsqueeze_656 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze"](%/model/Sub_2_output_0, %onnx::Unsqueeze_656), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %onnx::Unsqueeze_660 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_1"](%/model/Sub_3_output_0, %onnx::Unsqueeze_660), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat"](%/model/Constant_19_output_0, %/model/Unsqueeze_output_0, %/model/Constant_20_output_0, %/model/Unsqueeze_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %onnx::Unsqueeze_665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_2"](%/model/Sub_2_output_0, %onnx::Unsqueeze_665), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %onnx::Unsqueeze_669 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_3"](%/model/Sub_3_output_0, %onnx::Unsqueeze_669), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat_1"](%/model/Constant_21_output_0, %/model/Unsqueeze_2_output_0, %/model/Constant_22_output_0, %/model/Unsqueeze_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Shape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape"](%/model/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Gather_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather_2"](%/model/Shape_output_0, %/model/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/model/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/model/Sub_4"](%/model/Constant_24_output_0, %/model/Gather_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Cast_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/Cast_1"](%/model/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/model/ConstantOfShape"](%/model/Sub_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Concat_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat_2"](%/model/Cast_1_output_0, %/model/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/model/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/Reshape"](%/model/Concat_2_output_0, %/model/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/model/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/model/Slice"](%/model/Reshape_output_0, %/model/Constant_27_output_0, %/model/Constant_28_output_0, %/model/Constant_26_output_0, %/model/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/model/Transpose"](%/model/Slice_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/Reshape_1"](%/model/Transpose_output_0, %/model/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Cast_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/Cast_2"](%/model/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_31_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Pad_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Pad[mode="constant", onnx_name="/model/Pad"](%/model/Div_output_0, %/model/Cast_2_output_0, %/model/Constant_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5096:0
  %/model/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:115:0
  %/model/Unsqueeze_4_output_0 : Float(1, *, *, *, strides=[6291456, 2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_4"](%/model/Pad_output_0, %/model/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/structures/image_list.py:115:0
  %/model/backbone/stem/conv1/Conv_output_0 : Float(1, 64, *, *, strides=[33554432, 524288, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2], onnx_name="/model/backbone/stem/conv1/Conv"](%/model/Unsqueeze_4_output_0, %onnx::Conv_6752, %onnx::Conv_6753), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/detectron2.modeling.backbone.resnet.BasicStem::stem/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/stem/Relu_output_0 : Float(1, 64, *, *, strides=[33554432, 524288, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/stem/Relu"](%/model/backbone/stem/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/detectron2.modeling.backbone.resnet.BasicStem::stem # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:357:0
  %/model/backbone/stem/MaxPool_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name="/model/backbone/stem/MaxPool"](%/model/backbone/stem/Relu_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/detectron2.modeling.backbone.resnet.BasicStem::stem # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:830:0
  %/model/backbone/res2/res2.0/conv1/Conv_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.0/conv1/Conv"](%/model/backbone/stem/MaxPool_output_0, %onnx::Conv_6755, %onnx::Conv_6756), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.0/Relu_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.0/Relu"](%/model/backbone/res2/res2.0/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res2/res2.0/conv2/Conv_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res2/res2.0/conv2/Conv"](%/model/backbone/res2/res2.0/Relu_output_0, %onnx::Conv_6758, %onnx::Conv_6759), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.0/Relu_1_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.0/Relu_1"](%/model/backbone/res2/res2.0/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res2/res2.0/conv3/Conv_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.0/conv3/Conv"](%/model/backbone/res2/res2.0/Relu_1_output_0, %onnx::Conv_6761, %onnx::Conv_6762), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.0/shortcut/Conv_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.0/shortcut/Conv"](%/model/backbone/stem/MaxPool_output_0, %onnx::Conv_6764, %onnx::Conv_6765), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0/detectron2.layers.wrappers.Conv2d::shortcut # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.0/Add_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res2/res2.0/Add"](%/model/backbone/res2/res2.0/conv3/Conv_output_0, %/model/backbone/res2/res2.0/shortcut/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res2/res2.0/Relu_2_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.0/Relu_2"](%/model/backbone/res2/res2.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res2/res2.1/conv1/Conv_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.1/conv1/Conv"](%/model/backbone/res2/res2.0/Relu_2_output_0, %onnx::Conv_6767, %onnx::Conv_6768), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.1/Relu_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.1/Relu"](%/model/backbone/res2/res2.1/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res2/res2.1/conv2/Conv_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res2/res2.1/conv2/Conv"](%/model/backbone/res2/res2.1/Relu_output_0, %onnx::Conv_6770, %onnx::Conv_6771), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.1/Relu_1_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.1/Relu_1"](%/model/backbone/res2/res2.1/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res2/res2.1/conv3/Conv_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.1/conv3/Conv"](%/model/backbone/res2/res2.1/Relu_1_output_0, %onnx::Conv_6773, %onnx::Conv_6774), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.1/Add_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res2/res2.1/Add"](%/model/backbone/res2/res2.1/conv3/Conv_output_0, %/model/backbone/res2/res2.0/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res2/res2.1/Relu_2_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.1/Relu_2"](%/model/backbone/res2/res2.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res2/res2.2/conv1/Conv_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.2/conv1/Conv"](%/model/backbone/res2/res2.1/Relu_2_output_0, %onnx::Conv_6776, %onnx::Conv_6777), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.2/Relu_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.2/Relu"](%/model/backbone/res2/res2.2/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res2/res2.2/conv2/Conv_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res2/res2.2/conv2/Conv"](%/model/backbone/res2/res2.2/Relu_output_0, %onnx::Conv_6779, %onnx::Conv_6780), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.2/Relu_1_output_0 : Float(1, 64, *, *, strides=[8388608, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.2/Relu_1"](%/model/backbone/res2/res2.2/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res2/res2.2/conv3/Conv_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res2/res2.2/conv3/Conv"](%/model/backbone/res2/res2.2/Relu_1_output_0, %onnx::Conv_6782, %onnx::Conv_6783), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res2/res2.2/Add_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res2/res2.2/Add"](%/model/backbone/res2/res2.2/conv3/Conv_output_0, %/model/backbone/res2/res2.1/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res2/res2.2/Relu_2_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res2/res2.2/Relu_2"](%/model/backbone/res2/res2.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res2/detectron2.modeling.backbone.resnet.BottleneckBlock::res2.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res3/res3.0/conv1/Conv_output_0 : Float(1, 128, *, *, strides=[16777216, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.0/conv1/Conv"](%/model/backbone/res2/res2.2/Relu_2_output_0, %onnx::Conv_6785, %onnx::Conv_6786), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.0/Relu_output_0 : Float(1, 128, *, *, strides=[16777216, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.0/Relu"](%/model/backbone/res3/res3.0/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res3/res3.0/conv2/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name="/model/backbone/res3/res3.0/conv2/Conv"](%/model/backbone/res3/res3.0/Relu_output_0, %onnx::Conv_6788, %onnx::Conv_6789), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.0/Relu_1_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.0/Relu_1"](%/model/backbone/res3/res3.0/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res3/res3.0/conv3/Conv_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.0/conv3/Conv"](%/model/backbone/res3/res3.0/Relu_1_output_0, %onnx::Conv_6791, %onnx::Conv_6792), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.0/shortcut/Conv_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name="/model/backbone/res3/res3.0/shortcut/Conv"](%/model/backbone/res2/res2.2/Relu_2_output_0, %onnx::Conv_6794, %onnx::Conv_6795), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0/detectron2.layers.wrappers.Conv2d::shortcut # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.0/Add_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res3/res3.0/Add"](%/model/backbone/res3/res3.0/conv3/Conv_output_0, %/model/backbone/res3/res3.0/shortcut/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res3/res3.0/Relu_2_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.0/Relu_2"](%/model/backbone/res3/res3.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res3/res3.1/conv1/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.1/conv1/Conv"](%/model/backbone/res3/res3.0/Relu_2_output_0, %onnx::Conv_6797, %onnx::Conv_6798), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.1/Relu_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.1/Relu"](%/model/backbone/res3/res3.1/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res3/res3.1/conv2/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res3/res3.1/conv2/Conv"](%/model/backbone/res3/res3.1/Relu_output_0, %onnx::Conv_6800, %onnx::Conv_6801), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.1/Relu_1_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.1/Relu_1"](%/model/backbone/res3/res3.1/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res3/res3.1/conv3/Conv_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.1/conv3/Conv"](%/model/backbone/res3/res3.1/Relu_1_output_0, %onnx::Conv_6803, %onnx::Conv_6804), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.1/Add_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res3/res3.1/Add"](%/model/backbone/res3/res3.1/conv3/Conv_output_0, %/model/backbone/res3/res3.0/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res3/res3.1/Relu_2_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.1/Relu_2"](%/model/backbone/res3/res3.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res3/res3.2/conv1/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.2/conv1/Conv"](%/model/backbone/res3/res3.1/Relu_2_output_0, %onnx::Conv_6806, %onnx::Conv_6807), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.2/Relu_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.2/Relu"](%/model/backbone/res3/res3.2/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res3/res3.2/conv2/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res3/res3.2/conv2/Conv"](%/model/backbone/res3/res3.2/Relu_output_0, %onnx::Conv_6809, %onnx::Conv_6810), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.2/Relu_1_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.2/Relu_1"](%/model/backbone/res3/res3.2/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res3/res3.2/conv3/Conv_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.2/conv3/Conv"](%/model/backbone/res3/res3.2/Relu_1_output_0, %onnx::Conv_6812, %onnx::Conv_6813), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.2/Add_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res3/res3.2/Add"](%/model/backbone/res3/res3.2/conv3/Conv_output_0, %/model/backbone/res3/res3.1/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res3/res3.2/Relu_2_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.2/Relu_2"](%/model/backbone/res3/res3.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res3/res3.3/conv1/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.3/conv1/Conv"](%/model/backbone/res3/res3.2/Relu_2_output_0, %onnx::Conv_6815, %onnx::Conv_6816), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.3/Relu_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.3/Relu"](%/model/backbone/res3/res3.3/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res3/res3.3/conv2/Conv_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res3/res3.3/conv2/Conv"](%/model/backbone/res3/res3.3/Relu_output_0, %onnx::Conv_6818, %onnx::Conv_6819), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.3/Relu_1_output_0 : Float(1, 128, *, *, strides=[4194304, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.3/Relu_1"](%/model/backbone/res3/res3.3/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res3/res3.3/conv3/Conv_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res3/res3.3/conv3/Conv"](%/model/backbone/res3/res3.3/Relu_1_output_0, %onnx::Conv_6821, %onnx::Conv_6822), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res3/res3.3/Add_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res3/res3.3/Add"](%/model/backbone/res3/res3.3/conv3/Conv_output_0, %/model/backbone/res3/res3.2/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res3/res3.3/Relu_2_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res3/res3.3/Relu_2"](%/model/backbone/res3/res3.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res3/detectron2.modeling.backbone.resnet.BottleneckBlock::res3.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res4/res4.0/conv1/Conv_output_0 : Float(1, 256, *, *, strides=[8388608, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.0/conv1/Conv"](%/model/backbone/res3/res3.3/Relu_2_output_0, %onnx::Conv_6824, %onnx::Conv_6825), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.0/Relu_output_0 : Float(1, 256, *, *, strides=[8388608, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.0/Relu"](%/model/backbone/res4/res4.0/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res4/res4.0/conv2/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name="/model/backbone/res4/res4.0/conv2/Conv"](%/model/backbone/res4/res4.0/Relu_output_0, %onnx::Conv_6827, %onnx::Conv_6828), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.0/Relu_1_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.0/Relu_1"](%/model/backbone/res4/res4.0/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res4/res4.0/conv3/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.0/conv3/Conv"](%/model/backbone/res4/res4.0/Relu_1_output_0, %onnx::Conv_6830, %onnx::Conv_6831), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.0/shortcut/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name="/model/backbone/res4/res4.0/shortcut/Conv"](%/model/backbone/res3/res3.3/Relu_2_output_0, %onnx::Conv_6833, %onnx::Conv_6834), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0/detectron2.layers.wrappers.Conv2d::shortcut # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.0/Add_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res4/res4.0/Add"](%/model/backbone/res4/res4.0/conv3/Conv_output_0, %/model/backbone/res4/res4.0/shortcut/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res4/res4.0/Relu_2_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.0/Relu_2"](%/model/backbone/res4/res4.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res4/res4.1/conv1/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.1/conv1/Conv"](%/model/backbone/res4/res4.0/Relu_2_output_0, %onnx::Conv_6836, %onnx::Conv_6837), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.1/Relu_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.1/Relu"](%/model/backbone/res4/res4.1/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res4/res4.1/conv2/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res4/res4.1/conv2/Conv"](%/model/backbone/res4/res4.1/Relu_output_0, %onnx::Conv_6839, %onnx::Conv_6840), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.1/Relu_1_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.1/Relu_1"](%/model/backbone/res4/res4.1/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res4/res4.1/conv3/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.1/conv3/Conv"](%/model/backbone/res4/res4.1/Relu_1_output_0, %onnx::Conv_6842, %onnx::Conv_6843), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.1/Add_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res4/res4.1/Add"](%/model/backbone/res4/res4.1/conv3/Conv_output_0, %/model/backbone/res4/res4.0/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res4/res4.1/Relu_2_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.1/Relu_2"](%/model/backbone/res4/res4.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res4/res4.2/conv1/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.2/conv1/Conv"](%/model/backbone/res4/res4.1/Relu_2_output_0, %onnx::Conv_6845, %onnx::Conv_6846), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.2/Relu_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.2/Relu"](%/model/backbone/res4/res4.2/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res4/res4.2/conv2/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res4/res4.2/conv2/Conv"](%/model/backbone/res4/res4.2/Relu_output_0, %onnx::Conv_6848, %onnx::Conv_6849), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.2/Relu_1_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.2/Relu_1"](%/model/backbone/res4/res4.2/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res4/res4.2/conv3/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.2/conv3/Conv"](%/model/backbone/res4/res4.2/Relu_1_output_0, %onnx::Conv_6851, %onnx::Conv_6852), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.2/Add_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res4/res4.2/Add"](%/model/backbone/res4/res4.2/conv3/Conv_output_0, %/model/backbone/res4/res4.1/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res4/res4.2/Relu_2_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.2/Relu_2"](%/model/backbone/res4/res4.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res4/res4.3/conv1/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.3/conv1/Conv"](%/model/backbone/res4/res4.2/Relu_2_output_0, %onnx::Conv_6854, %onnx::Conv_6855), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.3/Relu_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.3/Relu"](%/model/backbone/res4/res4.3/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res4/res4.3/conv2/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res4/res4.3/conv2/Conv"](%/model/backbone/res4/res4.3/Relu_output_0, %onnx::Conv_6857, %onnx::Conv_6858), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.3/Relu_1_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.3/Relu_1"](%/model/backbone/res4/res4.3/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res4/res4.3/conv3/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.3/conv3/Conv"](%/model/backbone/res4/res4.3/Relu_1_output_0, %onnx::Conv_6860, %onnx::Conv_6861), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.3/Add_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res4/res4.3/Add"](%/model/backbone/res4/res4.3/conv3/Conv_output_0, %/model/backbone/res4/res4.2/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res4/res4.3/Relu_2_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.3/Relu_2"](%/model/backbone/res4/res4.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res4/res4.4/conv1/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.4/conv1/Conv"](%/model/backbone/res4/res4.3/Relu_2_output_0, %onnx::Conv_6863, %onnx::Conv_6864), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.4/Relu_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.4/Relu"](%/model/backbone/res4/res4.4/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res4/res4.4/conv2/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res4/res4.4/conv2/Conv"](%/model/backbone/res4/res4.4/Relu_output_0, %onnx::Conv_6866, %onnx::Conv_6867), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.4/Relu_1_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.4/Relu_1"](%/model/backbone/res4/res4.4/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res4/res4.4/conv3/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.4/conv3/Conv"](%/model/backbone/res4/res4.4/Relu_1_output_0, %onnx::Conv_6869, %onnx::Conv_6870), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.4/Add_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res4/res4.4/Add"](%/model/backbone/res4/res4.4/conv3/Conv_output_0, %/model/backbone/res4/res4.3/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res4/res4.4/Relu_2_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.4/Relu_2"](%/model/backbone/res4/res4.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.4 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res4/res4.5/conv1/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.5/conv1/Conv"](%/model/backbone/res4/res4.4/Relu_2_output_0, %onnx::Conv_6872, %onnx::Conv_6873), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.5/Relu_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.5/Relu"](%/model/backbone/res4/res4.5/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res4/res4.5/conv2/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res4/res4.5/conv2/Conv"](%/model/backbone/res4/res4.5/Relu_output_0, %onnx::Conv_6875, %onnx::Conv_6876), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.5/Relu_1_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.5/Relu_1"](%/model/backbone/res4/res4.5/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res4/res4.5/conv3/Conv_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res4/res4.5/conv3/Conv"](%/model/backbone/res4/res4.5/Relu_1_output_0, %onnx::Conv_6878, %onnx::Conv_6879), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res4/res4.5/Add_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res4/res4.5/Add"](%/model/backbone/res4/res4.5/conv3/Conv_output_0, %/model/backbone/res4/res4.4/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res4/res4.5/Relu_2_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res4/res4.5/Relu_2"](%/model/backbone/res4/res4.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res4/detectron2.modeling.backbone.resnet.BottleneckBlock::res4.5 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res5/res5.0/conv1/Conv_output_0 : Float(1, 512, *, *, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res5/res5.0/conv1/Conv"](%/model/backbone/res4/res4.5/Relu_2_output_0, %onnx::Conv_6881, %onnx::Conv_6882), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.0/Relu_output_0 : Float(1, 512, *, *, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.0/Relu"](%/model/backbone/res5/res5.0/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res5/res5.0/conv2/Conv_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name="/model/backbone/res5/res5.0/conv2/Conv"](%/model/backbone/res5/res5.0/Relu_output_0, %onnx::Conv_6884, %onnx::Conv_6885), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.0/Relu_1_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.0/Relu_1"](%/model/backbone/res5/res5.0/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res5/res5.0/conv3/Conv_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res5/res5.0/conv3/Conv"](%/model/backbone/res5/res5.0/Relu_1_output_0, %onnx::Conv_6887, %onnx::Conv_6888), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.0/shortcut/Conv_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name="/model/backbone/res5/res5.0/shortcut/Conv"](%/model/backbone/res4/res4.5/Relu_2_output_0, %onnx::Conv_6890, %onnx::Conv_6891), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0/detectron2.layers.wrappers.Conv2d::shortcut # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.0/Add_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res5/res5.0/Add"](%/model/backbone/res5/res5.0/conv3/Conv_output_0, %/model/backbone/res5/res5.0/shortcut/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res5/res5.0/Relu_2_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.0/Relu_2"](%/model/backbone/res5/res5.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res5/res5.1/conv1/Conv_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res5/res5.1/conv1/Conv"](%/model/backbone/res5/res5.0/Relu_2_output_0, %onnx::Conv_6893, %onnx::Conv_6894), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.1/Relu_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.1/Relu"](%/model/backbone/res5/res5.1/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res5/res5.1/conv2/Conv_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res5/res5.1/conv2/Conv"](%/model/backbone/res5/res5.1/Relu_output_0, %onnx::Conv_6896, %onnx::Conv_6897), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.1/Relu_1_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.1/Relu_1"](%/model/backbone/res5/res5.1/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res5/res5.1/conv3/Conv_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res5/res5.1/conv3/Conv"](%/model/backbone/res5/res5.1/Relu_1_output_0, %onnx::Conv_6899, %onnx::Conv_6900), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.1/Add_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res5/res5.1/Add"](%/model/backbone/res5/res5.1/conv3/Conv_output_0, %/model/backbone/res5/res5.0/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res5/res5.1/Relu_2_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.1/Relu_2"](%/model/backbone/res5/res5.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/backbone/res5/res5.2/conv1/Conv_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res5/res5.2/conv1/Conv"](%/model/backbone/res5/res5.1/Relu_2_output_0, %onnx::Conv_6902, %onnx::Conv_6903), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2/detectron2.layers.wrappers.Conv2d::conv1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.2/Relu_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.2/Relu"](%/model/backbone/res5/res5.2/conv1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:196:0
  %/model/backbone/res5/res5.2/conv2/Conv_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/backbone/res5/res5.2/conv2/Conv"](%/model/backbone/res5/res5.2/Relu_output_0, %onnx::Conv_6905, %onnx::Conv_6906), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2/detectron2.layers.wrappers.Conv2d::conv2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.2/Relu_1_output_0 : Float(1, 512, *, *, strides=[1048576, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.2/Relu_1"](%/model/backbone/res5/res5.2/conv2/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:199:0
  %/model/backbone/res5/res5.2/conv3/Conv_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/backbone/res5/res5.2/conv3/Conv"](%/model/backbone/res5/res5.2/Relu_1_output_0, %onnx::Conv_6908, %onnx::Conv_6909), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2/detectron2.layers.wrappers.Conv2d::conv3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/backbone/res5/res5.2/Add_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/backbone/res5/res5.2/Add"](%/model/backbone/res5/res5.2/conv3/Conv_output_0, %/model/backbone/res5/res5.1/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:208:0
  %/model/backbone/res5/res5.2/Relu_2_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/backbone/res5/res5.2/Relu_2"](%/model/backbone/res5/res5.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/detectron2.modeling.backbone.resnet.ResNet::backbone/torch.nn.modules.container.Sequential::res5/detectron2.modeling.backbone.resnet.BottleneckBlock::res5.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/backbone/resnet.py:209:0
  %/model/sem_seg_head/Cast_output_0 : Float(1, 2048, *, *, strides=[4194304, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/Cast"](%/model/backbone/res5/res5.2/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:325:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.0/Conv_output_0 : Float(1, 256, *, *, strides=[524288, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.0/Conv"](%/model/sem_seg_head/Cast_output_0, %model.sem_seg_head.pixel_decoder.input_proj.0.0.weight, %model.sem_seg_head.pixel_decoder.input_proj.0.0.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.conv.Conv2d::input_proj.0.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=  0  32  -1 [ CPULongType{3} ], onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Reshape_output_0 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Reshape"](%/model/sem_seg_head/input_proj.0/input_proj.0.0/Conv_output_0, %/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_1_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_2_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/InstanceNormalization_output_0 : Float(*, *, *, device=cpu) = onnx::InstanceNormalization[epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/InstanceNormalization"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Reshape_output_0, %/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_1_output_0, %/model/sem_seg_head/input_proj.0/input_proj.0.1/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Shape"](%/model/sem_seg_head/input_proj.0/input_proj.0.0/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Reshape_1_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Reshape_1"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/InstanceNormalization_output_0, %/model/sem_seg_head/input_proj.0/input_proj.0.1/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Mul_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Mul"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Reshape_1_output_0, %onnx::Mul_6916), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.0/input_proj.0.1/Add_output_0 : Float(1, 256, *, *, strides=[524288, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/input_proj.0/input_proj.0.1/Add"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Mul_output_0, %onnx::Add_6917), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.0/torch.nn.modules.normalization.GroupNorm::input_proj.0.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/pe_layer/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer/Shape"](%/model/sem_seg_head/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer/Gather"](%/model/sem_seg_head/pe_layer/Shape_output_0, %/model/sem_seg_head/pe_layer/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer/Shape_1"](%/model/sem_seg_head/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer/Gather_1"](%/model/sem_seg_head/pe_layer/Shape_1_output_0, %/model/sem_seg_head/pe_layer/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/pe_layer/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer/Shape_2"](%/model/sem_seg_head/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer/Gather_2"](%/model/sem_seg_head/pe_layer/Shape_2_output_0, %/model/sem_seg_head/pe_layer/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %onnx::Unsqueeze_895 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze"](%/model/sem_seg_head/pe_layer/Gather_output_0, %onnx::Unsqueeze_895), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_1"](%/model/sem_seg_head/pe_layer/Gather_1_output_0, %onnx::Unsqueeze_897), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_2"](%/model/sem_seg_head/pe_layer/Gather_2_output_0, %onnx::Unsqueeze_899), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/pe_layer/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer/Concat"](%/model/sem_seg_head/pe_layer/Unsqueeze_output_0, %/model/sem_seg_head/pe_layer/Unsqueeze_1_output_0, %/model/sem_seg_head/pe_layer/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={11}, onnx_name="/model/sem_seg_head/pe_layer/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/pe_layer/ConstantOfShape_output_0 : Bool(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/pe_layer/ConstantOfShape"](%/model/sem_seg_head/pe_layer/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer/Not_output_0 : Bool(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/pe_layer/Not"](%/model/sem_seg_head/pe_layer/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:32:0
  %/model/sem_seg_head/pe_layer/Constant_5_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer/Cast_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/pe_layer/Cast"](%/model/sem_seg_head/pe_layer/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer/CumSum_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/pe_layer/CumSum"](%/model/sem_seg_head/pe_layer/Cast_output_0, %/model/sem_seg_head/pe_layer/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer/Constant_6_output_0 : Int(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer/Cast_1_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/pe_layer/Cast_1"](%/model/sem_seg_head/pe_layer/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer/CumSum_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/pe_layer/CumSum_1"](%/model/sem_seg_head/pe_layer/Cast_1_output_0, %/model/sem_seg_head/pe_layer/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Slice_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice"](%/model/sem_seg_head/pe_layer/CumSum_output_0, %/model/sem_seg_head/pe_layer/Constant_8_output_0, %/model/sem_seg_head/pe_layer/Constant_9_output_0, %/model/sem_seg_head/pe_layer/Constant_7_output_0, %/model/sem_seg_head/pe_layer/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/pe_layer/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Add_output_0 : Float(*, *, *, strides=[64, 64, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/pe_layer/Add"](%/model/sem_seg_head/pe_layer/Slice_output_0, %/model/sem_seg_head/pe_layer/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Div_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer/Div"](%/model/sem_seg_head/pe_layer/CumSum_output_0, %/model/sem_seg_head/pe_layer/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Constant_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/pe_layer/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Mul_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/pe_layer/Mul"](%/model/sem_seg_head/pe_layer/Div_output_0, %/model/sem_seg_head/pe_layer/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Slice_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_1"](%/model/sem_seg_head/pe_layer/CumSum_1_output_0, %/model/sem_seg_head/pe_layer/Constant_14_output_0, %/model/sem_seg_head/pe_layer/Constant_15_output_0, %/model/sem_seg_head/pe_layer/Constant_13_output_0, %/model/sem_seg_head/pe_layer/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/pe_layer/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Add_1_output_0 : Float(*, *, *, strides=[32, 1, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/pe_layer/Add_1"](%/model/sem_seg_head/pe_layer/Slice_1_output_0, %/model/sem_seg_head/pe_layer/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Div_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer/Div_1"](%/model/sem_seg_head/pe_layer/CumSum_1_output_0, %/model/sem_seg_head/pe_layer/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Constant_18_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/pe_layer/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Mul_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/pe_layer/Mul_1"](%/model/sem_seg_head/pe_layer/Div_1_output_0, %/model/sem_seg_head/pe_layer/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer/Unsqueeze_3_output_0 : Float(*, *, *, 1, strides=[2048, 64, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_3"](%/model/sem_seg_head/pe_layer/Mul_1_output_0, %/model/sem_seg_head/pe_layer/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer/Constant_20_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/pe_layer/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer/Div_2_output_0 : Float(*, *, *, 128, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer/Div_2"](%/model/sem_seg_head/pe_layer/Unsqueeze_3_output_0, %/model/sem_seg_head/pe_layer/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer/Unsqueeze_4_output_0 : Float(*, *, *, 1, strides=[2048, 64, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_4"](%/model/sem_seg_head/pe_layer/Mul_output_0, %/model/sem_seg_head/pe_layer/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer/Constant_22_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/pe_layer/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer/Div_3_output_0 : Float(*, *, *, 128, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer/Div_3"](%/model/sem_seg_head/pe_layer/Unsqueeze_4_output_0, %/model/sem_seg_head/pe_layer/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Slice_2_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_2"](%/model/sem_seg_head/pe_layer/Div_2_output_0, %/model/sem_seg_head/pe_layer/Constant_24_output_0, %/model/sem_seg_head/pe_layer/Constant_25_output_0, %/model/sem_seg_head/pe_layer/Constant_23_output_0, %/model/sem_seg_head/pe_layer/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Sin_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/pe_layer/Sin"](%/model/sem_seg_head/pe_layer/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Slice_3_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_3"](%/model/sem_seg_head/pe_layer/Div_2_output_0, %/model/sem_seg_head/pe_layer/Constant_28_output_0, %/model/sem_seg_head/pe_layer/Constant_29_output_0, %/model/sem_seg_head/pe_layer/Constant_27_output_0, %/model/sem_seg_head/pe_layer/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Cos_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/pe_layer/Cos"](%/model/sem_seg_head/pe_layer/Slice_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer/Constant_31_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/pe_layer/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer/Unsqueeze_5_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_5"](%/model/sem_seg_head/pe_layer/Sin_output_0, %/model/sem_seg_head/pe_layer/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer/Unsqueeze_6_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_6"](%/model/sem_seg_head/pe_layer/Cos_output_0, %/model/sem_seg_head/pe_layer/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer/Concat_1_output_0 : Float(*, *, *, 64, 2, strides=[262144, 8192, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/pe_layer/Concat_1"](%/model/sem_seg_head/pe_layer/Unsqueeze_5_output_0, %/model/sem_seg_head/pe_layer/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer/Shape_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer/Shape_3"](%/model/sem_seg_head/pe_layer/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_4"](%/model/sem_seg_head/pe_layer/Shape_3_output_0, %/model/sem_seg_head/pe_layer/Constant_35_output_0, %/model/sem_seg_head/pe_layer/Constant_36_output_0, %/model/sem_seg_head/pe_layer/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer/Concat_2"](%/model/sem_seg_head/pe_layer/Slice_4_output_0, %/model/sem_seg_head/pe_layer/Constant_37_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Reshape_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/pe_layer/Reshape"](%/model/sem_seg_head/pe_layer/Concat_1_output_0, %/model/sem_seg_head/pe_layer/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Slice_5_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_5"](%/model/sem_seg_head/pe_layer/Div_3_output_0, %/model/sem_seg_head/pe_layer/Constant_39_output_0, %/model/sem_seg_head/pe_layer/Constant_40_output_0, %/model/sem_seg_head/pe_layer/Constant_38_output_0, %/model/sem_seg_head/pe_layer/Constant_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Sin_1_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/pe_layer/Sin_1"](%/model/sem_seg_head/pe_layer/Slice_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Slice_6_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_6"](%/model/sem_seg_head/pe_layer/Div_3_output_0, %/model/sem_seg_head/pe_layer/Constant_43_output_0, %/model/sem_seg_head/pe_layer/Constant_44_output_0, %/model/sem_seg_head/pe_layer/Constant_42_output_0, %/model/sem_seg_head/pe_layer/Constant_45_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Cos_1_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/pe_layer/Cos_1"](%/model/sem_seg_head/pe_layer/Slice_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer/Unsqueeze_7_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_7"](%/model/sem_seg_head/pe_layer/Sin_1_output_0, %/model/sem_seg_head/pe_layer/Constant_46_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer/Constant_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer/Constant_47"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer/Unsqueeze_8_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer/Unsqueeze_8"](%/model/sem_seg_head/pe_layer/Cos_1_output_0, %/model/sem_seg_head/pe_layer/Constant_47_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer/Concat_3_output_0 : Float(*, *, *, 64, 2, strides=[262144, 8192, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/pe_layer/Concat_3"](%/model/sem_seg_head/pe_layer/Unsqueeze_7_output_0, %/model/sem_seg_head/pe_layer/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer/Shape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer/Shape_4"](%/model/sem_seg_head/pe_layer/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Constant_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant_48"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer/Constant_49"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer/Constant_50"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Slice_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer/Slice_7"](%/model/sem_seg_head/pe_layer/Shape_4_output_0, %/model/sem_seg_head/pe_layer/Constant_49_output_0, %/model/sem_seg_head/pe_layer/Constant_50_output_0, %/model/sem_seg_head/pe_layer/Constant_48_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Constant_51_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer/Constant_51"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer/Concat_4"](%/model/sem_seg_head/pe_layer/Slice_7_output_0, %/model/sem_seg_head/pe_layer/Constant_51_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Reshape_1_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/pe_layer/Reshape_1"](%/model/sem_seg_head/pe_layer/Concat_3_output_0, %/model/sem_seg_head/pe_layer/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer/Concat_5_output_0 : Float(*, *, *, *, strides=[524288, 16384, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/pe_layer/Concat_5"](%/model/sem_seg_head/pe_layer/Reshape_1_output_0, %/model/sem_seg_head/pe_layer/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/Cast_1_output_0 : Float(1, 1024, *, *, strides=[8388608, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/Cast_1"](%/model/backbone/res4/res4.5/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:325:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.0/Conv_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.0/Conv"](%/model/sem_seg_head/Cast_1_output_0, %model.sem_seg_head.pixel_decoder.input_proj.1.0.weight, %model.sem_seg_head.pixel_decoder.input_proj.1.0.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.conv.Conv2d::input_proj.1.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=  0  32  -1 [ CPULongType{3} ], onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Reshape_output_0 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Reshape"](%/model/sem_seg_head/input_proj.1/input_proj.1.0/Conv_output_0, %/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_1_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_2_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/InstanceNormalization_output_0 : Float(*, *, *, device=cpu) = onnx::InstanceNormalization[epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/InstanceNormalization"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Reshape_output_0, %/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_1_output_0, %/model/sem_seg_head/input_proj.1/input_proj.1.1/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Shape"](%/model/sem_seg_head/input_proj.1/input_proj.1.0/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Reshape_1_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Reshape_1"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/InstanceNormalization_output_0, %/model/sem_seg_head/input_proj.1/input_proj.1.1/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Mul_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Mul"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Reshape_1_output_0, %onnx::Mul_6942), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.1/input_proj.1.1/Add_output_0 : Float(1, 256, *, *, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/input_proj.1/input_proj.1.1/Add"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Mul_output_0, %onnx::Add_6943), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.1/torch.nn.modules.normalization.GroupNorm::input_proj.1.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/pe_layer_1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_1/Shape"](%/model/sem_seg_head/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer_1/Gather"](%/model/sem_seg_head/pe_layer_1/Shape_output_0, %/model/sem_seg_head/pe_layer_1/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_1/Shape_1"](%/model/sem_seg_head/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer_1/Gather_1"](%/model/sem_seg_head/pe_layer_1/Shape_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_1/Shape_2"](%/model/sem_seg_head/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer_1/Gather_2"](%/model/sem_seg_head/pe_layer_1/Shape_2_output_0, %/model/sem_seg_head/pe_layer_1/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %onnx::Unsqueeze_1040 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze"](%/model/sem_seg_head/pe_layer_1/Gather_output_0, %onnx::Unsqueeze_1040), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_1042 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_1"](%/model/sem_seg_head/pe_layer_1/Gather_1_output_0, %onnx::Unsqueeze_1042), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_1044 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_2"](%/model/sem_seg_head/pe_layer_1/Gather_2_output_0, %onnx::Unsqueeze_1044), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/pe_layer_1/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer_1/Concat"](%/model/sem_seg_head/pe_layer_1/Unsqueeze_output_0, %/model/sem_seg_head/pe_layer_1/Unsqueeze_1_output_0, %/model/sem_seg_head/pe_layer_1/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/ConstantOfShape_output_0 : Bool(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/ConstantOfShape"](%/model/sem_seg_head/pe_layer_1/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_1/Not_output_0 : Bool(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/pe_layer_1/Not"](%/model/sem_seg_head/pe_layer_1/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:32:0
  %/model/sem_seg_head/pe_layer_1/Constant_3_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer_1/Cast_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/pe_layer_1/Cast"](%/model/sem_seg_head/pe_layer_1/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer_1/CumSum_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/pe_layer_1/CumSum"](%/model/sem_seg_head/pe_layer_1/Cast_output_0, %/model/sem_seg_head/pe_layer_1/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer_1/Constant_4_output_0 : Int(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer_1/Cast_1_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/pe_layer_1/Cast_1"](%/model/sem_seg_head/pe_layer_1/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer_1/CumSum_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/pe_layer_1/CumSum_1"](%/model/sem_seg_head/pe_layer_1/Cast_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer_1/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Slice_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice"](%/model/sem_seg_head/pe_layer_1/CumSum_output_0, %/model/sem_seg_head/pe_layer_1/Constant_6_output_0, %/model/sem_seg_head/pe_layer_1/Constant_7_output_0, %/model/sem_seg_head/pe_layer_1/Constant_5_output_0, %/model/sem_seg_head/pe_layer_1/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Add_output_0 : Float(*, *, *, strides=[128, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/pe_layer_1/Add"](%/model/sem_seg_head/pe_layer_1/Slice_output_0, %/model/sem_seg_head/pe_layer_1/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Div_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_1/Div"](%/model/sem_seg_head/pe_layer_1/CumSum_output_0, %/model/sem_seg_head/pe_layer_1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Mul_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/pe_layer_1/Mul"](%/model/sem_seg_head/pe_layer_1/Div_output_0, %/model/sem_seg_head/pe_layer_1/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_1/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Slice_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_1"](%/model/sem_seg_head/pe_layer_1/CumSum_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_12_output_0, %/model/sem_seg_head/pe_layer_1/Constant_13_output_0, %/model/sem_seg_head/pe_layer_1/Constant_11_output_0, %/model/sem_seg_head/pe_layer_1/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Add_1_output_0 : Float(*, *, *, strides=[64, 1, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/pe_layer_1/Add_1"](%/model/sem_seg_head/pe_layer_1/Slice_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Div_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_1/Div_1"](%/model/sem_seg_head/pe_layer_1/CumSum_1_output_0, %/model/sem_seg_head/pe_layer_1/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Mul_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/pe_layer_1/Mul_1"](%/model/sem_seg_head/pe_layer_1/Div_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_1/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_3_output_0 : Float(*, *, *, 1, strides=[8192, 128, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_3"](%/model/sem_seg_head/pe_layer_1/Mul_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_1/Constant_18_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_1/Div_2_output_0 : Float(*, *, *, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_1/Div_2"](%/model/sem_seg_head/pe_layer_1/Unsqueeze_3_output_0, %/model/sem_seg_head/pe_layer_1/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_1/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_4_output_0 : Float(*, *, *, 1, strides=[8192, 128, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_4"](%/model/sem_seg_head/pe_layer_1/Mul_output_0, %/model/sem_seg_head/pe_layer_1/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_1/Constant_20_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_1/Div_3_output_0 : Float(*, *, *, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_1/Div_3"](%/model/sem_seg_head/pe_layer_1/Unsqueeze_4_output_0, %/model/sem_seg_head/pe_layer_1/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_1/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Slice_2_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_2"](%/model/sem_seg_head/pe_layer_1/Div_2_output_0, %/model/sem_seg_head/pe_layer_1/Constant_22_output_0, %/model/sem_seg_head/pe_layer_1/Constant_23_output_0, %/model/sem_seg_head/pe_layer_1/Constant_21_output_0, %/model/sem_seg_head/pe_layer_1/Constant_24_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Sin_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/pe_layer_1/Sin"](%/model/sem_seg_head/pe_layer_1/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Slice_3_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_3"](%/model/sem_seg_head/pe_layer_1/Div_2_output_0, %/model/sem_seg_head/pe_layer_1/Constant_26_output_0, %/model/sem_seg_head/pe_layer_1/Constant_27_output_0, %/model/sem_seg_head/pe_layer_1/Constant_25_output_0, %/model/sem_seg_head/pe_layer_1/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Cos_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/pe_layer_1/Cos"](%/model/sem_seg_head/pe_layer_1/Slice_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_1/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_5_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_5"](%/model/sem_seg_head/pe_layer_1/Sin_output_0, %/model/sem_seg_head/pe_layer_1/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_1/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_6_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_6"](%/model/sem_seg_head/pe_layer_1/Cos_output_0, %/model/sem_seg_head/pe_layer_1/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_1/Concat_1_output_0 : Float(*, *, *, 64, 2, strides=[1048576, 16384, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/pe_layer_1/Concat_1"](%/model/sem_seg_head/pe_layer_1/Unsqueeze_5_output_0, %/model/sem_seg_head/pe_layer_1/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_1/Shape_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_1/Shape_3"](%/model/sem_seg_head/pe_layer_1/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_4"](%/model/sem_seg_head/pe_layer_1/Shape_3_output_0, %/model/sem_seg_head/pe_layer_1/Constant_32_output_0, %/model/sem_seg_head/pe_layer_1/Constant_33_output_0, %/model/sem_seg_head/pe_layer_1/Constant_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer_1/Concat_2"](%/model/sem_seg_head/pe_layer_1/Slice_4_output_0, %/model/sem_seg_head/pe_layer_1/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Reshape_output_0 : Float(*, *, *, *, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/pe_layer_1/Reshape"](%/model/sem_seg_head/pe_layer_1/Concat_1_output_0, %/model/sem_seg_head/pe_layer_1/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_1/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Slice_5_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_5"](%/model/sem_seg_head/pe_layer_1/Div_3_output_0, %/model/sem_seg_head/pe_layer_1/Constant_36_output_0, %/model/sem_seg_head/pe_layer_1/Constant_37_output_0, %/model/sem_seg_head/pe_layer_1/Constant_35_output_0, %/model/sem_seg_head/pe_layer_1/Constant_38_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Sin_1_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/pe_layer_1/Sin_1"](%/model/sem_seg_head/pe_layer_1/Slice_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Slice_6_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_6"](%/model/sem_seg_head/pe_layer_1/Div_3_output_0, %/model/sem_seg_head/pe_layer_1/Constant_40_output_0, %/model/sem_seg_head/pe_layer_1/Constant_41_output_0, %/model/sem_seg_head/pe_layer_1/Constant_39_output_0, %/model/sem_seg_head/pe_layer_1/Constant_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Cos_1_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/pe_layer_1/Cos_1"](%/model/sem_seg_head/pe_layer_1/Slice_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_1/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_7_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_7"](%/model/sem_seg_head/pe_layer_1/Sin_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_43_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_1/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_1/Unsqueeze_8_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_1/Unsqueeze_8"](%/model/sem_seg_head/pe_layer_1/Cos_1_output_0, %/model/sem_seg_head/pe_layer_1/Constant_44_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_1/Concat_3_output_0 : Float(*, *, *, 64, 2, strides=[1048576, 16384, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/pe_layer_1/Concat_3"](%/model/sem_seg_head/pe_layer_1/Unsqueeze_7_output_0, %/model/sem_seg_head/pe_layer_1/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_1/Shape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_1/Shape_4"](%/model/sem_seg_head/pe_layer_1/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Constant_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_47"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Slice_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_1/Slice_7"](%/model/sem_seg_head/pe_layer_1/Shape_4_output_0, %/model/sem_seg_head/pe_layer_1/Constant_46_output_0, %/model/sem_seg_head/pe_layer_1/Constant_47_output_0, %/model/sem_seg_head/pe_layer_1/Constant_45_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_1/Constant_48"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer_1/Concat_4"](%/model/sem_seg_head/pe_layer_1/Slice_7_output_0, %/model/sem_seg_head/pe_layer_1/Constant_48_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Reshape_1_output_0 : Float(*, *, *, *, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/pe_layer_1/Reshape_1"](%/model/sem_seg_head/pe_layer_1/Concat_3_output_0, %/model/sem_seg_head/pe_layer_1/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_1/Concat_5_output_0 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/pe_layer_1/Concat_5"](%/model/sem_seg_head/pe_layer_1/Reshape_1_output_0, %/model/sem_seg_head/pe_layer_1/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/Cast_2_output_0 : Float(1, 512, *, *, strides=[16777216, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/Cast_2"](%/model/backbone/res3/res3.3/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:325:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.0/Conv_output_0 : Float(1, 256, *, *, strides=[8388608, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.0/Conv"](%/model/sem_seg_head/Cast_2_output_0, %model.sem_seg_head.pixel_decoder.input_proj.2.0.weight, %model.sem_seg_head.pixel_decoder.input_proj.2.0.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.conv.Conv2d::input_proj.2.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/conv.py:549:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=  0  32  -1 [ CPULongType{3} ], onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Reshape_output_0 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Reshape"](%/model/sem_seg_head/input_proj.2/input_proj.2.0/Conv_output_0, %/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_1_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_2_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/InstanceNormalization_output_0 : Float(*, *, *, device=cpu) = onnx::InstanceNormalization[epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/InstanceNormalization"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Reshape_output_0, %/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_1_output_0, %/model/sem_seg_head/input_proj.2/input_proj.2.1/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Shape"](%/model/sem_seg_head/input_proj.2/input_proj.2.0/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Reshape_1_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Reshape_1"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/InstanceNormalization_output_0, %/model/sem_seg_head/input_proj.2/input_proj.2.1/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Mul_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Mul"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Reshape_1_output_0, %onnx::Mul_6968), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/input_proj.2/input_proj.2.1/Add_output_0 : Float(1, 256, *, *, strides=[8388608, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/input_proj.2/input_proj.2.1/Add"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Mul_output_0, %onnx::Add_6969), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/torch.nn.modules.container.Sequential::input_proj.2/torch.nn.modules.normalization.GroupNorm::input_proj.2.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/pe_layer_2/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_2/Shape"](%/model/sem_seg_head/Cast_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer_2/Gather"](%/model/sem_seg_head/pe_layer_2/Shape_output_0, %/model/sem_seg_head/pe_layer_2/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_2/Shape_1"](%/model/sem_seg_head/Cast_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer_2/Gather_1"](%/model/sem_seg_head/pe_layer_2/Shape_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_2/Shape_2"](%/model/sem_seg_head/Cast_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/pe_layer_2/Gather_2"](%/model/sem_seg_head/pe_layer_2/Shape_2_output_0, %/model/sem_seg_head/pe_layer_2/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %onnx::Unsqueeze_1182 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze"](%/model/sem_seg_head/pe_layer_2/Gather_output_0, %onnx::Unsqueeze_1182), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_1184 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_1"](%/model/sem_seg_head/pe_layer_2/Gather_1_output_0, %onnx::Unsqueeze_1184), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_1186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_2"](%/model/sem_seg_head/pe_layer_2/Gather_2_output_0, %onnx::Unsqueeze_1186), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/pe_layer_2/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer_2/Concat"](%/model/sem_seg_head/pe_layer_2/Unsqueeze_output_0, %/model/sem_seg_head/pe_layer_2/Unsqueeze_1_output_0, %/model/sem_seg_head/pe_layer_2/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/ConstantOfShape_output_0 : Bool(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/ConstantOfShape"](%/model/sem_seg_head/pe_layer_2/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/pe_layer_2/Not_output_0 : Bool(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/pe_layer_2/Not"](%/model/sem_seg_head/pe_layer_2/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:32:0
  %/model/sem_seg_head/pe_layer_2/Constant_3_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer_2/Cast_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/pe_layer_2/Cast"](%/model/sem_seg_head/pe_layer_2/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer_2/CumSum_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/pe_layer_2/CumSum"](%/model/sem_seg_head/pe_layer_2/Cast_output_0, %/model/sem_seg_head/pe_layer_2/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/pe_layer_2/Constant_4_output_0 : Int(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer_2/Cast_1_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/pe_layer_2/Cast_1"](%/model/sem_seg_head/pe_layer_2/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer_2/CumSum_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/pe_layer_2/CumSum_1"](%/model/sem_seg_head/pe_layer_2/Cast_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/pe_layer_2/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Slice_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice"](%/model/sem_seg_head/pe_layer_2/CumSum_output_0, %/model/sem_seg_head/pe_layer_2/Constant_6_output_0, %/model/sem_seg_head/pe_layer_2/Constant_7_output_0, %/model/sem_seg_head/pe_layer_2/Constant_5_output_0, %/model/sem_seg_head/pe_layer_2/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/pe_layer_2/Add"](%/model/sem_seg_head/pe_layer_2/Slice_output_0, %/model/sem_seg_head/pe_layer_2/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Div_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_2/Div"](%/model/sem_seg_head/pe_layer_2/CumSum_output_0, %/model/sem_seg_head/pe_layer_2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Mul_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/pe_layer_2/Mul"](%/model/sem_seg_head/pe_layer_2/Div_output_0, %/model/sem_seg_head/pe_layer_2/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/pe_layer_2/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Slice_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_1"](%/model/sem_seg_head/pe_layer_2/CumSum_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_12_output_0, %/model/sem_seg_head/pe_layer_2/Constant_13_output_0, %/model/sem_seg_head/pe_layer_2/Constant_11_output_0, %/model/sem_seg_head/pe_layer_2/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Add_1_output_0 : Float(*, *, *, strides=[128, 1, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/pe_layer_2/Add_1"](%/model/sem_seg_head/pe_layer_2/Slice_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Div_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_2/Div_1"](%/model/sem_seg_head/pe_layer_2/CumSum_1_output_0, %/model/sem_seg_head/pe_layer_2/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Mul_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/pe_layer_2/Mul_1"](%/model/sem_seg_head/pe_layer_2/Div_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/pe_layer_2/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_3_output_0 : Float(*, *, *, 1, strides=[32768, 256, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_3"](%/model/sem_seg_head/pe_layer_2/Mul_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_2/Constant_18_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_2/Div_2_output_0 : Float(*, *, *, 128, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_2/Div_2"](%/model/sem_seg_head/pe_layer_2/Unsqueeze_3_output_0, %/model/sem_seg_head/pe_layer_2/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/pe_layer_2/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_4_output_0 : Float(*, *, *, 1, strides=[32768, 256, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_4"](%/model/sem_seg_head/pe_layer_2/Mul_output_0, %/model/sem_seg_head/pe_layer_2/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_2/Constant_20_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_2/Div_3_output_0 : Float(*, *, *, 128, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/pe_layer_2/Div_3"](%/model/sem_seg_head/pe_layer_2/Unsqueeze_4_output_0, %/model/sem_seg_head/pe_layer_2/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/pe_layer_2/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Slice_2_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_2"](%/model/sem_seg_head/pe_layer_2/Div_2_output_0, %/model/sem_seg_head/pe_layer_2/Constant_22_output_0, %/model/sem_seg_head/pe_layer_2/Constant_23_output_0, %/model/sem_seg_head/pe_layer_2/Constant_21_output_0, %/model/sem_seg_head/pe_layer_2/Constant_24_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Sin_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/pe_layer_2/Sin"](%/model/sem_seg_head/pe_layer_2/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Slice_3_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_3"](%/model/sem_seg_head/pe_layer_2/Div_2_output_0, %/model/sem_seg_head/pe_layer_2/Constant_26_output_0, %/model/sem_seg_head/pe_layer_2/Constant_27_output_0, %/model/sem_seg_head/pe_layer_2/Constant_25_output_0, %/model/sem_seg_head/pe_layer_2/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Cos_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/pe_layer_2/Cos"](%/model/sem_seg_head/pe_layer_2/Slice_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/pe_layer_2/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_5_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_5"](%/model/sem_seg_head/pe_layer_2/Sin_output_0, %/model/sem_seg_head/pe_layer_2/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_2/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_6_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_6"](%/model/sem_seg_head/pe_layer_2/Cos_output_0, %/model/sem_seg_head/pe_layer_2/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_2/Concat_1_output_0 : Float(*, *, *, 64, 2, strides=[4194304, 32768, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/pe_layer_2/Concat_1"](%/model/sem_seg_head/pe_layer_2/Unsqueeze_5_output_0, %/model/sem_seg_head/pe_layer_2/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/pe_layer_2/Shape_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_2/Shape_3"](%/model/sem_seg_head/pe_layer_2/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_4"](%/model/sem_seg_head/pe_layer_2/Shape_3_output_0, %/model/sem_seg_head/pe_layer_2/Constant_32_output_0, %/model/sem_seg_head/pe_layer_2/Constant_33_output_0, %/model/sem_seg_head/pe_layer_2/Constant_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer_2/Concat_2"](%/model/sem_seg_head/pe_layer_2/Slice_4_output_0, %/model/sem_seg_head/pe_layer_2/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Reshape_output_0 : Float(*, *, *, *, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/pe_layer_2/Reshape"](%/model/sem_seg_head/pe_layer_2/Concat_1_output_0, %/model/sem_seg_head/pe_layer_2/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/pe_layer_2/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Slice_5_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_5"](%/model/sem_seg_head/pe_layer_2/Div_3_output_0, %/model/sem_seg_head/pe_layer_2/Constant_36_output_0, %/model/sem_seg_head/pe_layer_2/Constant_37_output_0, %/model/sem_seg_head/pe_layer_2/Constant_35_output_0, %/model/sem_seg_head/pe_layer_2/Constant_38_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Sin_1_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/pe_layer_2/Sin_1"](%/model/sem_seg_head/pe_layer_2/Slice_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Slice_6_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_6"](%/model/sem_seg_head/pe_layer_2/Div_3_output_0, %/model/sem_seg_head/pe_layer_2/Constant_40_output_0, %/model/sem_seg_head/pe_layer_2/Constant_41_output_0, %/model/sem_seg_head/pe_layer_2/Constant_39_output_0, %/model/sem_seg_head/pe_layer_2/Constant_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Cos_1_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/pe_layer_2/Cos_1"](%/model/sem_seg_head/pe_layer_2/Slice_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/pe_layer_2/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_7_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_7"](%/model/sem_seg_head/pe_layer_2/Sin_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_43_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_2/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_2/Unsqueeze_8_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/pe_layer_2/Unsqueeze_8"](%/model/sem_seg_head/pe_layer_2/Cos_1_output_0, %/model/sem_seg_head/pe_layer_2/Constant_44_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_2/Concat_3_output_0 : Float(*, *, *, 64, 2, strides=[4194304, 32768, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/pe_layer_2/Concat_3"](%/model/sem_seg_head/pe_layer_2/Unsqueeze_7_output_0, %/model/sem_seg_head/pe_layer_2/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/pe_layer_2/Shape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/pe_layer_2/Shape_4"](%/model/sem_seg_head/pe_layer_2/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Constant_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_47"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Slice_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/pe_layer_2/Slice_7"](%/model/sem_seg_head/pe_layer_2/Shape_4_output_0, %/model/sem_seg_head/pe_layer_2/Constant_46_output_0, %/model/sem_seg_head/pe_layer_2/Constant_47_output_0, %/model/sem_seg_head/pe_layer_2/Constant_45_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/pe_layer_2/Constant_48"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/pe_layer_2/Concat_4"](%/model/sem_seg_head/pe_layer_2/Slice_7_output_0, %/model/sem_seg_head/pe_layer_2/Constant_48_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Reshape_1_output_0 : Float(*, *, *, *, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/pe_layer_2/Reshape_1"](%/model/sem_seg_head/pe_layer_2/Concat_3_output_0, %/model/sem_seg_head/pe_layer_2/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/pe_layer_2/Concat_5_output_0 : Float(*, *, *, *, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/pe_layer_2/Concat_5"](%/model/sem_seg_head/pe_layer_2/Reshape_1_output_0, %/model/sem_seg_head/pe_layer_2/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/transformer/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather"](%/model/sem_seg_head/transformer/Shape_output_0, %/model/sem_seg_head/transformer/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_1"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_1"](%/model/sem_seg_head/transformer/Shape_1_output_0, %/model/sem_seg_head/transformer/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_2"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_2"](%/model/sem_seg_head/transformer/Shape_2_output_0, %/model/sem_seg_head/transformer/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %onnx::Unsqueeze_1309 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze"](%/model/sem_seg_head/transformer/Gather_output_0, %onnx::Unsqueeze_1309), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1311 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_1"](%/model/sem_seg_head/transformer/Gather_1_output_0, %onnx::Unsqueeze_1311), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1313 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_2"](%/model/sem_seg_head/transformer/Gather_2_output_0, %onnx::Unsqueeze_1313), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat"](%/model/sem_seg_head/transformer/Unsqueeze_output_0, %/model/sem_seg_head/transformer/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/ConstantOfShape_output_0 : Bool(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/transformer/ConstantOfShape"](%/model/sem_seg_head/transformer/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_3"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_3"](%/model/sem_seg_head/transformer/Shape_3_output_0, %/model/sem_seg_head/transformer/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_4"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_4"](%/model/sem_seg_head/transformer/Shape_4_output_0, %/model/sem_seg_head/transformer/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_5"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_5"](%/model/sem_seg_head/transformer/Shape_5_output_0, %/model/sem_seg_head/transformer/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %onnx::Unsqueeze_1326 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_3"](%/model/sem_seg_head/transformer/Gather_3_output_0, %onnx::Unsqueeze_1326), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1328 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_4"](%/model/sem_seg_head/transformer/Gather_4_output_0, %onnx::Unsqueeze_1328), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1330 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_5"](%/model/sem_seg_head/transformer/Gather_5_output_0, %onnx::Unsqueeze_1330), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_1"](%/model/sem_seg_head/transformer/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/ConstantOfShape_1_output_0 : Bool(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/transformer/ConstantOfShape_1"](%/model/sem_seg_head/transformer/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_6"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_6"](%/model/sem_seg_head/transformer/Shape_6_output_0, %/model/sem_seg_head/transformer/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_7"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_7"](%/model/sem_seg_head/transformer/Shape_7_output_0, %/model/sem_seg_head/transformer/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_8"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_8"](%/model/sem_seg_head/transformer/Shape_8_output_0, %/model/sem_seg_head/transformer/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %onnx::Unsqueeze_1343 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_6"](%/model/sem_seg_head/transformer/Gather_6_output_0, %onnx::Unsqueeze_1343), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1345 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_7"](%/model/sem_seg_head/transformer/Gather_7_output_0, %onnx::Unsqueeze_1345), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1347 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_8"](%/model/sem_seg_head/transformer/Gather_8_output_0, %onnx::Unsqueeze_1347), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_2"](%/model/sem_seg_head/transformer/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/ConstantOfShape_2_output_0 : Bool(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/transformer/ConstantOfShape_2"](%/model/sem_seg_head/transformer/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:63:0
  %/model/sem_seg_head/transformer/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_9"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Constant_9_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_9"](%/model/sem_seg_head/transformer/Shape_9_output_0, %/model/sem_seg_head/transformer/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Transpose_output_0 : Float(1, *, *, 256, strides=[524288, 16384, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/Transpose"](%/model/sem_seg_head/input_proj.0/input_proj.0.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %/model/sem_seg_head/transformer/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/Mul"](%/model/sem_seg_head/transformer/Gather_1_output_0, %/model/sem_seg_head/transformer/Gather_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %onnx::Unsqueeze_1356 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_9"](%/model/sem_seg_head/transformer/Gather_output_0, %onnx::Unsqueeze_1356), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_10"](%/model/sem_seg_head/transformer/Mul_output_0, %onnx::Unsqueeze_1358), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1360 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_11"](%/model/sem_seg_head/transformer/Gather_9_output_0, %onnx::Unsqueeze_1360), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_3"](%/model/sem_seg_head/transformer/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/Unsqueeze_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %onnx::Unsqueeze_1363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_12"](%/model/sem_seg_head/transformer/Gather_output_0, %onnx::Unsqueeze_1363), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_13"](%/model/sem_seg_head/transformer/Mul_output_0, %onnx::Unsqueeze_1365), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_14"](%/model/sem_seg_head/transformer/Gather_9_output_0, %onnx::Unsqueeze_1367), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_4"](%/model/sem_seg_head/transformer/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/Unsqueeze_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:79:0
  %/model/sem_seg_head/transformer/Reshape_output_0 : Float(*, *, *, strides=[524288, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/Reshape"](%/model/sem_seg_head/transformer/Transpose_output_0, %/model/sem_seg_head/transformer/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %/model/sem_seg_head/transformer/Flatten_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Flatten[axis=1, onnx_name="/model/sem_seg_head/transformer/Flatten"](%/model/sem_seg_head/transformer/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:76:0
  %/model/sem_seg_head/transformer/Reshape_1_output_0 : Float(*, *, *, strides=[524288, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/Reshape_1"](%/model/sem_seg_head/pe_layer/Concat_5_output_0, %/model/sem_seg_head/transformer/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:79:0
  %/model/sem_seg_head/transformer/Add_output_0 : Float(*, *, *, strides=[524288, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/Add"](%/model/sem_seg_head/transformer/Reshape_1_output_0, %onnx::Add_6995), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:80:0
  %/model/sem_seg_head/transformer/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_10"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Constant_10_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_10"](%/model/sem_seg_head/transformer/Shape_10_output_0, %/model/sem_seg_head/transformer/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Transpose_1_output_0 : Float(1, *, *, 256, strides=[2097152, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/Transpose_1"](%/model/sem_seg_head/input_proj.1/input_proj.1.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %/model/sem_seg_head/transformer/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/Mul_1"](%/model/sem_seg_head/transformer/Gather_4_output_0, %/model/sem_seg_head/transformer/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %onnx::Unsqueeze_1382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_15"](%/model/sem_seg_head/transformer/Gather_3_output_0, %onnx::Unsqueeze_1382), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_16"](%/model/sem_seg_head/transformer/Mul_1_output_0, %onnx::Unsqueeze_1384), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_17"](%/model/sem_seg_head/transformer/Gather_10_output_0, %onnx::Unsqueeze_1386), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_5"](%/model/sem_seg_head/transformer/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/Unsqueeze_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %onnx::Unsqueeze_1389 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_18"](%/model/sem_seg_head/transformer/Gather_3_output_0, %onnx::Unsqueeze_1389), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1391 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_19"](%/model/sem_seg_head/transformer/Mul_1_output_0, %onnx::Unsqueeze_1391), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1393 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_20"](%/model/sem_seg_head/transformer/Gather_10_output_0, %onnx::Unsqueeze_1393), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_6_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_6"](%/model/sem_seg_head/transformer/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/Unsqueeze_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:79:0
  %/model/sem_seg_head/transformer/Reshape_2_output_0 : Float(*, *, *, strides=[2097152, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/Reshape_2"](%/model/sem_seg_head/transformer/Transpose_1_output_0, %/model/sem_seg_head/transformer/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %/model/sem_seg_head/transformer/Flatten_1_output_0 : Bool(*, *, strides=[8192, 1], requires_grad=0, device=cuda:0) = onnx::Flatten[axis=1, onnx_name="/model/sem_seg_head/transformer/Flatten_1"](%/model/sem_seg_head/transformer/ConstantOfShape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:76:0
  %/model/sem_seg_head/transformer/Reshape_3_output_0 : Float(*, *, *, strides=[2097152, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/Reshape_3"](%/model/sem_seg_head/pe_layer_1/Concat_5_output_0, %/model/sem_seg_head/transformer/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:79:0
  %/model/sem_seg_head/transformer/Add_1_output_0 : Float(*, *, *, strides=[2097152, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/Add_1"](%/model/sem_seg_head/transformer/Reshape_3_output_0, %onnx::Add_6997), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:80:0
  %/model/sem_seg_head/transformer/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_11"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_11"](%/model/sem_seg_head/transformer/Shape_11_output_0, %/model/sem_seg_head/transformer/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:70:0
  %/model/sem_seg_head/transformer/Transpose_2_output_0 : Float(1, *, *, 256, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/Transpose_2"](%/model/sem_seg_head/input_proj.2/input_proj.2.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %/model/sem_seg_head/transformer/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/Mul_2"](%/model/sem_seg_head/transformer/Gather_7_output_0, %/model/sem_seg_head/transformer/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %onnx::Unsqueeze_1408 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_21"](%/model/sem_seg_head/transformer/Gather_6_output_0, %onnx::Unsqueeze_1408), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_22"](%/model/sem_seg_head/transformer/Mul_2_output_0, %onnx::Unsqueeze_1410), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_23"](%/model/sem_seg_head/transformer/Gather_11_output_0, %onnx::Unsqueeze_1412), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_7"](%/model/sem_seg_head/transformer/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/Unsqueeze_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %onnx::Unsqueeze_1415 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_24"](%/model/sem_seg_head/transformer/Gather_6_output_0, %onnx::Unsqueeze_1415), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1417 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_25"](%/model/sem_seg_head/transformer/Mul_2_output_0, %onnx::Unsqueeze_1417), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %onnx::Unsqueeze_1419 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_26"](%/model/sem_seg_head/transformer/Gather_11_output_0, %onnx::Unsqueeze_1419), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer
  %/model/sem_seg_head/transformer/Concat_8_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/Concat_8"](%/model/sem_seg_head/transformer/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/Unsqueeze_25_output_0, %/model/sem_seg_head/transformer/Unsqueeze_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:79:0
  %/model/sem_seg_head/transformer/Reshape_4_output_0 : Float(*, *, *, strides=[8388608, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/Reshape_4"](%/model/sem_seg_head/transformer/Transpose_2_output_0, %/model/sem_seg_head/transformer/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:75:0
  %/model/sem_seg_head/transformer/Flatten_2_output_0 : Bool(*, *, strides=[32768, 1], requires_grad=0, device=cuda:0) = onnx::Flatten[axis=1, onnx_name="/model/sem_seg_head/transformer/Flatten_2"](%/model/sem_seg_head/transformer/ConstantOfShape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:76:0
  %/model/sem_seg_head/transformer/Reshape_5_output_0 : Float(*, *, *, strides=[8388608, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/Reshape_5"](%/model/sem_seg_head/pe_layer_2/Concat_5_output_0, %/model/sem_seg_head/transformer/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:79:0
  %/model/sem_seg_head/transformer/Add_2_output_0 : Float(*, *, *, strides=[8388608, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/Add_2"](%/model/sem_seg_head/transformer/Reshape_5_output_0, %onnx::Add_6999), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:80:0
  %/model/sem_seg_head/transformer/Concat_9_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=1, onnx_name="/model/sem_seg_head/transformer/Concat_9"](%/model/sem_seg_head/transformer/Reshape_output_0, %/model/sem_seg_head/transformer/Reshape_2_output_0, %/model/sem_seg_head/transformer/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:84:0
  %/model/sem_seg_head/transformer/Concat_10_output_0 : Bool(*, *, strides=[43008, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=1, onnx_name="/model/sem_seg_head/transformer/Concat_10"](%/model/sem_seg_head/transformer/Flatten_output_0, %/model/sem_seg_head/transformer/Flatten_1_output_0, %/model/sem_seg_head/transformer/Flatten_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:85:0
  %/model/sem_seg_head/transformer/Concat_11_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=1, onnx_name="/model/sem_seg_head/transformer/Concat_11"](%/model/sem_seg_head/transformer/Add_output_0, %/model/sem_seg_head/transformer/Add_1_output_0, %/model/sem_seg_head/transformer/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:86:0
  %/model/sem_seg_head/transformer/Shape_12_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_12"](%/model/sem_seg_head/transformer/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_12_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_12"](%/model/sem_seg_head/transformer/Shape_12_output_0, %/model/sem_seg_head/transformer/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Shape_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_13"](%/model/sem_seg_head/transformer/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Constant_13_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_13_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_13"](%/model/sem_seg_head/transformer/Shape_13_output_0, %/model/sem_seg_head/transformer/Constant_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_14_output_0 : Bool(*, *, strides=[2048, 64], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/Gather_14"](%/model/sem_seg_head/transformer/ConstantOfShape_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Not_output_0 : Bool(*, *, strides=[32, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/transformer/Not"](%/model/sem_seg_head/transformer/Gather_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %onnx::ReduceSum_1440 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()
  %/model/sem_seg_head/transformer/Cast_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/transformer/Cast"](%/model/sem_seg_head/transformer/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/ReduceSum_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/ReduceSum"](%/model/sem_seg_head/transformer/Cast_output_0, %onnx::ReduceSum_1440), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Gather_15_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=1, onnx_name="/model/sem_seg_head/transformer/Gather_15"](%/model/sem_seg_head/transformer/ConstantOfShape_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Not_1_output_0 : Bool(*, *, strides=[64, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/transformer/Not_1"](%/model/sem_seg_head/transformer/Gather_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Cast_1_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/transformer/Cast_1"](%/model/sem_seg_head/transformer/Not_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/ReduceSum_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/ReduceSum_1"](%/model/sem_seg_head/transformer/Cast_1_output_0, %onnx::ReduceSum_1440), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Cast_2_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_2"](%/model/sem_seg_head/transformer/ReduceSum_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Cast_3_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_3"](%/model/sem_seg_head/transformer/Gather_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Div_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/Div"](%/model/sem_seg_head/transformer/Cast_2_output_0, %/model/sem_seg_head/transformer/Cast_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Cast_4_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_4"](%/model/sem_seg_head/transformer/ReduceSum_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Cast_5_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_5"](%/model/sem_seg_head/transformer/Gather_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Div_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/Div_1"](%/model/sem_seg_head/transformer/Cast_4_output_0, %/model/sem_seg_head/transformer/Cast_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Unsqueeze_27_output_0 : Float(*, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_27"](%/model/sem_seg_head/transformer/Div_1_output_0, %/model/sem_seg_head/transformer/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Unsqueeze_28_output_0 : Float(*, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_28"](%/model/sem_seg_head/transformer/Div_output_0, %/model/sem_seg_head/transformer/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Concat_12_output_0 : Float(*, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=-1, onnx_name="/model/sem_seg_head/transformer/Concat_12"](%/model/sem_seg_head/transformer/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Shape_14_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_14"](%/model/sem_seg_head/transformer/ConstantOfShape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_16_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_16"](%/model/sem_seg_head/transformer/Shape_14_output_0, %/model/sem_seg_head/transformer/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Shape_15_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_15"](%/model/sem_seg_head/transformer/ConstantOfShape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_17_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_17"](%/model/sem_seg_head/transformer/Shape_15_output_0, %/model/sem_seg_head/transformer/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_18_output_0 : Bool(*, *, strides=[8192, 128], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/Gather_18"](%/model/sem_seg_head/transformer/ConstantOfShape_1_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Not_2_output_0 : Bool(*, *, strides=[64, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/transformer/Not_2"](%/model/sem_seg_head/transformer/Gather_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Cast_6_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/transformer/Cast_6"](%/model/sem_seg_head/transformer/Not_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/ReduceSum_2_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/ReduceSum_2"](%/model/sem_seg_head/transformer/Cast_6_output_0, %onnx::ReduceSum_1440), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Gather_19_output_0 : Bool(*, *, strides=[8192, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=1, onnx_name="/model/sem_seg_head/transformer/Gather_19"](%/model/sem_seg_head/transformer/ConstantOfShape_1_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Not_3_output_0 : Bool(*, *, strides=[128, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/transformer/Not_3"](%/model/sem_seg_head/transformer/Gather_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Cast_7_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/transformer/Cast_7"](%/model/sem_seg_head/transformer/Not_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/ReduceSum_3_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/ReduceSum_3"](%/model/sem_seg_head/transformer/Cast_7_output_0, %onnx::ReduceSum_1440), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Cast_8_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_8"](%/model/sem_seg_head/transformer/ReduceSum_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_9"](%/model/sem_seg_head/transformer/Gather_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Div_2_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/Div_2"](%/model/sem_seg_head/transformer/Cast_8_output_0, %/model/sem_seg_head/transformer/Cast_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Cast_10_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_10"](%/model/sem_seg_head/transformer/ReduceSum_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Cast_11_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_11"](%/model/sem_seg_head/transformer/Gather_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Div_3_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/Div_3"](%/model/sem_seg_head/transformer/Cast_10_output_0, %/model/sem_seg_head/transformer/Cast_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Unsqueeze_29_output_0 : Float(*, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_29"](%/model/sem_seg_head/transformer/Div_3_output_0, %/model/sem_seg_head/transformer/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Unsqueeze_30_output_0 : Float(*, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_30"](%/model/sem_seg_head/transformer/Div_2_output_0, %/model/sem_seg_head/transformer/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Concat_13_output_0 : Float(*, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=-1, onnx_name="/model/sem_seg_head/transformer/Concat_13"](%/model/sem_seg_head/transformer/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/Unsqueeze_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Shape_16_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_16"](%/model/sem_seg_head/transformer/ConstantOfShape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_20_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_20"](%/model/sem_seg_head/transformer/Shape_16_output_0, %/model/sem_seg_head/transformer/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Shape_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/Shape_17"](%/model/sem_seg_head/transformer/ConstantOfShape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_21_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/Gather_21"](%/model/sem_seg_head/transformer/Shape_17_output_0, %/model/sem_seg_head/transformer/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:54:0
  %/model/sem_seg_head/transformer/Gather_22_output_0 : Bool(*, *, strides=[32768, 256], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/Gather_22"](%/model/sem_seg_head/transformer/ConstantOfShape_2_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Not_4_output_0 : Bool(*, *, strides=[128, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/transformer/Not_4"](%/model/sem_seg_head/transformer/Gather_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Cast_12_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/transformer/Cast_12"](%/model/sem_seg_head/transformer/Not_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/ReduceSum_4_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/ReduceSum_4"](%/model/sem_seg_head/transformer/Cast_12_output_0, %onnx::ReduceSum_1440), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:55:0
  %/model/sem_seg_head/transformer/Gather_23_output_0 : Bool(*, *, strides=[32768, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=1, onnx_name="/model/sem_seg_head/transformer/Gather_23"](%/model/sem_seg_head/transformer/ConstantOfShape_2_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Not_5_output_0 : Bool(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/transformer/Not_5"](%/model/sem_seg_head/transformer/Gather_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Cast_13_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/transformer/Cast_13"](%/model/sem_seg_head/transformer/Not_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/ReduceSum_5_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/ReduceSum_5"](%/model/sem_seg_head/transformer/Cast_13_output_0, %onnx::ReduceSum_1440), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:56:0
  %/model/sem_seg_head/transformer/Cast_14_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_14"](%/model/sem_seg_head/transformer/ReduceSum_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Cast_15_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_15"](%/model/sem_seg_head/transformer/Gather_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Div_4_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/Div_4"](%/model/sem_seg_head/transformer/Cast_14_output_0, %/model/sem_seg_head/transformer/Cast_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:57:0
  %/model/sem_seg_head/transformer/Cast_16_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_16"](%/model/sem_seg_head/transformer/ReduceSum_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Cast_17_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/transformer/Cast_17"](%/model/sem_seg_head/transformer/Gather_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Div_5_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/Div_5"](%/model/sem_seg_head/transformer/Cast_16_output_0, %/model/sem_seg_head/transformer/Cast_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:58:0
  %/model/sem_seg_head/transformer/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Unsqueeze_31_output_0 : Float(*, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_31"](%/model/sem_seg_head/transformer/Div_5_output_0, %/model/sem_seg_head/transformer/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Unsqueeze_32_output_0 : Float(*, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_32"](%/model/sem_seg_head/transformer/Div_4_output_0, %/model/sem_seg_head/transformer/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Concat_14_output_0 : Float(*, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=-1, onnx_name="/model/sem_seg_head/transformer/Concat_14"](%/model/sem_seg_head/transformer/Unsqueeze_31_output_0, %/model/sem_seg_head/transformer/Unsqueeze_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:59:0
  %/model/sem_seg_head/transformer/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/Unsqueeze_33_output_0 : Float(*, 1, 2, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_33"](%/model/sem_seg_head/transformer/Concat_12_output_0, %/model/sem_seg_head/transformer/Constant_24_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/Unsqueeze_34_output_0 : Float(*, 1, 2, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_34"](%/model/sem_seg_head/transformer/Concat_13_output_0, %/model/sem_seg_head/transformer/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/Unsqueeze_35_output_0 : Float(*, 1, 2, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/Unsqueeze_35"](%/model/sem_seg_head/transformer/Concat_14_output_0, %/model/sem_seg_head/transformer/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/Concat_15_output_0 : Float(*, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=1, onnx_name="/model/sem_seg_head/transformer/Concat_15"](%/model/sem_seg_head/transformer/Unsqueeze_33_output_0, %/model/sem_seg_head/transformer/Unsqueeze_34_output_0, %/model/sem_seg_head/transformer/Unsqueeze_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:89:0
  %/model/sem_seg_head/transformer/encoder/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_output_0 : Float(*, 1, 3, 2, strides=[6, 6, 2, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze"](%/model/sem_seg_head/transformer/Concat_15_output_0, %/model/sem_seg_head/transformer/encoder/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_output_0 : Float(*, 1, 2, strides=[6, 6, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_1_output_0 : Float(*, 1, strides=[6, 6], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_1"](%/model/sem_seg_head/transformer/encoder/Gather_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Mul_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul"](%/model/sem_seg_head/transformer/encoder/Gather_1_output_0, %/model/sem_seg_head/transformer/encoder/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Constant_2_output_0 : Float(1, 2048, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Div_output_0 : Float(*, 2048, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/Div"](%/model/sem_seg_head/transformer/encoder/Constant_2_output_0, %/model/sem_seg_head/transformer/encoder/Mul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_2_output_0 : Float(*, 1, strides=[6, 6], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_2"](%/model/sem_seg_head/transformer/encoder/Gather_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Mul_1_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul_1"](%/model/sem_seg_head/transformer/encoder/Gather_2_output_0, %/model/sem_seg_head/transformer/encoder/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_4_output_0 : Float(1, 2048, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Div_1_output_0 : Float(*, 2048, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/Div_1"](%/model/sem_seg_head/transformer/encoder/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/Mul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_1_output_0 : Float(*, 2048, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/Div_1_output_0, %/model/sem_seg_head/transformer/encoder/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_2_output_0 : Float(*, 2048, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/Div_output_0, %/model/sem_seg_head/transformer/encoder/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Concat_output_0 : Float(*, 2048, 2, strides=[4096, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/Concat"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Gather_3_output_0 : Float(*, 1, 2, strides=[6, 6, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_3"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_4_output_0 : Float(*, 1, strides=[6, 6], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_4"](%/model/sem_seg_head/transformer/encoder/Gather_3_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Mul_2_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul_2"](%/model/sem_seg_head/transformer/encoder/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Constant_8_output_0 : Float(1, 8192, strides=[8192, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Div_2_output_0 : Float(*, 8192, strides=[8192, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/Div_2"](%/model/sem_seg_head/transformer/encoder/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/Mul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_5_output_0 : Float(*, 1, strides=[6, 6], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_5"](%/model/sem_seg_head/transformer/encoder/Gather_3_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul_3"](%/model/sem_seg_head/transformer/encoder/Gather_5_output_0, %/model/sem_seg_head/transformer/encoder/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_10_output_0 : Float(1, 8192, strides=[8192, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Div_3_output_0 : Float(*, 8192, strides=[8192, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/Div_3"](%/model/sem_seg_head/transformer/encoder/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_3_output_0 : Float(*, 8192, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/Div_3_output_0, %/model/sem_seg_head/transformer/encoder/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_4_output_0 : Float(*, 8192, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/Div_2_output_0, %/model/sem_seg_head/transformer/encoder/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Concat_1_output_0 : Float(*, 8192, 2, strides=[16384, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/Concat_1"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/Unsqueeze_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Gather_6_output_0 : Float(*, 1, 2, strides=[6, 6, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_6"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_7_output_0 : Float(*, 1, strides=[6, 6], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_7"](%/model/sem_seg_head/transformer/encoder/Gather_6_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Mul_4_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul_4"](%/model/sem_seg_head/transformer/encoder/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/Constant_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Constant_14_output_0 : Float(1, 32768, strides=[32768, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Div_4_output_0 : Float(*, 32768, strides=[32768, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/Div_4"](%/model/sem_seg_head/transformer/encoder/Constant_14_output_0, %/model/sem_seg_head/transformer/encoder/Mul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:152:0
  %/model/sem_seg_head/transformer/encoder/Gather_8_output_0 : Float(*, 1, strides=[6, 6], requires_grad=0, device=cuda:0) = onnx::Gather[axis=2, onnx_name="/model/sem_seg_head/transformer/encoder/Gather_8"](%/model/sem_seg_head/transformer/encoder/Gather_6_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Mul_5_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul_5"](%/model/sem_seg_head/transformer/encoder/Gather_8_output_0, %/model/sem_seg_head/transformer/encoder/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_16_output_0 : Float(1, 32768, strides=[32768, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Div_5_output_0 : Float(*, 32768, strides=[32768, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/Div_5"](%/model/sem_seg_head/transformer/encoder/Constant_16_output_0, %/model/sem_seg_head/transformer/encoder/Mul_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:153:0
  %/model/sem_seg_head/transformer/encoder/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_5_output_0 : Float(*, 32768, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/Div_5_output_0, %/model/sem_seg_head/transformer/encoder/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_6_output_0 : Float(*, 32768, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/Div_4_output_0, %/model/sem_seg_head/transformer/encoder/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Concat_2_output_0 : Float(*, 32768, 2, strides=[65536, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/Concat_2"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:154:0
  %/model/sem_seg_head/transformer/encoder/Concat_3_output_0 : Float(*, 43008, 2, strides=[86016, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/Concat_3"](%/model/sem_seg_head/transformer/encoder/Concat_output_0, %/model/sem_seg_head/transformer/encoder/Concat_1_output_0, %/model/sem_seg_head/transformer/encoder/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:156:0
  %/model/sem_seg_head/transformer/encoder/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:157:0
  %/model/sem_seg_head/transformer/encoder/Unsqueeze_7_output_0 : Float(*, 43008, 1, 2, strides=[86016, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/Concat_3_output_0, %/model/sem_seg_head/transformer/encoder/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:157:0
  %/model/sem_seg_head/transformer/encoder/Mul_6_output_0 : Float(*, 43008, 3, 2, strides=[258048, 6, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/Mul_6"](%/model/sem_seg_head/transformer/encoder/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:157:0
  %/model/sem_seg_head/transformer/encoder/layers.0/Add_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/Add"](%/model/sem_seg_head/transformer/Concat_9_output_0, %/model/sem_seg_head/transformer/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:119:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape"](%/model/sem_seg_head/transformer/encoder/layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_1"](%/model/sem_seg_head/transformer/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_2"](%/model/sem_seg_head/transformer/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/value_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/value_proj/MatMul"](%/model/sem_seg_head/transformer/Concat_9_output_0, %onnx::MatMul_7000), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/value_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/value_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/value_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0 : Bool(*, *, 1, strides=[43008, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze"](%/model/sem_seg_head/transformer/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Cast_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Cast"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Where_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Where"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Cast_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/value_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1588 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1588), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_2_output_0, %onnx::Unsqueeze_1590), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Where_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 192, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/sampling_offsets/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.0/Add_output_0, %onnx::MatMul_7003), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/sampling_offsets/Add_output_0 : Float(*, *, 192, strides=[8257536, 192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/sampling_offsets/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/sampling_offsets/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_1601 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1601), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1603 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_1603), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_1_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/sampling_offsets/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/attention_weights/MatMul_output_0 : Float(*, *, 96, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/attention_weights/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.0/Add_output_0, %onnx::MatMul_7008), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/attention_weights/Add_output_0 : Float(*, *, 96, strides=[4128768, 96, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/attention_weights/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/attention_weights/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1619 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1619), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1621 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_1621), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_2_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/attention_weights/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Softmax_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Softmax"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %onnx::Unsqueeze_1630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1630), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_8"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_1632), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_3_output_0 : Float(*, *, 8, 3, 4, strides=[4128768, 96, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Softmax_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_9_output_0 : Float(*, 43008, 1, 3, 2, strides=[258048, 6, 6, 2, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_9"](%/model/sem_seg_head/transformer/encoder/Mul_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0 : Float(*, 43008, 1, 3, 1, 2, strides=[258048, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_20_output_0 : Float(1, 1, 1, 3, 1, 2, strides=[6, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,1,1,1,.,.) =    64  32  (1,1,1,2,.,.) =    128   64  (1,1,1,3,.,.) =    256  128 [ CUDAFloatType{1,1,1,3,1,2} ], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Div_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Div"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Add_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_22_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_5"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_23_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_5"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_6"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_24_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_7"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_7"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_8"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_26_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_8"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %onnx::Split_1667 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=  2048   8192  32768 [ CPULongType{3} ]]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split_output_1 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split_output_2 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Split[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_output_0, %onnx::Split_1667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_27_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_28_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Sub_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Sub"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_output_0 : Float(*, 8, 32, *, strides=[524288, 65536, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %onnx::Unsqueeze_1678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_11"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1678), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1680 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_12"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_1680), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[65536, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_9_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_9"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Sub_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_1_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %onnx::Unsqueeze_1690 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_13"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1690), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1692 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_14"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1692), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1694 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_15"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_8_output_0, %onnx::Unsqueeze_1694), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_5"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_14_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_1699 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_16"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1699), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1701 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_17"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1701), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_18"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_8_output_0, %onnx::Unsqueeze_1703), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_6"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_17_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_1708 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_19"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1708), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_20"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1710), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_21"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_8_output_0, %onnx::Unsqueeze_1712), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_7"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_20_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_5"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_2_output_0 : Float(*, 8, 32, *, strides=[2097152, 262144, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split_output_1), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_1721 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_22"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1721), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_23"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_1723), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_8"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_23_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_34_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_6"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_10_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_10"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Sub_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_3_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_7_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_7"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_1_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_1"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_4_output_0 : Float(*, 8, 32, *, strides=[8388608, 1048576, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Split_output_2), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_1737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_24"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1737), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_25"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_1739), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_9"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_25_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_36_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_37_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_8_output_0 : Float(*, *, *, *, strides=[1048576, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_8"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_11_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_11"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Sub_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_5_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_5"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_9_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_9"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_2_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_26_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_26"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_38_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_27_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_27"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_28_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_28"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/GridSample_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_40_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_10_output_0 : Float(*, *, *, 3, *, strides=[16515072, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_10"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_26_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_9_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_9"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Slice_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Slice"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Shape_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_42_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_43_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_11"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Slice_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_44_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_10_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_10"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_6_output_0 : Float(*, 8, *, 3, 4, strides=[4128768, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_6"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_2"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %onnx::Unsqueeze_1768 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_29"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1768), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1772 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_30"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1772), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1774 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_31"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_2_output_0, %onnx::Unsqueeze_1774), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_12_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_12"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_45_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_30_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_11_output_0 : Float(*, *, *, *, strides=[516096, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_11"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_3_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_3"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %onnx::ReduceSum_1779 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/ReduceSum_output_0 : Float(*, *, *, strides=[1376256, 43008, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/ReduceSum"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_3_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_4"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %onnx::Unsqueeze_1782 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_32"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_3_output_0, %onnx::Unsqueeze_1782), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1784 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_33"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Mul_4_output_0, %onnx::Unsqueeze_1784), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_34"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1786), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_13"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_32_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_33_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_12_output_0 : Float(*, *, *, strides=[11010048, 43008, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_12"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/ReduceSum_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_7_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_7"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Reshape_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:114:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/output_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Transpose_7_output_0, %onnx::MatMul_7024), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/self_attn/output_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/output_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/Add_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/Add_1"](%/model/sem_seg_head/transformer/Concat_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/output_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:130:0
  %/model/sem_seg_head/transformer/encoder/layers.0/norm1/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/norm1/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.0/Add_1_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.0/linear1/MatMul_output_0 : Float(*, *, 1024, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/linear1/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.0/norm1/LayerNormalization_output_0, %onnx::MatMul_7025), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/linear1/Add_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/linear1/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias, %/model/sem_seg_head/transformer/encoder/layers.0/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/Relu_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/Relu"](%/model/sem_seg_head/transformer/encoder/layers.0/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/transformer/encoder/layers.0/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/linear2/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.0/Relu_output_0, %onnx::MatMul_7026), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/linear2/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/linear2/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias, %/model/sem_seg_head/transformer/encoder/layers.0/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.0/Add_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/Add_2"](%/model/sem_seg_head/transformer/encoder/layers.0/norm1/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:123:0
  %/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.0/Add_2_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.1/Add_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:119:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape"](%/model/sem_seg_head/transformer/encoder/layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_1"](%/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_2"](%/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/value_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/value_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization_output_0, %onnx::MatMul_7027), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/value_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/value_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/value_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Cast_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Cast"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Where_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Where"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Cast_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/value_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %onnx::Unsqueeze_1821 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1821), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1823 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_2_output_0, %onnx::Unsqueeze_1823), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Where_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 192, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/sampling_offsets/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.1/Add_output_0, %onnx::MatMul_7030), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/sampling_offsets/Add_output_0 : Float(*, *, 192, strides=[8257536, 192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/sampling_offsets/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/sampling_offsets/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_1834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1834), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_1836), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_1_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/sampling_offsets/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/attention_weights/MatMul_output_0 : Float(*, *, 96, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/attention_weights/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.1/Add_output_0, %onnx::MatMul_7035), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/attention_weights/Add_output_0 : Float(*, *, 96, strides=[4128768, 96, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/attention_weights/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/attention_weights/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_1851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1851), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_1853), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_2_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/attention_weights/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Softmax_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Softmax"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %onnx::Unsqueeze_1862 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_1862), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_1864), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_3_output_0 : Float(*, *, 8, 3, 4, strides=[4128768, 96, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Softmax_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_15_output_0 : Float(1, 1, 1, 3, 1, 2, strides=[6, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,1,1,1,.,.) =    64  32  (1,1,1,2,.,.) =    128   64  (1,1,1,3,.,.) =    256  128 [ CUDAFloatType{1,1,1,3,1,2} ], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Div_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Div"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Add_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_5"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_5"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_6"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_7"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_7"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_8"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_8"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split_output_1 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split_output_2 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Split[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_output_0, %onnx::Split_1667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_22_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_23_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Sub_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Sub"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_output_0 : Float(*, 8, 32, *, strides=[524288, 65536, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %onnx::Unsqueeze_1904 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_8"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1904), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1906 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_9"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_1906), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[65536, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_9_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_9"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Sub_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_1_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %onnx::Unsqueeze_1916 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_10"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1916), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1918 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_11"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1918), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1920 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_12"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_8_output_0, %onnx::Unsqueeze_1920), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_5"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_1925 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_13"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1925), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_14"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1927), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_15"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_8_output_0, %onnx::Unsqueeze_1929), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_6"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_14_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_1934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_16"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1934), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1936 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_17"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1936), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1938 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_18"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_8_output_0, %onnx::Unsqueeze_1938), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_7"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_17_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_5"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_2_output_0 : Float(*, 8, 32, *, strides=[2097152, 262144, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split_output_1), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_1946 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_19"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1946), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1948 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_20"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_1948), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_8"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_20_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_6"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_10_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_10"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Sub_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_3_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_7_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_7"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_1_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_1"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_4_output_0 : Float(*, 8, 32, *, strides=[8388608, 1048576, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Split_output_2), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_1961 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_21"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1961), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1963 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_22"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_1963), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_9"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_31_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_8_output_0 : Float(*, *, *, *, strides=[1048576, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_8"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_11_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_11"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Sub_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_5_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_5"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_9_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_9"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_2_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_23_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_23"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_24_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_24"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_25_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_25"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/GridSample_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_10_output_0 : Float(*, *, *, 3, *, strides=[16515072, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_10"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_23_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_9_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_9"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Slice_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Slice"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Shape_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_37_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_38_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_11"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Slice_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_10_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_10"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_6_output_0 : Float(*, 8, *, 3, 4, strides=[4128768, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_6"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_2"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %onnx::Unsqueeze_1992 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_26"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_1_output_0, %onnx::Unsqueeze_1992), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1996 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_27"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_1996), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_1998 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_28"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_2_output_0, %onnx::Unsqueeze_1998), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_12_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_12"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_26_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Constant_40_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_11_output_0 : Float(*, *, *, *, strides=[516096, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_11"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_3_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_3"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/ReduceSum_output_0 : Float(*, *, *, strides=[1376256, 43008, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/ReduceSum"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_3_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_4"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %onnx::Unsqueeze_2005 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_29"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_3_output_0, %onnx::Unsqueeze_2005), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2007 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_30"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Mul_4_output_0, %onnx::Unsqueeze_2007), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2009 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_31"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2009), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_13"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_30_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_12_output_0 : Float(*, *, *, strides=[11010048, 43008, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_12"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/ReduceSum_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_7_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_7"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Reshape_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:114:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/output_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.1/self_attn/Transpose_7_output_0, %onnx::MatMul_7051), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/self_attn/output_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/output_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/Add_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/Add_1"](%/model/sem_seg_head/transformer/encoder/layers.0/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/self_attn/output_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:130:0
  %/model/sem_seg_head/transformer/encoder/layers.1/norm1/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/norm1/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.1/Add_1_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.1/linear1/MatMul_output_0 : Float(*, *, 1024, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/linear1/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.1/norm1/LayerNormalization_output_0, %onnx::MatMul_7052), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/linear1/Add_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/linear1/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias, %/model/sem_seg_head/transformer/encoder/layers.1/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/Relu_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/Relu"](%/model/sem_seg_head/transformer/encoder/layers.1/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/transformer/encoder/layers.1/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/linear2/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.1/Relu_output_0, %onnx::MatMul_7053), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/linear2/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/linear2/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias, %/model/sem_seg_head/transformer/encoder/layers.1/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.1/Add_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/Add_2"](%/model/sem_seg_head/transformer/encoder/layers.1/norm1/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.1/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:123:0
  %/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.1/Add_2_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.2/Add_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/Add"](%/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:119:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape"](%/model/sem_seg_head/transformer/encoder/layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_1"](%/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_2"](%/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/value_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/value_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization_output_0, %onnx::MatMul_7054), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/value_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/value_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/value_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Cast_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Cast"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Where_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Where"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Cast_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/value_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %onnx::Unsqueeze_2044 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2044), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2046 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_2_output_0, %onnx::Unsqueeze_2046), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Where_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 192, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/sampling_offsets/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.2/Add_output_0, %onnx::MatMul_7057), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/sampling_offsets/Add_output_0 : Float(*, *, 192, strides=[8257536, 192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/sampling_offsets/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/sampling_offsets/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2057), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2059 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_2059), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_1_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/sampling_offsets/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/attention_weights/MatMul_output_0 : Float(*, *, 96, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/attention_weights/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.2/Add_output_0, %onnx::MatMul_7062), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/attention_weights/Add_output_0 : Float(*, *, 96, strides=[4128768, 96, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/attention_weights/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/attention_weights/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2074 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2074), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2076 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_2076), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_2_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/attention_weights/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Softmax_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Softmax"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %onnx::Unsqueeze_2085 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2085), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2087 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_2087), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_3_output_0 : Float(*, *, 8, 3, 4, strides=[4128768, 96, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Softmax_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_15_output_0 : Float(1, 1, 1, 3, 1, 2, strides=[6, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,1,1,1,.,.) =    64  32  (1,1,1,2,.,.) =    128   64  (1,1,1,3,.,.) =    256  128 [ CUDAFloatType{1,1,1,3,1,2} ], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Div_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Div"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Add_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_5"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_5"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_6"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_7"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_7"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_8"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_8"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split_output_1 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split_output_2 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Split[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_output_0, %onnx::Split_1667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_22_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_23_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Sub_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Sub"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_output_0 : Float(*, 8, 32, *, strides=[524288, 65536, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %onnx::Unsqueeze_2127 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_8"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2127), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2129 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_9"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2129), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[65536, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_9_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_9"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Sub_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_1_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %onnx::Unsqueeze_2139 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_10"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2139), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2141 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_11"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2141), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2143 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_12"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2143), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_5"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2148 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_13"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2148), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_14"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2150), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_15"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2152), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_6"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_14_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_16"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2157), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_17"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2159), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2161 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_18"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2161), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_7"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_17_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_5"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_2_output_0 : Float(*, 8, 32, *, strides=[2097152, 262144, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split_output_1), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2169 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_19"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2169), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2171 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_20"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2171), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_8"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_20_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_6"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_10_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_10"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Sub_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_3_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_7_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_7"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_1_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_1"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_4_output_0 : Float(*, 8, 32, *, strides=[8388608, 1048576, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Split_output_2), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2184 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_21"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2184), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_22"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2186), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_9"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_31_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_8_output_0 : Float(*, *, *, *, strides=[1048576, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_8"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_11_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_11"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Sub_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_5_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_5"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_9_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_9"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_2_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_23_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_23"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_24_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_24"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_25_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_25"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/GridSample_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_10_output_0 : Float(*, *, *, 3, *, strides=[16515072, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_10"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_23_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_9_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_9"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Slice_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Slice"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Shape_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_37_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_38_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_11"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Slice_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_10_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_10"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_6_output_0 : Float(*, 8, *, 3, 4, strides=[4128768, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_6"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_2"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %onnx::Unsqueeze_2215 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_26"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2215), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2219 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_27"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2219), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2221 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_28"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_2_output_0, %onnx::Unsqueeze_2221), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_12_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_12"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_26_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Constant_40_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_11_output_0 : Float(*, *, *, *, strides=[516096, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_11"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_3_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_3"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/ReduceSum_output_0 : Float(*, *, *, strides=[1376256, 43008, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/ReduceSum"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_3_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_4"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %onnx::Unsqueeze_2228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_29"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_3_output_0, %onnx::Unsqueeze_2228), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_30"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Mul_4_output_0, %onnx::Unsqueeze_2230), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_31"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2232), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_13"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_30_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_12_output_0 : Float(*, *, *, strides=[11010048, 43008, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_12"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/ReduceSum_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_7_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_7"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Reshape_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:114:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/output_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.2/self_attn/Transpose_7_output_0, %onnx::MatMul_7078), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/self_attn/output_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/output_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/Add_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/Add_1"](%/model/sem_seg_head/transformer/encoder/layers.1/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/self_attn/output_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:130:0
  %/model/sem_seg_head/transformer/encoder/layers.2/norm1/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/norm1/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.2/Add_1_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/torch.nn.modules.normalization.LayerNorm::norm1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.2/linear1/MatMul_output_0 : Float(*, *, 1024, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/linear1/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.2/norm1/LayerNormalization_output_0, %onnx::MatMul_7079), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/linear1/Add_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/linear1/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias, %/model/sem_seg_head/transformer/encoder/layers.2/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/Relu_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/Relu"](%/model/sem_seg_head/transformer/encoder/layers.2/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/transformer/encoder/layers.2/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/linear2/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.2/Relu_output_0, %onnx::MatMul_7080), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/linear2/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/linear2/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias, %/model/sem_seg_head/transformer/encoder/layers.2/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.2/Add_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/Add_2"](%/model/sem_seg_head/transformer/encoder/layers.2/norm1/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.2/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:123:0
  %/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.2/Add_2_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.2/torch.nn.modules.normalization.LayerNorm::norm2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.3/Add_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/Add"](%/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:119:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape"](%/model/sem_seg_head/transformer/encoder/layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_1"](%/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_2"](%/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/value_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/value_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization_output_0, %onnx::MatMul_7081), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/value_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/value_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/value_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Cast_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Cast"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Where_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Where"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Cast_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/value_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %onnx::Unsqueeze_2267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2267), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2269 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_2_output_0, %onnx::Unsqueeze_2269), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Where_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 192, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/sampling_offsets/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.3/Add_output_0, %onnx::MatMul_7084), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/sampling_offsets/Add_output_0 : Float(*, *, 192, strides=[8257536, 192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/sampling_offsets/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/sampling_offsets/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2280 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2280), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2282 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_2282), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_1_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/sampling_offsets/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/attention_weights/MatMul_output_0 : Float(*, *, 96, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/attention_weights/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.3/Add_output_0, %onnx::MatMul_7089), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/attention_weights/Add_output_0 : Float(*, *, 96, strides=[4128768, 96, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/attention_weights/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/attention_weights/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2297), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2299 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_2299), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_2_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/attention_weights/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Softmax_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Softmax"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %onnx::Unsqueeze_2308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2308), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2310 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_2310), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_3_output_0 : Float(*, *, 8, 3, 4, strides=[4128768, 96, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Softmax_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_15_output_0 : Float(1, 1, 1, 3, 1, 2, strides=[6, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,1,1,1,.,.) =    64  32  (1,1,1,2,.,.) =    128   64  (1,1,1,3,.,.) =    256  128 [ CUDAFloatType{1,1,1,3,1,2} ], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Div_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Div"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Add_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_5"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_5"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_6"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_7"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_7"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_8"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_8"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split_output_1 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split_output_2 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Split[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_output_0, %onnx::Split_1667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_22_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_23_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Sub_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Sub"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_output_0 : Float(*, 8, 32, *, strides=[524288, 65536, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %onnx::Unsqueeze_2350 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_8"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2350), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2352 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_9"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2352), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[65536, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_9_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_9"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Sub_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_1_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %onnx::Unsqueeze_2362 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_10"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2362), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_11"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2364), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_12"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2366), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_5"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_13"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2371), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_14"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2373), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_15"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2375), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_6"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_14_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2380 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_16"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2380), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_17"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2382), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_18"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2384), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_7"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_17_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_5"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_2_output_0 : Float(*, 8, 32, *, strides=[2097152, 262144, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split_output_1), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2392 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_19"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2392), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2394 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_20"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2394), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_8"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_20_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_6"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_10_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_10"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Sub_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_3_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_7_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_7"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_1_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_1"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_4_output_0 : Float(*, 8, 32, *, strides=[8388608, 1048576, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Split_output_2), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2407 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_21"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2407), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_22"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2409), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_9"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_31_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_8_output_0 : Float(*, *, *, *, strides=[1048576, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_8"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_11_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_11"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Sub_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_5_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_5"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_9_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_9"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_2_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_23_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_23"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_24_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_24"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_25_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_25"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/GridSample_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_10_output_0 : Float(*, *, *, 3, *, strides=[16515072, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_10"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_23_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_9_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_9"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Slice_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Slice"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Shape_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_37_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_38_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_11"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Slice_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_10_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_10"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_6_output_0 : Float(*, 8, *, 3, 4, strides=[4128768, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_6"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_2"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %onnx::Unsqueeze_2438 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_26"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2438), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2442 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_27"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2442), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2444 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_28"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_2_output_0, %onnx::Unsqueeze_2444), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_12_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_12"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_26_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Constant_40_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_11_output_0 : Float(*, *, *, *, strides=[516096, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_11"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_3_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_3"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/ReduceSum_output_0 : Float(*, *, *, strides=[1376256, 43008, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/ReduceSum"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_3_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_4"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %onnx::Unsqueeze_2451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_29"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_3_output_0, %onnx::Unsqueeze_2451), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_30"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Mul_4_output_0, %onnx::Unsqueeze_2453), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2455 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_31"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2455), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_13"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_30_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_12_output_0 : Float(*, *, *, strides=[11010048, 43008, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_12"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/ReduceSum_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_7_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_7"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Reshape_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:114:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/output_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.3/self_attn/Transpose_7_output_0, %onnx::MatMul_7105), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/self_attn/output_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/output_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/Add_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/Add_1"](%/model/sem_seg_head/transformer/encoder/layers.2/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/self_attn/output_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:130:0
  %/model/sem_seg_head/transformer/encoder/layers.3/norm1/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/norm1/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.3/Add_1_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/torch.nn.modules.normalization.LayerNorm::norm1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.3/linear1/MatMul_output_0 : Float(*, *, 1024, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/linear1/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.3/norm1/LayerNormalization_output_0, %onnx::MatMul_7106), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/linear1/Add_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/linear1/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias, %/model/sem_seg_head/transformer/encoder/layers.3/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/Relu_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/Relu"](%/model/sem_seg_head/transformer/encoder/layers.3/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/transformer/encoder/layers.3/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/linear2/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.3/Relu_output_0, %onnx::MatMul_7107), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/linear2/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/linear2/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias, %/model/sem_seg_head/transformer/encoder/layers.3/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.3/Add_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/Add_2"](%/model/sem_seg_head/transformer/encoder/layers.3/norm1/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.3/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:123:0
  %/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.3/Add_2_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.3/torch.nn.modules.normalization.LayerNorm::norm2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.4/Add_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/Add"](%/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:119:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape"](%/model/sem_seg_head/transformer/encoder/layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_1"](%/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_2"](%/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/value_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/value_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization_output_0, %onnx::MatMul_7108), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/value_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/value_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/value_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Cast_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Cast"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Where_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Where"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Cast_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/value_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %onnx::Unsqueeze_2490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2490), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_2_output_0, %onnx::Unsqueeze_2492), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Where_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 192, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/sampling_offsets/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.4/Add_output_0, %onnx::MatMul_7111), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/sampling_offsets/Add_output_0 : Float(*, *, 192, strides=[8257536, 192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/sampling_offsets/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/sampling_offsets/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2503), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_output_0, %onnx::Unsqueeze_2505), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_1_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/sampling_offsets/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/attention_weights/MatMul_output_0 : Float(*, *, 96, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/attention_weights/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.4/Add_output_0, %onnx::MatMul_7116), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/attention_weights/Add_output_0 : Float(*, *, 96, strides=[4128768, 96, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/attention_weights/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/attention_weights/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2520 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2520), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_output_0, %onnx::Unsqueeze_2522), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_2_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/attention_weights/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Softmax_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Softmax"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %onnx::Unsqueeze_2531 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2531), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2533 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_output_0, %onnx::Unsqueeze_2533), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_3_output_0 : Float(*, *, 8, 3, 4, strides=[4128768, 96, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Softmax_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_15_output_0 : Float(1, 1, 1, 3, 1, 2, strides=[6, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,1,1,1,.,.) =    64  32  (1,1,1,2,.,.) =    128   64  (1,1,1,3,.,.) =    256  128 [ CUDAFloatType{1,1,1,3,1,2} ], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Div_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Div"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Add_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_5"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_5"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_6"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_7"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_7"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_8"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_8"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split_output_1 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split_output_2 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Split[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_output_0, %onnx::Split_1667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_22_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_23_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Sub_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Sub"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_output_0 : Float(*, 8, 32, *, strides=[524288, 65536, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %onnx::Unsqueeze_2573 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_8"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2573), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_9"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2575), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[65536, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_9_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_9"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Sub_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_1_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %onnx::Unsqueeze_2585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_10"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2585), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_11"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2587), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_12"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2589), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_5"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2594 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_13"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2594), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2596 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_14"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2596), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2598 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_15"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2598), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_6"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_14_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2603 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_16"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2603), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2605 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_17"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2605), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2607 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_18"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2607), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_7"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_17_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_5"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_2_output_0 : Float(*, 8, 32, *, strides=[2097152, 262144, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split_output_1), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2615 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_19"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2615), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2617 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_20"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2617), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_8"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_20_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_6"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_10_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_10"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Sub_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_3_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_7_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_7"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_1_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_1"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_4_output_0 : Float(*, 8, 32, *, strides=[8388608, 1048576, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Split_output_2), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_21"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2630), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_22"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2632), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_9"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_31_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_8_output_0 : Float(*, *, *, *, strides=[1048576, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_8"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_11_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_11"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Sub_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_5_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_5"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_9_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_9"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_2_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_23_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_23"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_24_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_24"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_25_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_25"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/GridSample_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_10_output_0 : Float(*, *, *, 3, *, strides=[16515072, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_10"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_23_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_9_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_9"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Slice_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Slice"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Shape_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_37_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_38_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_11"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Slice_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_10_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_10"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_6_output_0 : Float(*, 8, *, 3, 4, strides=[4128768, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_6"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_2"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %onnx::Unsqueeze_2661 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_26"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2661), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_27"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2665), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2667 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_28"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_2_output_0, %onnx::Unsqueeze_2667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_12_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_12"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_26_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Constant_40_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_11_output_0 : Float(*, *, *, *, strides=[516096, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_11"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_3_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_3"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/ReduceSum_output_0 : Float(*, *, *, strides=[1376256, 43008, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/ReduceSum"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_3_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_4"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %onnx::Unsqueeze_2674 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_29"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_3_output_0, %onnx::Unsqueeze_2674), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2676 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_30"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Mul_4_output_0, %onnx::Unsqueeze_2676), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_31"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2678), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_13"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_30_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_12_output_0 : Float(*, *, *, strides=[11010048, 43008, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_12"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/ReduceSum_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_7_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_7"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Reshape_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:114:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/output_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.4/self_attn/Transpose_7_output_0, %onnx::MatMul_7132), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/self_attn/output_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/output_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/Add_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/Add_1"](%/model/sem_seg_head/transformer/encoder/layers.3/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/self_attn/output_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:130:0
  %/model/sem_seg_head/transformer/encoder/layers.4/norm1/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/norm1/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.4/Add_1_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/torch.nn.modules.normalization.LayerNorm::norm1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.4/linear1/MatMul_output_0 : Float(*, *, 1024, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/linear1/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.4/norm1/LayerNormalization_output_0, %onnx::MatMul_7133), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/linear1/Add_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/linear1/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias, %/model/sem_seg_head/transformer/encoder/layers.4/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/Relu_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/Relu"](%/model/sem_seg_head/transformer/encoder/layers.4/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/transformer/encoder/layers.4/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/linear2/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.4/Relu_output_0, %onnx::MatMul_7134), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/linear2/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/linear2/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias, %/model/sem_seg_head/transformer/encoder/layers.4/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.4/Add_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/Add_2"](%/model/sem_seg_head/transformer/encoder/layers.4/norm1/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.4/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:123:0
  %/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.4/Add_2_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.4/torch.nn.modules.normalization.LayerNorm::norm2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.5/Add_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/Add"](%/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:119:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape"](%/model/sem_seg_head/transformer/encoder/layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_1"](%/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_2"](%/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:95:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/value_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/value_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization_output_0, %onnx::MatMul_7135), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/value_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/value_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/value_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::value_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Cast_output_0 : Bool(*, *, 1, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Cast"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Where_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Where"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Cast_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/value_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:100:0
  %onnx::Unsqueeze_2713 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2713), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2715 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_2_output_0, %onnx::Unsqueeze_2715), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Where_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:101:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/sampling_offsets/MatMul_output_0 : Float(*, *, 192, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/sampling_offsets/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.5/Add_output_0, %onnx::MatMul_7138), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/sampling_offsets/Add_output_0 : Float(*, *, 192, strides=[8257536, 192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/sampling_offsets/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/sampling_offsets/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::sampling_offsets # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2726 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2726), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2728 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_output_0, %onnx::Unsqueeze_2728), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_1_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/sampling_offsets/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:102:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/attention_weights/MatMul_output_0 : Float(*, *, 96, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/attention_weights/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.5/Add_output_0, %onnx::MatMul_7143), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/attention_weights/Add_output_0 : Float(*, *, 96, strides=[4128768, 96, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/attention_weights/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/attention_weights/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::attention_weights # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %onnx::Unsqueeze_2743 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2743), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2745 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_5"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_output_0, %onnx::Unsqueeze_2745), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_2_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/attention_weights/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:103:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Softmax_output_0 : Float(*, *, 8, 12, strides=[4128768, 96, 12, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Softmax"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %onnx::Unsqueeze_2754 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_6"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_1_output_0, %onnx::Unsqueeze_2754), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2756 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_7"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_output_0, %onnx::Unsqueeze_2756), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_3_output_0 : Float(*, *, 8, 3, 4, strides=[4128768, 96, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Softmax_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:104:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_15_output_0 : Float(1, 1, 1, 3, 1, 2, strides=[6, 6, 6, 2, 2, 1], requires_grad=0, device=cuda:0) = onnx::Constant[value=(1,1,1,1,.,.) =    64  32  (1,1,1,2,.,.) =    128   64  (1,1,1,3,.,.) =    256  128 [ CUDAFloatType{1,1,1,3,1,2} ], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Div_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Div"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Add_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Add"](%/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/modules/ms_deform_attn.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_17_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_5"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_5"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:79:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_6"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_7"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_7"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_8"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_8"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:80:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split_output_0 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split_output_1 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0), %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split_output_2 : Float(*, *, 8, 32, strides=[11010048, 256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Split[axis=1, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_output_0, %onnx::Split_1667), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_22_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Add_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_23_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Sub_output_0 : Float(*, *, 8, 3, 4, 2, strides=[8257536, 192, 24, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Sub"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:86:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_output_0 : Float(*, 8, 32, *, strides=[524288, 65536, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %onnx::Unsqueeze_2796 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_8"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2796), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_9"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2798), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_4_output_0 : Float(*, *, *, *, strides=[65536, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_9_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_9"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Sub_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_1_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %onnx::Unsqueeze_2808 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_10"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2808), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2810 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_11"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2810), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_12"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2812), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_5"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_13"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2817), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2819 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_14"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2819), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2821 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_15"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2821), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_6"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_13_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_14_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_15_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %onnx::Unsqueeze_2826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_16"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2826), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_17"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2828), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_18"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_8_output_0, %onnx::Unsqueeze_2830), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_7"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_16_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_17_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_18_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_5_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_5"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_2_output_0 : Float(*, 8, 32, *, strides=[2097152, 262144, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split_output_1), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_19"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2838), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2840 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_20"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2840), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_8"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_19_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_20_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_6"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_10_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_10"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Sub_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_3_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_7_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_7"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_3_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_1_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_1"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_4_output_0 : Float(*, 8, 32, *, strides=[8388608, 1048576, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Split_output_2), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:92:0
  %onnx::Unsqueeze_2853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_21"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2853), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_22"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_5_output_0, %onnx::Unsqueeze_2855), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_9"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_21_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_22_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_31_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_8_output_0 : Float(*, *, *, *, strides=[1048576, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_8"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:94:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_11_output_0 : Float(*, *, 8, 4, 2, strides=[8257536, 192, 24, 2, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_11"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Sub_output_0, %/model/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:96:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_5_output_0 : Float(*, 8, *, 4, 2, strides=[2752512, 344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_5"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:97:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_9_output_0 : Float(*, *, *, *, strides=[344064, 8, 2, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_9"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_5_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:98:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_2_output_0 : Float(*, *, *, *, strides=[5505024, 172032, 4, 1], requires_grad=0, device=cuda:0) = onnx::GridSample[align_corners=0, mode="bilinear", padding_mode="zeros", onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_8_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4910:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_23_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_23"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_24_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_24"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_25_output_0 : Float(*, *, *, 1, *, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_25"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/GridSample_2_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_10_output_0 : Float(*, *, *, 3, *, strides=[16515072, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_10"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_23_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_24_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:105:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_9_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_9"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Slice_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Slice"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Shape_9_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_37_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_38_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_11"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Slice_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_10_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_10"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:106:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_6_output_0 : Float(*, 8, *, 3, 4, strides=[4128768, 516096, 12, 4, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3, 4], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_6"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:108:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_2"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_7_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %onnx::Unsqueeze_2884 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_26"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_1_output_0, %onnx::Unsqueeze_2884), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2888 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_27"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2888), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2890 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_28"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_2_output_0, %onnx::Unsqueeze_2890), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_12_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_12"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_26_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Constant_40_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_27_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_11_output_0 : Float(*, *, *, *, strides=[516096, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_11"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_6_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:109:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_3_output_0 : Float(*, *, *, *, strides=[16515072, 516096, 12, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_3"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_10_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/ReduceSum_output_0 : Float(*, *, *, strides=[1376256, 43008, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/ReduceSum"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_3_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:111:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_4"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_4_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %onnx::Unsqueeze_2897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_29"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_3_output_0, %onnx::Unsqueeze_2897), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_30"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Mul_4_output_0, %onnx::Unsqueeze_2899), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %onnx::Unsqueeze_2901 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_31"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Gather_6_output_0, %onnx::Unsqueeze_2901), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_13_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_13"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_29_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_30_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_12_output_0 : Float(*, *, *, strides=[11010048, 43008, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_12"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/ReduceSum_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:112:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_7_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_7"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Reshape_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/ops/functions/ms_deform_attn_func.py:114:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/output_proj/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/output_proj/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.5/self_attn/Transpose_7_output_0, %onnx::MatMul_7159), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/output_proj/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/self_attn/output_proj/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/output_proj/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/mask2former.modeling.pixel_decoder.ops.modules.ms_deform_attn.MSDeformAttn::self_attn/torch.nn.modules.linear.Linear::output_proj # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/Add_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/Add_1"](%/model/sem_seg_head/transformer/encoder/layers.4/norm2/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/self_attn/output_proj/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:130:0
  %/model/sem_seg_head/transformer/encoder/layers.5/norm1/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/norm1/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.5/Add_1_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/torch.nn.modules.normalization.LayerNorm::norm1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/transformer/encoder/layers.5/linear1/MatMul_output_0 : Float(*, *, 1024, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/linear1/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.5/norm1/LayerNormalization_output_0, %onnx::MatMul_7160), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/linear1/Add_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/linear1/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias, %/model/sem_seg_head/transformer/encoder/layers.5/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/Relu_output_0 : Float(*, *, 1024, strides=[44040192, 1024, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/Relu"](%/model/sem_seg_head/transformer/encoder/layers.5/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/transformer/encoder/layers.5/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/linear2/MatMul"](%/model/sem_seg_head/transformer/encoder/layers.5/Relu_output_0, %onnx::MatMul_7161), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/linear2/Add_output_0 : Float(*, *, 256, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/linear2/Add"](%model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias, %/model/sem_seg_head/transformer/encoder/layers.5/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/transformer/encoder/layers.5/Add_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/Add_2"](%/model/sem_seg_head/transformer/encoder/layers.5/norm1/LayerNormalization_output_0, %/model/sem_seg_head/transformer/encoder/layers.5/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:123:0
  %/model/sem_seg_head/transformer/encoder/layers.5/norm2/LayerNormalization_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/transformer/encoder/layers.5/norm2/LayerNormalization"](%/model/sem_seg_head/transformer/encoder/layers.5/Add_2_output_0, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight, %model.sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderOnly::transformer/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoder::encoder/mask2former.modeling.pixel_decoder.msdeformattn.MSDeformAttnTransformerEncoderLayer::layers.5/torch.nn.modules.normalization.LayerNorm::norm2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape"](%/model/sem_seg_head/transformer/encoder/layers.5/norm2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:337:0
  %/model/sem_seg_head/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:337:0
  %/model/sem_seg_head/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather"](%/model/sem_seg_head/Shape_output_0, %/model/sem_seg_head/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:337:0
  %/model/sem_seg_head/Constant_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={10240}, onnx_name="/model/sem_seg_head/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:337:0
  %/model/sem_seg_head/Sub_output_0 : Long(requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name="/model/sem_seg_head/Sub"](%/model/sem_seg_head/Gather_output_0, %/model/sem_seg_head/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:337:0
  %/model/sem_seg_head/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze"](%/model/sem_seg_head/Sub_output_0, %/model/sem_seg_head/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2048}, onnx_name="/model/sem_seg_head/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Slice_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/Slice"](%/model/sem_seg_head/transformer/encoder/layers.5/norm2/LayerNormalization_output_0, %/model/sem_seg_head/Constant_3_output_0, %/model/sem_seg_head/Constant_5_output_0, %/model/sem_seg_head/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10240}, onnx_name="/model/sem_seg_head/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Slice_1_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/Slice_1"](%/model/sem_seg_head/transformer/encoder/layers.5/norm2/LayerNormalization_output_0, %/model/sem_seg_head/Constant_5_output_0, %/model/sem_seg_head/Constant_6_output_0, %/model/sem_seg_head/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Add_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name="/model/sem_seg_head/Add"](%/model/sem_seg_head/Constant_6_output_0, %/model/sem_seg_head/Unsqueeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Slice_2_output_0 : Float(*, *, *, strides=[11010048, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/Slice_2"](%/model/sem_seg_head/transformer/encoder/layers.5/norm2/LayerNormalization_output_0, %/model/sem_seg_head/Constant_6_output_0, %/model/sem_seg_head/Add_output_0, %/model/sem_seg_head/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:983:0
  %/model/sem_seg_head/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_1"](%/model/sem_seg_head/Slice_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_1"](%/model/sem_seg_head/Shape_1_output_0, %/model/sem_seg_head/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_2"](%/model/sem_seg_head/Slice_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_2"](%/model/sem_seg_head/Shape_2_output_0, %/model/sem_seg_head/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %onnx::Unsqueeze_2948 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_1"](%/model/sem_seg_head/Gather_1_output_0, %onnx::Unsqueeze_2948), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name="/model/sem_seg_head/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %onnx::Unsqueeze_2954 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_2"](%/model/sem_seg_head/Gather_2_output_0, %onnx::Unsqueeze_2954), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/Concat"](%/model/sem_seg_head/Unsqueeze_1_output_0, %/model/sem_seg_head/Constant_9_output_0, %/model/sem_seg_head/Constant_10_output_0, %/model/sem_seg_head/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:93:0
  %/model/sem_seg_head/Reshape_output_0 : Float(*, 32, 64, *, strides=[524288, 16384, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/Reshape"](%/model/sem_seg_head/Slice_output_0, %/model/sem_seg_head/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:93:0
  %/model/sem_seg_head/Transpose_output_0 : Float(*, *, 32, 64, strides=[524288, 1, 16384, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name="/model/sem_seg_head/Transpose"](%/model/sem_seg_head/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:258:0
  %/model/sem_seg_head/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_3"](%/model/sem_seg_head/Slice_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_3"](%/model/sem_seg_head/Shape_3_output_0, %/model/sem_seg_head/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_4"](%/model/sem_seg_head/Slice_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_4"](%/model/sem_seg_head/Shape_4_output_0, %/model/sem_seg_head/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %onnx::Unsqueeze_2965 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_3"](%/model/sem_seg_head/Gather_3_output_0, %onnx::Unsqueeze_2965), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name="/model/sem_seg_head/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %onnx::Unsqueeze_2971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_4"](%/model/sem_seg_head/Gather_4_output_0, %onnx::Unsqueeze_2971), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/Concat_1"](%/model/sem_seg_head/Unsqueeze_3_output_0, %/model/sem_seg_head/Constant_13_output_0, %/model/sem_seg_head/Constant_14_output_0, %/model/sem_seg_head/Unsqueeze_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:93:0
  %/model/sem_seg_head/Reshape_1_output_0 : Float(*, 64, 128, *, strides=[2097152, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/Reshape_1"](%/model/sem_seg_head/Slice_1_output_0, %/model/sem_seg_head/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:93:0
  %/model/sem_seg_head/Transpose_1_output_0 : Float(*, *, 64, 128, strides=[2097152, 1, 32768, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name="/model/sem_seg_head/Transpose_1"](%/model/sem_seg_head/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:258:0
  %/model/sem_seg_head/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_5"](%/model/sem_seg_head/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_5"](%/model/sem_seg_head/Shape_5_output_0, %/model/sem_seg_head/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Shape_6_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_6"](%/model/sem_seg_head/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %/model/sem_seg_head/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_6"](%/model/sem_seg_head/Shape_6_output_0, %/model/sem_seg_head/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:90:0
  %onnx::Unsqueeze_2982 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_5"](%/model/sem_seg_head/Gather_5_output_0, %onnx::Unsqueeze_2982), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={128}, onnx_name="/model/sem_seg_head/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={256}, onnx_name="/model/sem_seg_head/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %onnx::Unsqueeze_2988 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_6"](%/model/sem_seg_head/Gather_6_output_0, %onnx::Unsqueeze_2988), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/Concat_2"](%/model/sem_seg_head/Unsqueeze_5_output_0, %/model/sem_seg_head/Constant_17_output_0, %/model/sem_seg_head/Constant_18_output_0, %/model/sem_seg_head/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:93:0
  %/model/sem_seg_head/Reshape_2_output_0 : Float(*, 128, 256, *, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/Reshape_2"](%/model/sem_seg_head/Slice_2_output_0, %/model/sem_seg_head/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:93:0
  %/model/sem_seg_head/Transpose_2_output_0 : Float(*, *, 128, 256, strides=[8388608, 1, 65536, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name="/model/sem_seg_head/Transpose_2"](%/model/sem_seg_head/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/einops/_backends.py:258:0
  %/model/sem_seg_head/Cast_3_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/Cast_3"](%/model/backbone/res2/res2.2/Relu_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:352:0
  %/model/sem_seg_head/adapter_1/Conv_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/sem_seg_head/adapter_1/Conv"](%/model/sem_seg_head/Cast_3_output_0, %model.sem_seg_head.pixel_decoder.adapter_1.weight), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/sem_seg_head/adapter_1/norm/Constant_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=  0  32  -1 [ CPULongType{3} ], onnx_name="/model/sem_seg_head/adapter_1/norm/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Reshape_output_0 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/adapter_1/norm/Reshape"](%/model/sem_seg_head/adapter_1/Conv_output_0, %/model/sem_seg_head/adapter_1/norm/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Constant_1_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/adapter_1/norm/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Constant_2_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/adapter_1/norm/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/InstanceNormalization_output_0 : Float(*, *, *, device=cpu) = onnx::InstanceNormalization[epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/adapter_1/norm/InstanceNormalization"](%/model/sem_seg_head/adapter_1/norm/Reshape_output_0, %/model/sem_seg_head/adapter_1/norm/Constant_1_output_0, %/model/sem_seg_head/adapter_1/norm/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/adapter_1/norm/Shape"](%/model/sem_seg_head/adapter_1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Reshape_1_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/adapter_1/norm/Reshape_1"](%/model/sem_seg_head/adapter_1/norm/InstanceNormalization_output_0, %/model/sem_seg_head/adapter_1/norm/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Mul_output_0 : Float(1, 256, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/adapter_1/norm/Mul"](%/model/sem_seg_head/adapter_1/norm/Reshape_1_output_0, %onnx::Mul_7172), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/adapter_1/norm/Add_output_0 : Float(1, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/adapter_1/norm/Add"](%/model/sem_seg_head/adapter_1/norm/Mul_output_0, %onnx::Add_7173), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::adapter_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_7"](%/model/sem_seg_head/adapter_1/norm/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %/model/sem_seg_head/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %/model/sem_seg_head/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_7"](%/model/sem_seg_head/Shape_7_output_0, %/model/sem_seg_head/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %/model/sem_seg_head/Shape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_8"](%/model/sem_seg_head/adapter_1/norm/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %/model/sem_seg_head/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %/model/sem_seg_head/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/Gather_8"](%/model/sem_seg_head/Shape_8_output_0, %/model/sem_seg_head/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %onnx::Unsqueeze_3014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_7"](%/model/sem_seg_head/Gather_7_output_0, %onnx::Unsqueeze_3014), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %onnx::Unsqueeze_3016 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/Unsqueeze_8"](%/model/sem_seg_head/Gather_8_output_0, %onnx::Unsqueeze_3016), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head
  %/model/sem_seg_head/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/Concat_3"](%/model/sem_seg_head/Unsqueeze_7_output_0, %/model/sem_seg_head/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/Shape_9"](%/model/sem_seg_head/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Slice_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/Slice_3"](%/model/sem_seg_head/Shape_9_output_0, %/model/sem_seg_head/Constant_22_output_0, %/model/sem_seg_head/Constant_23_output_0, %/model/sem_seg_head/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Cast_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/Cast_4"](%/model/sem_seg_head/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/Concat_4"](%/model/sem_seg_head/Slice_3_output_0, %/model/sem_seg_head/Cast_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_3026 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_3027 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Resize_output_0 : Float(*, *, *, *, strides=[33554432, 1, 131072, 256], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/Resize"](%/model/sem_seg_head/Transpose_2_output_0, %onnx::Resize_3026, %onnx::Resize_3027, %/model/sem_seg_head/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/Add_1_output_0 : Float(*, *, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/Add_1"](%/model/sem_seg_head/adapter_1/norm/Add_output_0, %/model/sem_seg_head/Resize_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py:357:0
  %/model/sem_seg_head/layer_1/Conv_output_0 : Float(*, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name="/model/sem_seg_head/layer_1/Conv"](%/model/sem_seg_head/Add_1_output_0, %model.sem_seg_head.pixel_decoder.layer_1.weight), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/sem_seg_head/layer_1/norm/Constant_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=  0  32  -1 [ CPULongType{3} ], onnx_name="/model/sem_seg_head/layer_1/norm/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Reshape_output_0 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/layer_1/norm/Reshape"](%/model/sem_seg_head/layer_1/Conv_output_0, %/model/sem_seg_head/layer_1/norm/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Constant_1_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/layer_1/norm/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Constant_2_output_0 : Float(32, strides=[1], device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/layer_1/norm/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/InstanceNormalization_output_0 : Float(*, *, *, device=cpu) = onnx::InstanceNormalization[epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/layer_1/norm/InstanceNormalization"](%/model/sem_seg_head/layer_1/norm/Reshape_output_0, %/model/sem_seg_head/layer_1/norm/Constant_1_output_0, %/model/sem_seg_head/layer_1/norm/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/layer_1/norm/Shape"](%/model/sem_seg_head/layer_1/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Reshape_1_output_0 : Float(*, 256, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/layer_1/norm/Reshape_1"](%/model/sem_seg_head/layer_1/norm/InstanceNormalization_output_0, %/model/sem_seg_head/layer_1/norm/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Mul_output_0 : Float(*, 256, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/layer_1/norm/Mul"](%/model/sem_seg_head/layer_1/norm/Reshape_1_output_0, %onnx::Mul_7174), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/norm/Add_output_0 : Float(*, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/layer_1/norm/Add"](%/model/sem_seg_head/layer_1/norm/Mul_output_0, %onnx::Add_7175), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1/torch.nn.modules.normalization.GroupNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2955:0
  %/model/sem_seg_head/layer_1/Relu_output_0 : Float(*, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/layer_1/Relu"](%/model/sem_seg_head/layer_1/norm/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::layer_1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/mask_features/Conv_output_0 : Float(*, 256, *, *, strides=[33554432, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name="/model/sem_seg_head/mask_features/Conv"](%/model/sem_seg_head/layer_1/Relu_output_0, %model.sem_seg_head.pixel_decoder.mask_features.weight, %model.sem_seg_head.pixel_decoder.mask_features.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/detectron2.layers.wrappers.Conv2d::mask_features # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/layers/wrappers.py:142:0
  %/model/sem_seg_head/predictor/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape"](%/model/sem_seg_head/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather"](%/model/sem_seg_head/predictor/Shape_output_0, %/model/sem_seg_head/predictor/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_1"](%/model/sem_seg_head/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_1"](%/model/sem_seg_head/predictor/Shape_1_output_0, %/model/sem_seg_head/predictor/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/pe_layer/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer/Shape"](%/model/sem_seg_head/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer/Gather"](%/model/sem_seg_head/predictor/pe_layer/Shape_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %onnx::Unsqueeze_3055 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze"](%/model/sem_seg_head/predictor/pe_layer/Gather_output_0, %onnx::Unsqueeze_3055), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_3057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_1"](%/model/sem_seg_head/predictor/Gather_output_0, %onnx::Unsqueeze_3057), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_3059 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_2"](%/model/sem_seg_head/predictor/Gather_1_output_0, %onnx::Unsqueeze_3059), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/predictor/pe_layer/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer/Concat"](%/model/sem_seg_head/predictor/pe_layer/Unsqueeze_output_0, %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer/ConstantOfShape_output_0 : Bool(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/ConstantOfShape"](%/model/sem_seg_head/predictor/pe_layer/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer/Not_output_0 : Bool(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/pe_layer/Not"](%/model/sem_seg_head/predictor/pe_layer/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:32:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_1_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer/Cast_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/predictor/pe_layer/Cast"](%/model/sem_seg_head/predictor/pe_layer/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer/CumSum_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/predictor/pe_layer/CumSum"](%/model/sem_seg_head/predictor/pe_layer/Cast_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_2_output_0 : Int(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer/Cast_1_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/predictor/pe_layer/Cast_1"](%/model/sem_seg_head/predictor/pe_layer/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer/CumSum_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/predictor/pe_layer/CumSum_1"](%/model/sem_seg_head/predictor/pe_layer/Cast_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice"](%/model/sem_seg_head/predictor/pe_layer/CumSum_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_4_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_5_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_3_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Add_output_0 : Float(*, *, *, strides=[64, 64, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/pe_layer/Add"](%/model/sem_seg_head/predictor/pe_layer/Slice_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Div_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer/Div"](%/model/sem_seg_head/predictor/pe_layer/CumSum_output_0, %/model/sem_seg_head/predictor/pe_layer/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Mul_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/pe_layer/Mul"](%/model/sem_seg_head/predictor/pe_layer/Div_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_1"](%/model/sem_seg_head/predictor/pe_layer/CumSum_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_10_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_11_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_9_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Add_1_output_0 : Float(*, *, *, strides=[32, 1, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/pe_layer/Add_1"](%/model/sem_seg_head/predictor/pe_layer/Slice_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Div_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer/Div_1"](%/model/sem_seg_head/predictor/pe_layer/CumSum_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Mul_1_output_0 : Float(*, *, *, strides=[2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/pe_layer/Mul_1"](%/model/sem_seg_head/predictor/pe_layer/Div_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_3_output_0 : Float(*, *, *, 1, strides=[2048, 64, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_3"](%/model/sem_seg_head/predictor/pe_layer/Mul_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_16_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer/Div_2_output_0 : Float(*, *, *, 128, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer/Div_2"](%/model/sem_seg_head/predictor/pe_layer/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_4_output_0 : Float(*, *, *, 1, strides=[2048, 64, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_4"](%/model/sem_seg_head/predictor/pe_layer/Mul_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_18_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer/Div_3_output_0 : Float(*, *, *, 128, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer/Div_3"](%/model/sem_seg_head/predictor/pe_layer/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_2_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_2"](%/model/sem_seg_head/predictor/pe_layer/Div_2_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_20_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_21_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_19_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Sin_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/predictor/pe_layer/Sin"](%/model/sem_seg_head/predictor/pe_layer/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_3_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_3"](%/model/sem_seg_head/predictor/pe_layer/Div_2_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_24_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_25_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_23_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Cos_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/predictor/pe_layer/Cos"](%/model/sem_seg_head/predictor/pe_layer/Slice_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_5_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_5"](%/model/sem_seg_head/predictor/pe_layer/Sin_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_6_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_6"](%/model/sem_seg_head/predictor/pe_layer/Cos_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer/Concat_1_output_0 : Float(*, *, *, 64, 2, strides=[262144, 8192, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/predictor/pe_layer/Concat_1"](%/model/sem_seg_head/predictor/pe_layer/Unsqueeze_5_output_0, %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer/Shape_1_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer/Shape_1"](%/model/sem_seg_head/predictor/pe_layer/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_4"](%/model/sem_seg_head/predictor/pe_layer/Shape_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_30_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_31_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer/Concat_2"](%/model/sem_seg_head/predictor/pe_layer/Slice_4_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Reshape_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/pe_layer/Reshape"](%/model/sem_seg_head/predictor/pe_layer/Concat_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_5_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_5"](%/model/sem_seg_head/predictor/pe_layer/Div_3_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_34_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_35_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_33_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Sin_1_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/predictor/pe_layer/Sin_1"](%/model/sem_seg_head/predictor/pe_layer/Slice_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_6_output_0 : Float(*, *, *, 64, strides=[262144, 8192, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_6"](%/model/sem_seg_head/predictor/pe_layer/Div_3_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_38_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_39_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_37_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_40_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Cos_1_output_0 : Float(*, *, *, 64, strides=[131072, 4096, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/predictor/pe_layer/Cos_1"](%/model/sem_seg_head/predictor/pe_layer/Slice_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_7_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_7"](%/model/sem_seg_head/predictor/pe_layer/Sin_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_8_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer/Unsqueeze_8"](%/model/sem_seg_head/predictor/pe_layer/Cos_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer/Concat_3_output_0 : Float(*, *, *, 64, 2, strides=[262144, 8192, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/predictor/pe_layer/Concat_3"](%/model/sem_seg_head/predictor/pe_layer/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/pe_layer/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer/Shape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer/Shape_2"](%/model/sem_seg_head/predictor/pe_layer/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Slice_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer/Slice_7"](%/model/sem_seg_head/predictor/pe_layer/Shape_2_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_44_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_45_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_43_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer/Concat_4"](%/model/sem_seg_head/predictor/pe_layer/Slice_7_output_0, %/model/sem_seg_head/predictor/pe_layer/Constant_46_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Reshape_1_output_0 : Float(*, *, *, *, strides=[262144, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/pe_layer/Reshape_1"](%/model/sem_seg_head/predictor/pe_layer/Concat_3_output_0, %/model/sem_seg_head/predictor/pe_layer/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer/Concat_5_output_0 : Float(*, *, *, *, strides=[524288, 16384, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/predictor/pe_layer/Concat_5"](%/model/sem_seg_head/predictor/pe_layer/Reshape_1_output_0, %/model/sem_seg_head/predictor/pe_layer/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/predictor/pe_layer/Transpose_output_0 : Float(*, *, *, *, strides=[524288, 1, 16384, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name="/model/sem_seg_head/predictor/pe_layer/Transpose"](%/model/sem_seg_head/predictor/pe_layer/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/predictor/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_2"](%/model/sem_seg_head/predictor/pe_layer/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice"](%/model/sem_seg_head/predictor/Shape_2_output_0, %/model/sem_seg_head/predictor/Constant_3_output_0, %/model/sem_seg_head/predictor/Constant_4_output_0, %/model/sem_seg_head/predictor/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat"](%/model/sem_seg_head/predictor/Slice_output_0, %/model/sem_seg_head/predictor/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Reshape_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape"](%/model/sem_seg_head/predictor/pe_layer/Transpose_output_0, %/model/sem_seg_head/predictor/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_3"](%/model/sem_seg_head/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Slice_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_1"](%/model/sem_seg_head/predictor/Shape_3_output_0, %/model/sem_seg_head/predictor/Constant_7_output_0, %/model/sem_seg_head/predictor/Constant_8_output_0, %/model/sem_seg_head/predictor/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_1"](%/model/sem_seg_head/predictor/Slice_1_output_0, %/model/sem_seg_head/predictor/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Reshape_1_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_1"](%/model/sem_seg_head/Transpose_output_0, %/model/sem_seg_head/predictor/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Add_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/Add"](%/model/sem_seg_head/predictor/Reshape_1_output_0, %onnx::Add_7202), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Transpose_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name="/model/sem_seg_head/predictor/Transpose"](%/model/sem_seg_head/predictor/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:380:0
  %/model/sem_seg_head/predictor/Transpose_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name="/model/sem_seg_head/predictor/Transpose_1"](%/model/sem_seg_head/predictor/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:381:0
  %/model/sem_seg_head/predictor/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_4"](%/model/sem_seg_head/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Constant_10_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_2"](%/model/sem_seg_head/predictor/Shape_4_output_0, %/model/sem_seg_head/predictor/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_5"](%/model/sem_seg_head/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_3"](%/model/sem_seg_head/predictor/Shape_5_output_0, %/model/sem_seg_head/predictor/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/pe_layer_1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Shape"](%/model/sem_seg_head/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_1/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Gather"](%/model/sem_seg_head/predictor/pe_layer_1/Shape_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %onnx::Unsqueeze_3207 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze"](%/model/sem_seg_head/predictor/pe_layer_1/Gather_output_0, %onnx::Unsqueeze_3207), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_3209 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_1"](%/model/sem_seg_head/predictor/Gather_2_output_0, %onnx::Unsqueeze_3209), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_3211 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_2"](%/model/sem_seg_head/predictor/Gather_3_output_0, %onnx::Unsqueeze_3211), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/predictor/pe_layer_1/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Concat"](%/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_1/ConstantOfShape_output_0 : Bool(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/ConstantOfShape"](%/model/sem_seg_head/predictor/pe_layer_1/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_1/Not_output_0 : Bool(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Not"](%/model/sem_seg_head/predictor/pe_layer_1/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:32:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_1_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer_1/Cast_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Cast"](%/model/sem_seg_head/predictor/pe_layer_1/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer_1/CumSum_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/CumSum"](%/model/sem_seg_head/predictor/pe_layer_1/Cast_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_2_output_0 : Int(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer_1/Cast_1_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Cast_1"](%/model/sem_seg_head/predictor/pe_layer_1/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer_1/CumSum_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/CumSum_1"](%/model/sem_seg_head/predictor/pe_layer_1/Cast_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice"](%/model/sem_seg_head/predictor/pe_layer_1/CumSum_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_4_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_5_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_3_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Add_output_0 : Float(*, *, *, strides=[128, 128, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Add"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Div_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Div"](%/model/sem_seg_head/predictor/pe_layer_1/CumSum_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Mul_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Mul"](%/model/sem_seg_head/predictor/pe_layer_1/Div_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_1"](%/model/sem_seg_head/predictor/pe_layer_1/CumSum_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_10_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_11_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_9_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Add_1_output_0 : Float(*, *, *, strides=[64, 1, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Add_1"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Div_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Div_1"](%/model/sem_seg_head/predictor/pe_layer_1/CumSum_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Mul_1_output_0 : Float(*, *, *, strides=[8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Mul_1"](%/model/sem_seg_head/predictor/pe_layer_1/Div_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_3_output_0 : Float(*, *, *, 1, strides=[8192, 128, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_3"](%/model/sem_seg_head/predictor/pe_layer_1/Mul_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_16_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_1/Div_2_output_0 : Float(*, *, *, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Div_2"](%/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_4_output_0 : Float(*, *, *, 1, strides=[8192, 128, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_4"](%/model/sem_seg_head/predictor/pe_layer_1/Mul_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_18_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_1/Div_3_output_0 : Float(*, *, *, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Div_3"](%/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_2_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_2"](%/model/sem_seg_head/predictor/pe_layer_1/Div_2_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_20_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_21_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_19_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Sin_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Sin"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_3_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_3"](%/model/sem_seg_head/predictor/pe_layer_1/Div_2_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_24_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_25_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_23_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Cos_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Cos"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_5_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_5"](%/model/sem_seg_head/predictor/pe_layer_1/Sin_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_6_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_6"](%/model/sem_seg_head/predictor/pe_layer_1/Cos_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_1/Concat_1_output_0 : Float(*, *, *, 64, 2, strides=[1048576, 16384, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Concat_1"](%/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_5_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_1/Shape_1_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Shape_1"](%/model/sem_seg_head/predictor/pe_layer_1/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_4"](%/model/sem_seg_head/predictor/pe_layer_1/Shape_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_30_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_31_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Concat_2"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_4_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Reshape_output_0 : Float(*, *, *, *, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Reshape"](%/model/sem_seg_head/predictor/pe_layer_1/Concat_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_5_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_5"](%/model/sem_seg_head/predictor/pe_layer_1/Div_3_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_34_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_35_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_33_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Sin_1_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Sin_1"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_6_output_0 : Float(*, *, *, 64, strides=[1048576, 16384, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_6"](%/model/sem_seg_head/predictor/pe_layer_1/Div_3_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_38_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_39_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_37_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_40_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Cos_1_output_0 : Float(*, *, *, 64, strides=[524288, 8192, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Cos_1"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_7_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_7"](%/model/sem_seg_head/predictor/pe_layer_1/Sin_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_8_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_8"](%/model/sem_seg_head/predictor/pe_layer_1/Cos_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_1/Concat_3_output_0 : Float(*, *, *, 64, 2, strides=[1048576, 16384, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Concat_3"](%/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_1/Shape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Shape_2"](%/model/sem_seg_head/predictor/pe_layer_1/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Slice_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Slice_7"](%/model/sem_seg_head/predictor/pe_layer_1/Shape_2_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_44_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_45_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_43_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Concat_4"](%/model/sem_seg_head/predictor/pe_layer_1/Slice_7_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Constant_46_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Reshape_1_output_0 : Float(*, *, *, *, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Reshape_1"](%/model/sem_seg_head/predictor/pe_layer_1/Concat_3_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_1/Concat_5_output_0 : Float(*, *, *, *, strides=[2097152, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Concat_5"](%/model/sem_seg_head/predictor/pe_layer_1/Reshape_1_output_0, %/model/sem_seg_head/predictor/pe_layer_1/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/predictor/pe_layer_1/Transpose_output_0 : Float(*, *, *, *, strides=[2097152, 1, 32768, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name="/model/sem_seg_head/predictor/pe_layer_1/Transpose"](%/model/sem_seg_head/predictor/pe_layer_1/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/predictor/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_6"](%/model/sem_seg_head/predictor/pe_layer_1/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Slice_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_2"](%/model/sem_seg_head/predictor/Shape_6_output_0, %/model/sem_seg_head/predictor/Constant_13_output_0, %/model/sem_seg_head/predictor/Constant_14_output_0, %/model/sem_seg_head/predictor/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_2"](%/model/sem_seg_head/predictor/Slice_2_output_0, %/model/sem_seg_head/predictor/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Reshape_2_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_2"](%/model/sem_seg_head/predictor/pe_layer_1/Transpose_output_0, %/model/sem_seg_head/predictor/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_7"](%/model/sem_seg_head/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Slice_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_3"](%/model/sem_seg_head/predictor/Shape_7_output_0, %/model/sem_seg_head/predictor/Constant_17_output_0, %/model/sem_seg_head/predictor/Constant_18_output_0, %/model/sem_seg_head/predictor/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Concat_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_3"](%/model/sem_seg_head/predictor/Slice_3_output_0, %/model/sem_seg_head/predictor/Constant_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Reshape_3_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_3"](%/model/sem_seg_head/Transpose_1_output_0, %/model/sem_seg_head/predictor/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Add_1_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/Add_1"](%/model/sem_seg_head/predictor/Reshape_3_output_0, %onnx::Add_7229), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Transpose_2_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name="/model/sem_seg_head/predictor/Transpose_2"](%/model/sem_seg_head/predictor/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:380:0
  %/model/sem_seg_head/predictor/Transpose_3_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name="/model/sem_seg_head/predictor/Transpose_3"](%/model/sem_seg_head/predictor/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:381:0
  %/model/sem_seg_head/predictor/Shape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_8"](%/model/sem_seg_head/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_4"](%/model/sem_seg_head/predictor/Shape_8_output_0, %/model/sem_seg_head/predictor/Constant_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_9"](%/model/sem_seg_head/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Constant_21_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_5"](%/model/sem_seg_head/predictor/Shape_9_output_0, %/model/sem_seg_head/predictor/Constant_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:375:0
  %/model/sem_seg_head/predictor/pe_layer_2/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Shape"](%/model/sem_seg_head/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_2/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Gather"](%/model/sem_seg_head/predictor/pe_layer_2/Shape_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %onnx::Unsqueeze_3359 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze"](%/model/sem_seg_head/predictor/pe_layer_2/Gather_output_0, %onnx::Unsqueeze_3359), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_3361 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_1"](%/model/sem_seg_head/predictor/Gather_4_output_0, %onnx::Unsqueeze_3361), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %onnx::Unsqueeze_3363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_2"](%/model/sem_seg_head/predictor/Gather_5_output_0, %onnx::Unsqueeze_3363), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer
  %/model/sem_seg_head/predictor/pe_layer_2/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Concat"](%/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_2/ConstantOfShape_output_0 : Bool(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/ConstantOfShape"](%/model/sem_seg_head/predictor/pe_layer_2/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:31:0
  %/model/sem_seg_head/predictor/pe_layer_2/Not_output_0 : Bool(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Not"](%/model/sem_seg_head/predictor/pe_layer_2/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:32:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_1_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer_2/Cast_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Cast"](%/model/sem_seg_head/predictor/pe_layer_2/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer_2/CumSum_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/CumSum"](%/model/sem_seg_head/predictor/pe_layer_2/Cast_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:33:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_2_output_0 : Int(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer_2/Cast_1_output_0 : Float(*, *, *, device=cpu) = onnx::Cast[to=1, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Cast_1"](%/model/sem_seg_head/predictor/pe_layer_2/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer_2/CumSum_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::CumSum[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/CumSum_1"](%/model/sem_seg_head/predictor/pe_layer_2/Cast_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:34:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice"](%/model/sem_seg_head/predictor/pe_layer_2/CumSum_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_4_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_5_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_3_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Add"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Div_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Div"](%/model/sem_seg_head/predictor/pe_layer_2/CumSum_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Mul_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Mul"](%/model/sem_seg_head/predictor/pe_layer_2/Div_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:37:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_12"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_1"](%/model/sem_seg_head/predictor/pe_layer_2/CumSum_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_10_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_11_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_9_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_13"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Add_1_output_0 : Float(*, *, *, strides=[128, 1, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Add_1"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Div_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Div_1"](%/model/sem_seg_head/predictor/pe_layer_2/CumSum_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={6.28319}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_14"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Mul_1_output_0 : Float(*, *, *, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Mul_1"](%/model/sem_seg_head/predictor/pe_layer_2/Div_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:38:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_15"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_3_output_0 : Float(*, *, *, 1, strides=[32768, 256, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_3"](%/model/sem_seg_head/predictor/pe_layer_2/Mul_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_16_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_16"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_2/Div_2_output_0 : Float(*, *, *, 128, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Div_2"](%/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:43:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_17"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_4_output_0 : Float(*, *, *, 1, strides=[32768, 256, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_4"](%/model/sem_seg_head/predictor/pe_layer_2/Mul_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_18_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_18"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_2/Div_3_output_0 : Float(*, *, *, 128, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Div_3"](%/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:44:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_19"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_20"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_21"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_2_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_2"](%/model/sem_seg_head/predictor/pe_layer_2/Div_2_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_20_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_21_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_19_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Sin_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Sin"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_3_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_3"](%/model/sem_seg_head/predictor/pe_layer_2/Div_2_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_24_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_25_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_23_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Cos_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Cos"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:46:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_5_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_5"](%/model/sem_seg_head/predictor/pe_layer_2/Sin_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_6_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_6"](%/model/sem_seg_head/predictor/pe_layer_2/Cos_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_2/Concat_1_output_0 : Float(*, *, *, 64, 2, strides=[4194304, 32768, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Concat_1"](%/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_5_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:45:0
  %/model/sem_seg_head/predictor/pe_layer_2/Shape_1_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Shape_1"](%/model/sem_seg_head/predictor/pe_layer_2/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_4"](%/model/sem_seg_head/predictor/pe_layer_2/Shape_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_30_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_31_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Concat_2"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_4_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Reshape_output_0 : Float(*, *, *, *, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Reshape"](%/model/sem_seg_head/predictor/pe_layer_2/Concat_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:47:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_5_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_5"](%/model/sem_seg_head/predictor/pe_layer_2/Div_3_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_34_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_35_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_33_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Sin_1_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sin[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Sin_1"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_6_output_0 : Float(*, *, *, 64, strides=[4194304, 32768, 128, 2], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_6"](%/model/sem_seg_head/predictor/pe_layer_2/Div_3_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_38_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_39_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_37_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_40_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Cos_1_output_0 : Float(*, *, *, 64, strides=[2097152, 16384, 64, 1], requires_grad=0, device=cuda:0) = onnx::Cos[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Cos_1"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:49:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_7_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_7"](%/model/sem_seg_head/predictor/pe_layer_2/Sin_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_8_output_0 : Float(*, *, *, 64, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_8"](%/model/sem_seg_head/predictor/pe_layer_2/Cos_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_2/Concat_3_output_0 : Float(*, *, *, 64, 2, strides=[4194304, 32768, 128, 2, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=4, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Concat_3"](%/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:48:0
  %/model/sem_seg_head/predictor/pe_layer_2/Shape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Shape_2"](%/model/sem_seg_head/predictor/pe_layer_2/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Slice_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Slice_7"](%/model/sem_seg_head/predictor/pe_layer_2/Shape_2_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_44_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_45_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_43_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Concat_4"](%/model/sem_seg_head/predictor/pe_layer_2/Slice_7_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Constant_46_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Reshape_1_output_0 : Float(*, *, *, *, strides=[4194304, 32768, 128, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Reshape_1"](%/model/sem_seg_head/predictor/pe_layer_2/Concat_3_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:50:0
  %/model/sem_seg_head/predictor/pe_layer_2/Concat_5_output_0 : Float(*, *, *, *, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cuda:0) = onnx::Concat[axis=3, onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Concat_5"](%/model/sem_seg_head/predictor/pe_layer_2/Reshape_1_output_0, %/model/sem_seg_head/predictor/pe_layer_2/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/predictor/pe_layer_2/Transpose_output_0 : Float(*, *, *, *, strides=[8388608, 1, 65536, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name="/model/sem_seg_head/predictor/pe_layer_2/Transpose"](%/model/sem_seg_head/predictor/pe_layer_2/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.position_encoding.PositionEmbeddingSine::pe_layer # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:51:0
  %/model/sem_seg_head/predictor/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_10"](%/model/sem_seg_head/predictor/pe_layer_2/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_22"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_23"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_24"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Slice_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_4"](%/model/sem_seg_head/predictor/Shape_10_output_0, %/model/sem_seg_head/predictor/Constant_23_output_0, %/model/sem_seg_head/predictor/Constant_24_output_0, %/model/sem_seg_head/predictor/Constant_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_25"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_4"](%/model/sem_seg_head/predictor/Slice_4_output_0, %/model/sem_seg_head/predictor/Constant_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Reshape_4_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_4"](%/model/sem_seg_head/predictor/pe_layer_2/Transpose_output_0, %/model/sem_seg_head/predictor/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:376:0
  %/model/sem_seg_head/predictor/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_11"](%/model/sem_seg_head/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_26"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_27"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_28"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Slice_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_5"](%/model/sem_seg_head/predictor/Shape_11_output_0, %/model/sem_seg_head/predictor/Constant_27_output_0, %/model/sem_seg_head/predictor/Constant_28_output_0, %/model/sem_seg_head/predictor/Constant_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_29"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Concat_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_5"](%/model/sem_seg_head/predictor/Slice_5_output_0, %/model/sem_seg_head/predictor/Constant_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Reshape_5_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_5"](%/model/sem_seg_head/Transpose_2_output_0, %/model/sem_seg_head/predictor/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Add_2_output_0 : Float(*, *, *, strides=[256, 1, 256], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/Add_2"](%/model/sem_seg_head/predictor/Reshape_5_output_0, %onnx::Add_7256), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:377:0
  %/model/sem_seg_head/predictor/Transpose_4_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name="/model/sem_seg_head/predictor/Transpose_4"](%/model/sem_seg_head/predictor/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:380:0
  %/model/sem_seg_head/predictor/Transpose_5_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name="/model/sem_seg_head/predictor/Transpose_5"](%/model/sem_seg_head/predictor/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:381:0
  %/model/sem_seg_head/predictor/Shape_12_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_12"](%/model/sem_seg_head/predictor/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:383:0
  %/model/sem_seg_head/predictor/Constant_30_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_30"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:383:0
  %/model/sem_seg_head/predictor/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_6"](%/model/sem_seg_head/predictor/Shape_12_output_0, %/model/sem_seg_head/predictor/Constant_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:383:0
  %/model/sem_seg_head/predictor/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_31"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3509 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze"](%/model/sem_seg_head/predictor/Gather_6_output_0, %onnx::Unsqueeze_3509), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_32"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_6_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_6"](%/model/sem_seg_head/predictor/Constant_31_output_0, %/model/sem_seg_head/predictor/Unsqueeze_output_0, %/model/sem_seg_head/predictor/Constant_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:386:0
  %/model/sem_seg_head/predictor/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_1"](%/model/sem_seg_head/predictor/Gather_6_output_0, %onnx::Unsqueeze_3516), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_7_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_7"](%/model/sem_seg_head/predictor/Constant_33_output_0, %/model/sem_seg_head/predictor/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:386:0
  %/model/sem_seg_head/predictor/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_2"](%/model/sem_seg_head/predictor/Gather_6_output_0, %onnx::Unsqueeze_3523), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_8_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_8"](%/model/sem_seg_head/predictor/Constant_35_output_0, %/model/sem_seg_head/predictor/Unsqueeze_2_output_0, %/model/sem_seg_head/predictor/Constant_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:387:0
  %/model/sem_seg_head/predictor/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_3"](%/model/sem_seg_head/predictor/Gather_6_output_0, %onnx::Unsqueeze_3530), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_9"](%/model/sem_seg_head/predictor/Constant_37_output_0, %/model/sem_seg_head/predictor/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/Constant_38_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:387:0
  %/model/sem_seg_head/predictor/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_13"](%/model/sem_seg_head/predictor/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:386:0
  %/model/sem_seg_head/predictor/ConstantOfShape_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape"](%/model/sem_seg_head/predictor/Shape_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:386:0
  %/model/sem_seg_head/predictor/Expand_output_0 : Float(100, 1, 256, strides=[256, 256, 1], device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand"](%onnx::Expand_7257, %/model/sem_seg_head/predictor/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:386:0
  %/model/sem_seg_head/predictor/Tile_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile"](%/model/sem_seg_head/predictor/Expand_output_0, %/model/sem_seg_head/predictor/Concat_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:386:0
  %/model/sem_seg_head/predictor/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_14"](%/model/sem_seg_head/predictor/Concat_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:387:0
  %/model/sem_seg_head/predictor/ConstantOfShape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_1"](%/model/sem_seg_head/predictor/Shape_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:387:0
  %/model/sem_seg_head/predictor/Expand_1_output_0 : Float(100, 1, 256, strides=[256, 256, 1], device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_1"](%onnx::Expand_7266, %/model/sem_seg_head/predictor/ConstantOfShape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:387:0
  %/model/sem_seg_head/predictor/Tile_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_1"](%/model/sem_seg_head/predictor/Expand_1_output_0, %/model/sem_seg_head/predictor/Concat_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:387:0
  %/model/sem_seg_head/predictor/decoder_norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm/LayerNormalization"](%/model/sem_seg_head/predictor/Tile_1_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_6_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_6"](%/model/sem_seg_head/predictor/decoder_norm/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0/MatMul"](%/model/sem_seg_head/predictor/Transpose_6_output_0, %onnx::MatMul_7267), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1/MatMul"](%/model/sem_seg_head/predictor/mask_embed/Relu_output_0, %onnx::MatMul_7268), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2/MatMul"](%/model/sem_seg_head/predictor/mask_embed/Relu_1_output_0, %onnx::MatMul_7269), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum"](%/model/sem_seg_head/predictor/mask_embed/layers.2/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %onnx::Unsqueeze_3559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_4"](%/model/sem_seg_head/predictor/Gather_output_0, %onnx::Unsqueeze_3559), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3561 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_5"](%/model/sem_seg_head/predictor/Gather_1_output_0, %onnx::Unsqueeze_3561), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_10"](%/model/sem_seg_head/predictor/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Unsqueeze_3564 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_6"](%/model/sem_seg_head/predictor/Gather_output_0, %onnx::Unsqueeze_3564), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3566 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_7"](%/model/sem_seg_head/predictor/Gather_1_output_0, %onnx::Unsqueeze_3566), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_11_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_11"](%/model/sem_seg_head/predictor/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/Unsqueeze_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Unsqueeze_3569 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_8"](%/model/sem_seg_head/predictor/Gather_output_0, %onnx::Unsqueeze_3569), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_9"](%/model/sem_seg_head/predictor/Gather_1_output_0, %onnx::Unsqueeze_3571), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_12"](%/model/sem_seg_head/predictor/Unsqueeze_8_output_0, %/model/sem_seg_head/predictor/Unsqueeze_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Shape_15_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_15"](%/model/sem_seg_head/predictor/Einsum_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_6"](%/model/sem_seg_head/predictor/Shape_15_output_0, %/model/sem_seg_head/predictor/Constant_40_output_0, %/model/sem_seg_head/predictor/Constant_41_output_0, %/model/sem_seg_head/predictor/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast"](%/model/sem_seg_head/predictor/Concat_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_13"](%/model/sem_seg_head/predictor/Slice_6_output_0, %/model/sem_seg_head/predictor/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_3581 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_3582 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_output_0 : Float(*, *, *, *, strides=[204800, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize"](%/model/sem_seg_head/predictor/Einsum_output_0, %onnx::Resize_3581, %onnx::Resize_3582, %/model/sem_seg_head/predictor/Concat_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_output_0 : Float(*, *, *, *, strides=[204800, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid"](%/model/sem_seg_head/predictor/Resize_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_16_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_16"](%/model/sem_seg_head/predictor/Sigmoid_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_7_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_7"](%/model/sem_seg_head/predictor/Shape_16_output_0, %/model/sem_seg_head/predictor/Constant_43_output_0, %/model/sem_seg_head/predictor/Constant_44_output_0, %/model/sem_seg_head/predictor/Constant_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_14_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_14"](%/model/sem_seg_head/predictor/Slice_7_output_0, %/model/sem_seg_head/predictor/Constant_45_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_6_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_6"](%/model/sem_seg_head/predictor/Sigmoid_output_0, %/model/sem_seg_head/predictor/Concat_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_10_output_0 : Float(*, 1, *, *, strides=[204800, 204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_10"](%/model/sem_seg_head/predictor/Reshape_6_output_0, %/model/sem_seg_head/predictor/Constant_46_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %onnx::Tile_3595 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  8  1  1 [ CPULongType{4} ]]()
  %/model/sem_seg_head/predictor/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_47"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_2"](%/model/sem_seg_head/predictor/Constant_47_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_2_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_2"](%/model/sem_seg_head/predictor/Unsqueeze_10_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_2_output_0 : Float(*, 8, *, *, strides=[1638400, 204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_2"](%/model/sem_seg_head/predictor/Expand_2_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_17"](%/model/sem_seg_head/predictor/Tile_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_48"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_49"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_50"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_8_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_8"](%/model/sem_seg_head/predictor/Shape_17_output_0, %/model/sem_seg_head/predictor/Constant_49_output_0, %/model/sem_seg_head/predictor/Constant_50_output_0, %/model/sem_seg_head/predictor/Constant_48_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_51"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_52"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_53"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_9"](%/model/sem_seg_head/predictor/Shape_17_output_0, %/model/sem_seg_head/predictor/Constant_52_output_0, %/model/sem_seg_head/predictor/Constant_53_output_0, %/model/sem_seg_head/predictor/Constant_51_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_54_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_54"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_15_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_15"](%/model/sem_seg_head/predictor/Slice_8_output_0, %/model/sem_seg_head/predictor/Constant_54_output_0, %/model/sem_seg_head/predictor/Slice_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_7_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_7"](%/model/sem_seg_head/predictor/Tile_2_output_0, %/model/sem_seg_head/predictor/Concat_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_55_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_55"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less"](%/model/sem_seg_head/predictor/Reshape_7_output_0, %/model/sem_seg_head/predictor/Constant_55_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_1_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_1"](%/model/sem_seg_head/predictor/Less_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_2_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_2"](%/model/sem_seg_head/predictor/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum"](%/model/sem_seg_head/predictor/Cast_2_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_18_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_18"](%/model/sem_seg_head/predictor/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_56_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_56"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_7"](%/model/sem_seg_head/predictor/Shape_18_output_0, %/model/sem_seg_head/predictor/Constant_56_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal"](%/model/sem_seg_head/predictor/ReduceSum_output_0, %/model/sem_seg_head/predictor/Gather_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_57_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_57"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_11_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_11"](%/model/sem_seg_head/predictor/Equal_output_0, %/model/sem_seg_head/predictor/Constant_57_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not"](%/model/sem_seg_head/predictor/Unsqueeze_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And"](%/model/sem_seg_head/predictor/Cast_1_output_0, %/model/sem_seg_head/predictor/Not_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add"](%/model/sem_seg_head/predictor/Tile_1_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_1"](%/model/sem_seg_head/predictor/Transpose_1_output_0, %/model/sem_seg_head/predictor/Transpose_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Where_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_output_0, %onnx::MatMul_7291), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add"](%onnx::Add_7286, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_1_output_0, %onnx::MatMul_7292), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_1"](%onnx::Add_7288, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_1_output_0, %onnx::MatMul_7293), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_2"](%onnx::Add_7290, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_3690 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_output_0, %onnx::Unsqueeze_3690), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3692 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_output_0, %onnx::Unsqueeze_3692), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3694 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_3694), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_3702 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_3702), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3704 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_output_0, %onnx::Unsqueeze_3704), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3706 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_3706), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_3713 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_3713), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3715 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_output_0, %onnx::Unsqueeze_3715), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3717 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_3717), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_3735 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_3735), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_3737), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_3745 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_output_0, %onnx::Unsqueeze_3745), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_3747), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_3749 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_3749), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_2_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_2"](%/model/sem_seg_head/predictor/Tile_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_2_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.0/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_output_0, %onnx::MatMul_7316), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add"](%onnx::Add_7311, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_output_0, %onnx::MatMul_7317), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_1"](%onnx::Add_7313, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/norm/LayerNormalization_output_0, %onnx::MatMul_7318), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_2"](%onnx::Add_7315, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_3814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_3814), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_output_0, %onnx::Unsqueeze_3816), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3818), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_3826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_3_output_0, %onnx::Unsqueeze_3826), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_output_0, %onnx::Unsqueeze_3828), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3830), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_3837 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_4_output_0, %onnx::Unsqueeze_3837), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3839 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_output_0, %onnx::Unsqueeze_3839), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3841 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_3841), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_3854 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Mul_2_output_0, %onnx::Unsqueeze_3854), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3856 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_2_output_0, %onnx::Unsqueeze_3856), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_3864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_3864), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_3866), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_3868 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_3868), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.0/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.0/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.0.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.0.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.0/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/norm/LayerNormalization_output_0, %onnx::MatMul_7319), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.0.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.0/Relu_output_0, %onnx::MatMul_7320), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.0.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.0/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.0/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.0/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.0/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.0/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.0.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.0.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.0/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_1/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_1/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.0/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_7_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_7"](%/model/sem_seg_head/predictor/decoder_norm_1/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_1/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_1/MatMul"](%/model/sem_seg_head/predictor/Transpose_7_output_0, %onnx::MatMul_7321), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_1/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_1/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_1/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_1/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_1/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_1/MatMul"](%/model/sem_seg_head/predictor/mask_embed_1/Relu_output_0, %onnx::MatMul_7322), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_1/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_1/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_1/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_1/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_1/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_1/MatMul"](%/model/sem_seg_head/predictor/mask_embed_1/Relu_1_output_0, %onnx::MatMul_7323), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_1/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_1/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_1_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_1"](%/model/sem_seg_head/predictor/mask_embed/layers.2_1/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %onnx::Unsqueeze_3897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_12"](%/model/sem_seg_head/predictor/Gather_2_output_0, %onnx::Unsqueeze_3897), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_13"](%/model/sem_seg_head/predictor/Gather_3_output_0, %onnx::Unsqueeze_3899), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_16_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_16"](%/model/sem_seg_head/predictor/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Unsqueeze_3902 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_14"](%/model/sem_seg_head/predictor/Gather_2_output_0, %onnx::Unsqueeze_3902), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3904 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_15"](%/model/sem_seg_head/predictor/Gather_3_output_0, %onnx::Unsqueeze_3904), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_17"](%/model/sem_seg_head/predictor/Unsqueeze_14_output_0, %/model/sem_seg_head/predictor/Unsqueeze_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Unsqueeze_3907 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_16"](%/model/sem_seg_head/predictor/Gather_2_output_0, %onnx::Unsqueeze_3907), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_3909 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_17"](%/model/sem_seg_head/predictor/Gather_3_output_0, %onnx::Unsqueeze_3909), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_18"](%/model/sem_seg_head/predictor/Unsqueeze_16_output_0, %/model/sem_seg_head/predictor/Unsqueeze_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Shape_19_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_19"](%/model/sem_seg_head/predictor/Einsum_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_58_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_58"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_59_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_59"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_60_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_60"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_10"](%/model/sem_seg_head/predictor/Shape_19_output_0, %/model/sem_seg_head/predictor/Constant_59_output_0, %/model/sem_seg_head/predictor/Constant_60_output_0, %/model/sem_seg_head/predictor/Constant_58_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_3"](%/model/sem_seg_head/predictor/Concat_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_19_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_19"](%/model/sem_seg_head/predictor/Slice_10_output_0, %/model/sem_seg_head/predictor/Cast_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_3919 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_3920 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_1_output_0 : Float(*, *, *, *, strides=[819200, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_1"](%/model/sem_seg_head/predictor/Einsum_1_output_0, %onnx::Resize_3919, %onnx::Resize_3920, %/model/sem_seg_head/predictor/Concat_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_1_output_0 : Float(*, *, *, *, strides=[819200, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_1"](%/model/sem_seg_head/predictor/Resize_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_20_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_20"](%/model/sem_seg_head/predictor/Sigmoid_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_61_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_61"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_62_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_62"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_63_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_63"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_11_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_11"](%/model/sem_seg_head/predictor/Shape_20_output_0, %/model/sem_seg_head/predictor/Constant_62_output_0, %/model/sem_seg_head/predictor/Constant_63_output_0, %/model/sem_seg_head/predictor/Constant_61_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_64"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_20_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_20"](%/model/sem_seg_head/predictor/Slice_11_output_0, %/model/sem_seg_head/predictor/Constant_64_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_8_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_8"](%/model/sem_seg_head/predictor/Sigmoid_1_output_0, %/model/sem_seg_head/predictor/Concat_20_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_65_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_65"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_18_output_0 : Float(*, 1, *, *, strides=[819200, 819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_18"](%/model/sem_seg_head/predictor/Reshape_8_output_0, %/model/sem_seg_head/predictor/Constant_65_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_66_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_66"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_3"](%/model/sem_seg_head/predictor/Constant_66_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_3_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_3"](%/model/sem_seg_head/predictor/Unsqueeze_18_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_3_output_0 : Float(*, 8, *, *, strides=[6553600, 819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_3"](%/model/sem_seg_head/predictor/Expand_3_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_21"](%/model/sem_seg_head/predictor/Tile_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_67_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_67"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_68_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_68"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_69"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_12_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_12"](%/model/sem_seg_head/predictor/Shape_21_output_0, %/model/sem_seg_head/predictor/Constant_68_output_0, %/model/sem_seg_head/predictor/Constant_69_output_0, %/model/sem_seg_head/predictor/Constant_67_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_70"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_71"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_72"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_13"](%/model/sem_seg_head/predictor/Shape_21_output_0, %/model/sem_seg_head/predictor/Constant_71_output_0, %/model/sem_seg_head/predictor/Constant_72_output_0, %/model/sem_seg_head/predictor/Constant_70_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_73_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_73"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_21_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_21"](%/model/sem_seg_head/predictor/Slice_12_output_0, %/model/sem_seg_head/predictor/Constant_73_output_0, %/model/sem_seg_head/predictor/Slice_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_9_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_9"](%/model/sem_seg_head/predictor/Tile_3_output_0, %/model/sem_seg_head/predictor/Concat_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_74_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_74"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_1_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_1"](%/model/sem_seg_head/predictor/Reshape_9_output_0, %/model/sem_seg_head/predictor/Constant_74_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_4_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_4"](%/model/sem_seg_head/predictor/Less_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_5_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_5"](%/model/sem_seg_head/predictor/Cast_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_1_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_1"](%/model/sem_seg_head/predictor/Cast_5_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_22_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_22"](%/model/sem_seg_head/predictor/Cast_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_75_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_75"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_8_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_8"](%/model/sem_seg_head/predictor/Shape_22_output_0, %/model/sem_seg_head/predictor/Constant_75_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_1_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_1"](%/model/sem_seg_head/predictor/ReduceSum_1_output_0, %/model/sem_seg_head/predictor/Gather_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_76_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_76"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_19_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_19"](%/model/sem_seg_head/predictor/Equal_1_output_0, %/model/sem_seg_head/predictor/Constant_76_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_1_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_1"](%/model/sem_seg_head/predictor/Unsqueeze_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_1_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_1"](%/model/sem_seg_head/predictor/Cast_4_output_0, %/model/sem_seg_head/predictor/Not_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.0/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_1"](%/model/sem_seg_head/predictor/Transpose_3_output_0, %/model/sem_seg_head/predictor/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Where_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_output_0, %onnx::MatMul_7345), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add"](%onnx::Add_7340, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_1_output_0, %onnx::MatMul_7346), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_1"](%onnx::Add_7342, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_3_output_0, %onnx::MatMul_7347), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_2"](%onnx::Add_7344, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_4027 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_output_0, %onnx::Unsqueeze_4027), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4029 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4029), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4031), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_4039 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_4039), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4041 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4041), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4043), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_4050 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_4050), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4052 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4052), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4054 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4054), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_4072 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_4072), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4074 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_4074), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_4082 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_output_0, %onnx::Unsqueeze_4082), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4084 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_4084), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4086 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_4086), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_2_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_2"](%/model/sem_seg_head/predictor/transformer_ffn_layers.0/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_2_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.1/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_output_0, %onnx::MatMul_7370), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add"](%onnx::Add_7365, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_output_0, %onnx::MatMul_7371), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_1"](%onnx::Add_7367, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/norm/LayerNormalization_output_0, %onnx::MatMul_7372), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_2"](%onnx::Add_7369, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_4151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_4151), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_output_0, %onnx::Unsqueeze_4153), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4155), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_4163 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_3_output_0, %onnx::Unsqueeze_4163), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_output_0, %onnx::Unsqueeze_4165), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4167), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_4174 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_4_output_0, %onnx::Unsqueeze_4174), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4176 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_output_0, %onnx::Unsqueeze_4176), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4178 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4178), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_4191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Mul_2_output_0, %onnx::Unsqueeze_4191), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_2_output_0, %onnx::Unsqueeze_4193), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_4201 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_4201), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_4203), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4205 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_4205), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.1/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.1/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.1.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.1.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.1/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/norm/LayerNormalization_output_0, %onnx::MatMul_7373), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.1.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.1/Relu_output_0, %onnx::MatMul_7374), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.1.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.1/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.1/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.1/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.1/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.1/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.1.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.1.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.1/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_2/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_2/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.1/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_8_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_8"](%/model/sem_seg_head/predictor/decoder_norm_2/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_2/MatMul"](%/model/sem_seg_head/predictor/Transpose_8_output_0, %onnx::MatMul_7375), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_2/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_2/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_2/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_2/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_2/MatMul"](%/model/sem_seg_head/predictor/mask_embed_2/Relu_output_0, %onnx::MatMul_7376), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_2/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_2/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_2/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_2/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_2/MatMul"](%/model/sem_seg_head/predictor/mask_embed_2/Relu_1_output_0, %onnx::MatMul_7377), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_2/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_2/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_2_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_2"](%/model/sem_seg_head/predictor/mask_embed/layers.2_2/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %onnx::Unsqueeze_4234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_20"](%/model/sem_seg_head/predictor/Gather_4_output_0, %onnx::Unsqueeze_4234), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_4236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_21"](%/model/sem_seg_head/predictor/Gather_5_output_0, %onnx::Unsqueeze_4236), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_22"](%/model/sem_seg_head/predictor/Unsqueeze_20_output_0, %/model/sem_seg_head/predictor/Unsqueeze_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Unsqueeze_4239 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_22"](%/model/sem_seg_head/predictor/Gather_4_output_0, %onnx::Unsqueeze_4239), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_4241 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_23"](%/model/sem_seg_head/predictor/Gather_5_output_0, %onnx::Unsqueeze_4241), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_23"](%/model/sem_seg_head/predictor/Unsqueeze_22_output_0, %/model/sem_seg_head/predictor/Unsqueeze_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Unsqueeze_4244 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_24"](%/model/sem_seg_head/predictor/Gather_4_output_0, %onnx::Unsqueeze_4244), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %onnx::Unsqueeze_4246 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_25"](%/model/sem_seg_head/predictor/Gather_5_output_0, %onnx::Unsqueeze_4246), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor
  %/model/sem_seg_head/predictor/Concat_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_24"](%/model/sem_seg_head/predictor/Unsqueeze_24_output_0, %/model/sem_seg_head/predictor/Unsqueeze_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Shape_23_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_23"](%/model/sem_seg_head/predictor/Einsum_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_77_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_77"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_78"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_79_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_79"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_14"](%/model/sem_seg_head/predictor/Shape_23_output_0, %/model/sem_seg_head/predictor/Constant_78_output_0, %/model/sem_seg_head/predictor/Constant_79_output_0, %/model/sem_seg_head/predictor/Constant_77_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_6"](%/model/sem_seg_head/predictor/Concat_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_25_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_25"](%/model/sem_seg_head/predictor/Slice_14_output_0, %/model/sem_seg_head/predictor/Cast_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_4256 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_4257 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_2_output_0 : Float(*, *, *, *, strides=[3276800, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_2"](%/model/sem_seg_head/predictor/Einsum_2_output_0, %onnx::Resize_4256, %onnx::Resize_4257, %/model/sem_seg_head/predictor/Concat_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_2_output_0 : Float(*, *, *, *, strides=[3276800, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_2"](%/model/sem_seg_head/predictor/Resize_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_24_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_24"](%/model/sem_seg_head/predictor/Sigmoid_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_80_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_80"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_81"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_82_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_82"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_15"](%/model/sem_seg_head/predictor/Shape_24_output_0, %/model/sem_seg_head/predictor/Constant_81_output_0, %/model/sem_seg_head/predictor/Constant_82_output_0, %/model/sem_seg_head/predictor/Constant_80_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_83"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_26_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_26"](%/model/sem_seg_head/predictor/Slice_15_output_0, %/model/sem_seg_head/predictor/Constant_83_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_10_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_10"](%/model/sem_seg_head/predictor/Sigmoid_2_output_0, %/model/sem_seg_head/predictor/Concat_26_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_84_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_84"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_26_output_0 : Float(*, 1, *, *, strides=[3276800, 3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_26"](%/model/sem_seg_head/predictor/Reshape_10_output_0, %/model/sem_seg_head/predictor/Constant_84_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_85_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_85"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_4"](%/model/sem_seg_head/predictor/Constant_85_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_4_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_4"](%/model/sem_seg_head/predictor/Unsqueeze_26_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_4_output_0 : Float(*, 8, *, *, strides=[26214400, 3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_4"](%/model/sem_seg_head/predictor/Expand_4_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_25_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_25"](%/model/sem_seg_head/predictor/Tile_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_86_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_86"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_87_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_87"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_88_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_88"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_16_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_16"](%/model/sem_seg_head/predictor/Shape_25_output_0, %/model/sem_seg_head/predictor/Constant_87_output_0, %/model/sem_seg_head/predictor/Constant_88_output_0, %/model/sem_seg_head/predictor/Constant_86_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_89_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_89"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_90_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_90"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_91_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_91"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_17"](%/model/sem_seg_head/predictor/Shape_25_output_0, %/model/sem_seg_head/predictor/Constant_90_output_0, %/model/sem_seg_head/predictor/Constant_91_output_0, %/model/sem_seg_head/predictor/Constant_89_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_92"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_27_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_27"](%/model/sem_seg_head/predictor/Slice_16_output_0, %/model/sem_seg_head/predictor/Constant_92_output_0, %/model/sem_seg_head/predictor/Slice_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_11_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_11"](%/model/sem_seg_head/predictor/Tile_4_output_0, %/model/sem_seg_head/predictor/Concat_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_93_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_93"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_2_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_2"](%/model/sem_seg_head/predictor/Reshape_11_output_0, %/model/sem_seg_head/predictor/Constant_93_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_7_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_7"](%/model/sem_seg_head/predictor/Less_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_8_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_8"](%/model/sem_seg_head/predictor/Cast_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_2_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_2"](%/model/sem_seg_head/predictor/Cast_8_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_26_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_26"](%/model/sem_seg_head/predictor/Cast_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_94_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_94"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_9"](%/model/sem_seg_head/predictor/Shape_26_output_0, %/model/sem_seg_head/predictor/Constant_94_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_2_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_2"](%/model/sem_seg_head/predictor/ReduceSum_2_output_0, %/model/sem_seg_head/predictor/Gather_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_95_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_95"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_27_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_27"](%/model/sem_seg_head/predictor/Equal_2_output_0, %/model/sem_seg_head/predictor/Constant_95_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_2_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_2"](%/model/sem_seg_head/predictor/Unsqueeze_27_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_2_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_2"](%/model/sem_seg_head/predictor/Cast_7_output_0, %/model/sem_seg_head/predictor/Not_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.1/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_1"](%/model/sem_seg_head/predictor/Transpose_5_output_0, %/model/sem_seg_head/predictor/Transpose_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Where_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_output_0, %onnx::MatMul_7399), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add"](%onnx::Add_7394, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_1_output_0, %onnx::MatMul_7400), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_1"](%onnx::Add_7396, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_5_output_0, %onnx::MatMul_7401), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_2"](%onnx::Add_7398, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_4364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_output_0, %onnx::Unsqueeze_4364), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4366), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4368 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4368), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_4376 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_4376), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4378 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4378), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4380 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4380), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_4387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_4387), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4389 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4389), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4391 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4391), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_4409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_4409), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_4411), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_4419 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_output_0, %onnx::Unsqueeze_4419), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4421 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_4421), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4423 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_4423), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_2_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_2"](%/model/sem_seg_head/predictor/transformer_ffn_layers.1/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_2_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.2/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_output_0, %onnx::MatMul_7424), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add"](%onnx::Add_7419, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_output_0, %onnx::MatMul_7425), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_1"](%onnx::Add_7421, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/norm/LayerNormalization_output_0, %onnx::MatMul_7426), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_2"](%onnx::Add_7423, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_4488 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_4488), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_output_0, %onnx::Unsqueeze_4490), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4492), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_4500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_3_output_0, %onnx::Unsqueeze_4500), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_output_0, %onnx::Unsqueeze_4502), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4504), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_4511 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_4_output_0, %onnx::Unsqueeze_4511), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_output_0, %onnx::Unsqueeze_4513), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4515 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4515), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_4528 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Mul_2_output_0, %onnx::Unsqueeze_4528), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_2_output_0, %onnx::Unsqueeze_4530), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_4538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_output_0, %onnx::Unsqueeze_4538), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_1_output_0, %onnx::Unsqueeze_4540), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4542 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gather_5_output_0, %onnx::Unsqueeze_4542), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.2/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.2/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.2.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.2.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.2/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/norm/LayerNormalization_output_0, %onnx::MatMul_7427), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.2.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.2/Relu_output_0, %onnx::MatMul_7428), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.2.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.2/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.2/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.2/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.2/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.2/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.2.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.2.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.2/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_3/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_3/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.2/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_9_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_9"](%/model/sem_seg_head/predictor/decoder_norm_3/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_3/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_3/MatMul"](%/model/sem_seg_head/predictor/Transpose_9_output_0, %onnx::MatMul_7429), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_3/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_3/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_3/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_3/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_3/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_3/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_3/MatMul"](%/model/sem_seg_head/predictor/mask_embed_3/Relu_output_0, %onnx::MatMul_7430), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_3/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_3/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_3/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_3/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_3/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_3/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_3/MatMul"](%/model/sem_seg_head/predictor/mask_embed_3/Relu_1_output_0, %onnx::MatMul_7431), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_3/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_3/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_3/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_3_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_3"](%/model/sem_seg_head/predictor/mask_embed/layers.2_3/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/sem_seg_head/predictor/Shape_27_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_27"](%/model/sem_seg_head/predictor/Einsum_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_96_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_96"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_97_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_97"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_98_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_98"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_18"](%/model/sem_seg_head/predictor/Shape_27_output_0, %/model/sem_seg_head/predictor/Constant_97_output_0, %/model/sem_seg_head/predictor/Constant_98_output_0, %/model/sem_seg_head/predictor/Constant_96_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_9"](%/model/sem_seg_head/predictor/Concat_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_28_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_28"](%/model/sem_seg_head/predictor/Slice_18_output_0, %/model/sem_seg_head/predictor/Cast_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_4578 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_4579 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_3_output_0 : Float(*, *, *, *, strides=[204800, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_3"](%/model/sem_seg_head/predictor/Einsum_3_output_0, %onnx::Resize_4578, %onnx::Resize_4579, %/model/sem_seg_head/predictor/Concat_28_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_3_output_0 : Float(*, *, *, *, strides=[204800, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_3"](%/model/sem_seg_head/predictor/Resize_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_28_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_28"](%/model/sem_seg_head/predictor/Sigmoid_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_99_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_99"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_100_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_100"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_101_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_101"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_19"](%/model/sem_seg_head/predictor/Shape_28_output_0, %/model/sem_seg_head/predictor/Constant_100_output_0, %/model/sem_seg_head/predictor/Constant_101_output_0, %/model/sem_seg_head/predictor/Constant_99_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_102"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_29_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_29"](%/model/sem_seg_head/predictor/Slice_19_output_0, %/model/sem_seg_head/predictor/Constant_102_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_12_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_12"](%/model/sem_seg_head/predictor/Sigmoid_3_output_0, %/model/sem_seg_head/predictor/Concat_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_103_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_103"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_28_output_0 : Float(*, 1, *, *, strides=[204800, 204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_28"](%/model/sem_seg_head/predictor/Reshape_12_output_0, %/model/sem_seg_head/predictor/Constant_103_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_104_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_104"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_5"](%/model/sem_seg_head/predictor/Constant_104_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_5_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_5"](%/model/sem_seg_head/predictor/Unsqueeze_28_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_5_output_0 : Float(*, 8, *, *, strides=[1638400, 204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_5"](%/model/sem_seg_head/predictor/Expand_5_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_29_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_29"](%/model/sem_seg_head/predictor/Tile_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_105_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_105"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_106_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_106"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_107_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_107"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_20_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_20"](%/model/sem_seg_head/predictor/Shape_29_output_0, %/model/sem_seg_head/predictor/Constant_106_output_0, %/model/sem_seg_head/predictor/Constant_107_output_0, %/model/sem_seg_head/predictor/Constant_105_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_108"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_109"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_110"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_21"](%/model/sem_seg_head/predictor/Shape_29_output_0, %/model/sem_seg_head/predictor/Constant_109_output_0, %/model/sem_seg_head/predictor/Constant_110_output_0, %/model/sem_seg_head/predictor/Constant_108_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_111_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_111"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_30_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_30"](%/model/sem_seg_head/predictor/Slice_20_output_0, %/model/sem_seg_head/predictor/Constant_111_output_0, %/model/sem_seg_head/predictor/Slice_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_13_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_13"](%/model/sem_seg_head/predictor/Tile_5_output_0, %/model/sem_seg_head/predictor/Concat_30_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_112_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_112"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_3_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_3"](%/model/sem_seg_head/predictor/Reshape_13_output_0, %/model/sem_seg_head/predictor/Constant_112_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_10_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_10"](%/model/sem_seg_head/predictor/Less_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_11_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_11"](%/model/sem_seg_head/predictor/Cast_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_3_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_3"](%/model/sem_seg_head/predictor/Cast_11_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_30_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_30"](%/model/sem_seg_head/predictor/Cast_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_113_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_113"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_10"](%/model/sem_seg_head/predictor/Shape_30_output_0, %/model/sem_seg_head/predictor/Constant_113_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_3_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_3"](%/model/sem_seg_head/predictor/ReduceSum_3_output_0, %/model/sem_seg_head/predictor/Gather_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_114_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_114"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_29_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_29"](%/model/sem_seg_head/predictor/Equal_3_output_0, %/model/sem_seg_head/predictor/Constant_114_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_3_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_3"](%/model/sem_seg_head/predictor/Unsqueeze_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_3_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_3"](%/model/sem_seg_head/predictor/Cast_10_output_0, %/model/sem_seg_head/predictor/Not_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.2/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Where_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_output_0, %onnx::MatMul_7453), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add"](%onnx::Add_7448, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_1_output_0, %onnx::MatMul_7454), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_1"](%onnx::Add_7450, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_1_output_0, %onnx::MatMul_7455), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_2"](%onnx::Add_7452, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_4685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_output_0, %onnx::Unsqueeze_4685), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4687 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4687), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4689 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4689), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_4697 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_4697), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4699 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4699), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4701 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4701), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_4708 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_4708), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_output_0, %onnx::Unsqueeze_4710), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_4712), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_4730 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_4730), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4732 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_4732), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_4740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_output_0, %onnx::Unsqueeze_4740), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4742 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_4742), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_4744 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_4744), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_1"](%/model/sem_seg_head/predictor/transformer_ffn_layers.2/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/Add_1_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.3/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_output_0, %onnx::MatMul_7478), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add"](%onnx::Add_7473, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_output_0, %onnx::MatMul_7479), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_1"](%onnx::Add_7475, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/norm/LayerNormalization_output_0, %onnx::MatMul_7480), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_2"](%onnx::Add_7477, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_4809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_4809), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_output_0, %onnx::Unsqueeze_4811), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4813), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_4821 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_3_output_0, %onnx::Unsqueeze_4821), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4823 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_output_0, %onnx::Unsqueeze_4823), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4825 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4825), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_4832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_4_output_0, %onnx::Unsqueeze_4832), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_output_0, %onnx::Unsqueeze_4834), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Cast_1_output_0, %onnx::Unsqueeze_4836), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_4849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Mul_2_output_0, %onnx::Unsqueeze_4849), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_2_output_0, %onnx::Unsqueeze_4851), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_4859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_output_0, %onnx::Unsqueeze_4859), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4861 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_1_output_0, %onnx::Unsqueeze_4861), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_4863 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gather_5_output_0, %onnx::Unsqueeze_4863), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.3/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.3/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.3/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.3.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.3.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.3/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/norm/LayerNormalization_output_0, %onnx::MatMul_7481), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.3.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.3/Relu_output_0, %onnx::MatMul_7482), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.3.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.3/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.3/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.3/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.3/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.3/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.3.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.3.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.3/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_4/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_4/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.3/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_10_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_10"](%/model/sem_seg_head/predictor/decoder_norm_4/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_4/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_4/MatMul"](%/model/sem_seg_head/predictor/Transpose_10_output_0, %onnx::MatMul_7483), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_4/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_4/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_4/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_4/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_4/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_4/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_4/MatMul"](%/model/sem_seg_head/predictor/mask_embed_4/Relu_output_0, %onnx::MatMul_7484), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_4/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_4/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_4/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_4/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_4/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_4/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_4/MatMul"](%/model/sem_seg_head/predictor/mask_embed_4/Relu_1_output_0, %onnx::MatMul_7485), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_4/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_4/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_4/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_4_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_4"](%/model/sem_seg_head/predictor/mask_embed/layers.2_4/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/sem_seg_head/predictor/Shape_31_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_31"](%/model/sem_seg_head/predictor/Einsum_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_115_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_115"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_116_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_116"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_117_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_117"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_22"](%/model/sem_seg_head/predictor/Shape_31_output_0, %/model/sem_seg_head/predictor/Constant_116_output_0, %/model/sem_seg_head/predictor/Constant_117_output_0, %/model/sem_seg_head/predictor/Constant_115_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_12"](%/model/sem_seg_head/predictor/Concat_17_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_31_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_31"](%/model/sem_seg_head/predictor/Slice_22_output_0, %/model/sem_seg_head/predictor/Cast_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_4899 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_4900 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_4_output_0 : Float(*, *, *, *, strides=[819200, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_4"](%/model/sem_seg_head/predictor/Einsum_4_output_0, %onnx::Resize_4899, %onnx::Resize_4900, %/model/sem_seg_head/predictor/Concat_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_4_output_0 : Float(*, *, *, *, strides=[819200, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_4"](%/model/sem_seg_head/predictor/Resize_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_32_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_32"](%/model/sem_seg_head/predictor/Sigmoid_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_118_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_118"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_119_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_119"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_120_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_120"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_23"](%/model/sem_seg_head/predictor/Shape_32_output_0, %/model/sem_seg_head/predictor/Constant_119_output_0, %/model/sem_seg_head/predictor/Constant_120_output_0, %/model/sem_seg_head/predictor/Constant_118_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_121"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_32_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_32"](%/model/sem_seg_head/predictor/Slice_23_output_0, %/model/sem_seg_head/predictor/Constant_121_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_14_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_14"](%/model/sem_seg_head/predictor/Sigmoid_4_output_0, %/model/sem_seg_head/predictor/Concat_32_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_122_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_122"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_30_output_0 : Float(*, 1, *, *, strides=[819200, 819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_30"](%/model/sem_seg_head/predictor/Reshape_14_output_0, %/model/sem_seg_head/predictor/Constant_122_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_123_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_123"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_6"](%/model/sem_seg_head/predictor/Constant_123_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_6_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_6"](%/model/sem_seg_head/predictor/Unsqueeze_30_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_6_output_0 : Float(*, 8, *, *, strides=[6553600, 819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_6"](%/model/sem_seg_head/predictor/Expand_6_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_33_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_33"](%/model/sem_seg_head/predictor/Tile_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_124_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_124"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_125_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_125"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_126_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_126"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_24_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_24"](%/model/sem_seg_head/predictor/Shape_33_output_0, %/model/sem_seg_head/predictor/Constant_125_output_0, %/model/sem_seg_head/predictor/Constant_126_output_0, %/model/sem_seg_head/predictor/Constant_124_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_127"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_128"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_129"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_25"](%/model/sem_seg_head/predictor/Shape_33_output_0, %/model/sem_seg_head/predictor/Constant_128_output_0, %/model/sem_seg_head/predictor/Constant_129_output_0, %/model/sem_seg_head/predictor/Constant_127_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_130_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_130"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_33_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_33"](%/model/sem_seg_head/predictor/Slice_24_output_0, %/model/sem_seg_head/predictor/Constant_130_output_0, %/model/sem_seg_head/predictor/Slice_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_15_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_15"](%/model/sem_seg_head/predictor/Tile_6_output_0, %/model/sem_seg_head/predictor/Concat_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_131_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_131"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_4_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_4"](%/model/sem_seg_head/predictor/Reshape_15_output_0, %/model/sem_seg_head/predictor/Constant_131_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_13_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_13"](%/model/sem_seg_head/predictor/Less_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_14_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_14"](%/model/sem_seg_head/predictor/Cast_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_4_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_4"](%/model/sem_seg_head/predictor/Cast_14_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_34_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_34"](%/model/sem_seg_head/predictor/Cast_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_132_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_132"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_11"](%/model/sem_seg_head/predictor/Shape_34_output_0, %/model/sem_seg_head/predictor/Constant_132_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_4_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_4"](%/model/sem_seg_head/predictor/ReduceSum_4_output_0, %/model/sem_seg_head/predictor/Gather_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_133_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_133"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_31_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_31"](%/model/sem_seg_head/predictor/Equal_4_output_0, %/model/sem_seg_head/predictor/Constant_133_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_4_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_4"](%/model/sem_seg_head/predictor/Unsqueeze_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_4_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_4"](%/model/sem_seg_head/predictor/Cast_13_output_0, %/model/sem_seg_head/predictor/Not_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.3/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Where_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_output_0, %onnx::MatMul_7507), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add"](%onnx::Add_7502, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_1_output_0, %onnx::MatMul_7508), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_1"](%onnx::Add_7504, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_3_output_0, %onnx::MatMul_7509), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_2"](%onnx::Add_7506, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5006 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5006), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5008 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5008), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5010 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5010), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_5018), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5020 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5020), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5022 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5022), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5029 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_5029), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5031), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5033 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5033), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_5051 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_5051), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5053 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_5053), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_5061 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5061), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5063 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_5063), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5065 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_5065), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_1"](%/model/sem_seg_head/predictor/transformer_ffn_layers.3/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/Add_1_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.4/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_output_0, %onnx::MatMul_7532), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add"](%onnx::Add_7527, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_output_0, %onnx::MatMul_7533), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_1"](%onnx::Add_7529, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/norm/LayerNormalization_output_0, %onnx::MatMul_7534), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_2"](%onnx::Add_7531, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5130 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_output_0, %onnx::Unsqueeze_5130), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_output_0, %onnx::Unsqueeze_5132), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5134), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5142 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_3_output_0, %onnx::Unsqueeze_5142), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5144 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_output_0, %onnx::Unsqueeze_5144), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5146), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_4_output_0, %onnx::Unsqueeze_5153), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_output_0, %onnx::Unsqueeze_5155), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5157), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_5170 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Mul_2_output_0, %onnx::Unsqueeze_5170), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5172 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_2_output_0, %onnx::Unsqueeze_5172), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_5180 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_output_0, %onnx::Unsqueeze_5180), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5182 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_1_output_0, %onnx::Unsqueeze_5182), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5184 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gather_5_output_0, %onnx::Unsqueeze_5184), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.4/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.4/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.4/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.4.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.4.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.4/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/norm/LayerNormalization_output_0, %onnx::MatMul_7535), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.4.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.4/Relu_output_0, %onnx::MatMul_7536), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.4.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.4/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.4/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.4/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.4/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.4/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.4.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.4.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.4/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_5/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_5/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.4/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_11_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_11"](%/model/sem_seg_head/predictor/decoder_norm_5/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_5/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_5/MatMul"](%/model/sem_seg_head/predictor/Transpose_11_output_0, %onnx::MatMul_7537), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_5/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_5/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_5/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_5/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_5/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_5/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_5/MatMul"](%/model/sem_seg_head/predictor/mask_embed_5/Relu_output_0, %onnx::MatMul_7538), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_5/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_5/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_5/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_5/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_5/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_5/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_5/MatMul"](%/model/sem_seg_head/predictor/mask_embed_5/Relu_1_output_0, %onnx::MatMul_7539), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_5/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_5/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_5/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_5_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_5"](%/model/sem_seg_head/predictor/mask_embed/layers.2_5/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/sem_seg_head/predictor/Shape_35_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_35"](%/model/sem_seg_head/predictor/Einsum_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_134_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_134"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_135_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_135"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_136"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_26"](%/model/sem_seg_head/predictor/Shape_35_output_0, %/model/sem_seg_head/predictor/Constant_135_output_0, %/model/sem_seg_head/predictor/Constant_136_output_0, %/model/sem_seg_head/predictor/Constant_134_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_15"](%/model/sem_seg_head/predictor/Concat_23_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_34_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_34"](%/model/sem_seg_head/predictor/Slice_26_output_0, %/model/sem_seg_head/predictor/Cast_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_5220 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_5221 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_5_output_0 : Float(*, *, *, *, strides=[3276800, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_5"](%/model/sem_seg_head/predictor/Einsum_5_output_0, %onnx::Resize_5220, %onnx::Resize_5221, %/model/sem_seg_head/predictor/Concat_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_5_output_0 : Float(*, *, *, *, strides=[3276800, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_5"](%/model/sem_seg_head/predictor/Resize_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_36_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_36"](%/model/sem_seg_head/predictor/Sigmoid_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_137_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_137"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_138_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_138"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_139_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_139"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_27_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_27"](%/model/sem_seg_head/predictor/Shape_36_output_0, %/model/sem_seg_head/predictor/Constant_138_output_0, %/model/sem_seg_head/predictor/Constant_139_output_0, %/model/sem_seg_head/predictor/Constant_137_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_140_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_140"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_35_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_35"](%/model/sem_seg_head/predictor/Slice_27_output_0, %/model/sem_seg_head/predictor/Constant_140_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_16_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_16"](%/model/sem_seg_head/predictor/Sigmoid_5_output_0, %/model/sem_seg_head/predictor/Concat_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_141"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_32_output_0 : Float(*, 1, *, *, strides=[3276800, 3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_32"](%/model/sem_seg_head/predictor/Reshape_16_output_0, %/model/sem_seg_head/predictor/Constant_141_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_142_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_142"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_7"](%/model/sem_seg_head/predictor/Constant_142_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_7_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_7"](%/model/sem_seg_head/predictor/Unsqueeze_32_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_7_output_0 : Float(*, 8, *, *, strides=[26214400, 3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_7"](%/model/sem_seg_head/predictor/Expand_7_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_37_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_37"](%/model/sem_seg_head/predictor/Tile_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_143"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_144_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_144"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_145_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_145"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_28_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_28"](%/model/sem_seg_head/predictor/Shape_37_output_0, %/model/sem_seg_head/predictor/Constant_144_output_0, %/model/sem_seg_head/predictor/Constant_145_output_0, %/model/sem_seg_head/predictor/Constant_143_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_146"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_147_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_147"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_148_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_148"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_29"](%/model/sem_seg_head/predictor/Shape_37_output_0, %/model/sem_seg_head/predictor/Constant_147_output_0, %/model/sem_seg_head/predictor/Constant_148_output_0, %/model/sem_seg_head/predictor/Constant_146_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_149_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_149"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_36_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_36"](%/model/sem_seg_head/predictor/Slice_28_output_0, %/model/sem_seg_head/predictor/Constant_149_output_0, %/model/sem_seg_head/predictor/Slice_29_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_17_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_17"](%/model/sem_seg_head/predictor/Tile_7_output_0, %/model/sem_seg_head/predictor/Concat_36_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_150_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_150"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_5_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_5"](%/model/sem_seg_head/predictor/Reshape_17_output_0, %/model/sem_seg_head/predictor/Constant_150_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_16_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_16"](%/model/sem_seg_head/predictor/Less_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_17_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_17"](%/model/sem_seg_head/predictor/Cast_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_5_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_5"](%/model/sem_seg_head/predictor/Cast_17_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_38_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_38"](%/model/sem_seg_head/predictor/Cast_16_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_151_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_151"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_12_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_12"](%/model/sem_seg_head/predictor/Shape_38_output_0, %/model/sem_seg_head/predictor/Constant_151_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_5_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_5"](%/model/sem_seg_head/predictor/ReduceSum_5_output_0, %/model/sem_seg_head/predictor/Gather_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_152_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_152"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_33_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_33"](%/model/sem_seg_head/predictor/Equal_5_output_0, %/model/sem_seg_head/predictor/Constant_152_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_5_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_5"](%/model/sem_seg_head/predictor/Unsqueeze_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_5_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_5"](%/model/sem_seg_head/predictor/Cast_16_output_0, %/model/sem_seg_head/predictor/Not_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.4/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Where_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_output_0, %onnx::MatMul_7561), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add"](%onnx::Add_7556, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_1_output_0, %onnx::MatMul_7562), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_1"](%onnx::Add_7558, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_5_output_0, %onnx::MatMul_7563), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_2"](%onnx::Add_7560, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5327 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5327), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5329), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5331), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_5339), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5341 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5341), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5343 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5343), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5350 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_5350), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5352 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5352), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5354 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5354), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_5372 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_5372), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5374 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_5374), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_5382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5382), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_5384), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_5386), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_1"](%/model/sem_seg_head/predictor/transformer_ffn_layers.4/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/Add_1_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.5/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_output_0, %onnx::MatMul_7586), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add"](%onnx::Add_7581, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_output_0, %onnx::MatMul_7587), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_1"](%onnx::Add_7583, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/norm/LayerNormalization_output_0, %onnx::MatMul_7588), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_2"](%onnx::Add_7585, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_output_0, %onnx::Unsqueeze_5451), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_output_0, %onnx::Unsqueeze_5453), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5455 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5455), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_3_output_0, %onnx::Unsqueeze_5463), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_output_0, %onnx::Unsqueeze_5465), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5467 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5467), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5474 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_4_output_0, %onnx::Unsqueeze_5474), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5476 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_output_0, %onnx::Unsqueeze_5476), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5478 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5478), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_5491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Mul_2_output_0, %onnx::Unsqueeze_5491), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_2_output_0, %onnx::Unsqueeze_5493), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_5501 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_output_0, %onnx::Unsqueeze_5501), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_1_output_0, %onnx::Unsqueeze_5503), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gather_5_output_0, %onnx::Unsqueeze_5505), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.5/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.5/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.5/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.5.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.5.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.5/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/norm/LayerNormalization_output_0, %onnx::MatMul_7589), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.5.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.5/Relu_output_0, %onnx::MatMul_7590), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.5.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.5/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.5/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.5/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.5/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.5/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.5.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.5.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.5/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_6/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_6/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.5/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_12_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_12"](%/model/sem_seg_head/predictor/decoder_norm_6/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_6/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_6/MatMul"](%/model/sem_seg_head/predictor/Transpose_12_output_0, %onnx::MatMul_7591), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_6/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_6/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_6/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_6/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_6/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_6/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_6/MatMul"](%/model/sem_seg_head/predictor/mask_embed_6/Relu_output_0, %onnx::MatMul_7592), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_6/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_6/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_6/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_6/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_6/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_6/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_6/MatMul"](%/model/sem_seg_head/predictor/mask_embed_6/Relu_1_output_0, %onnx::MatMul_7593), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_6/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_6/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_6/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_6_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_6"](%/model/sem_seg_head/predictor/mask_embed/layers.2_6/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/sem_seg_head/predictor/Shape_39_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_39"](%/model/sem_seg_head/predictor/Einsum_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_153_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_153"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_154_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_154"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_155_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_155"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_30_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_30"](%/model/sem_seg_head/predictor/Shape_39_output_0, %/model/sem_seg_head/predictor/Constant_154_output_0, %/model/sem_seg_head/predictor/Constant_155_output_0, %/model/sem_seg_head/predictor/Constant_153_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_18"](%/model/sem_seg_head/predictor/Concat_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_37_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_37"](%/model/sem_seg_head/predictor/Slice_30_output_0, %/model/sem_seg_head/predictor/Cast_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_5541 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_5542 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_6_output_0 : Float(*, *, *, *, strides=[204800, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_6"](%/model/sem_seg_head/predictor/Einsum_6_output_0, %onnx::Resize_5541, %onnx::Resize_5542, %/model/sem_seg_head/predictor/Concat_37_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_6_output_0 : Float(*, *, *, *, strides=[204800, 2048, 64, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_6"](%/model/sem_seg_head/predictor/Resize_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_40_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_40"](%/model/sem_seg_head/predictor/Sigmoid_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_156_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_156"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_157_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_157"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_158_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_158"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_31_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_31"](%/model/sem_seg_head/predictor/Shape_40_output_0, %/model/sem_seg_head/predictor/Constant_157_output_0, %/model/sem_seg_head/predictor/Constant_158_output_0, %/model/sem_seg_head/predictor/Constant_156_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_159_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_159"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_38_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_38"](%/model/sem_seg_head/predictor/Slice_31_output_0, %/model/sem_seg_head/predictor/Constant_159_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_18_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_18"](%/model/sem_seg_head/predictor/Sigmoid_6_output_0, %/model/sem_seg_head/predictor/Concat_38_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_160_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_160"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_34_output_0 : Float(*, 1, *, *, strides=[204800, 204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_34"](%/model/sem_seg_head/predictor/Reshape_18_output_0, %/model/sem_seg_head/predictor/Constant_160_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_161_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_161"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_8"](%/model/sem_seg_head/predictor/Constant_161_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_8_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_8"](%/model/sem_seg_head/predictor/Unsqueeze_34_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_8_output_0 : Float(*, 8, *, *, strides=[1638400, 204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_8"](%/model/sem_seg_head/predictor/Expand_8_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_41_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_41"](%/model/sem_seg_head/predictor/Tile_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_162_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_162"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_163_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_163"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_164_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_164"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_32_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_32"](%/model/sem_seg_head/predictor/Shape_41_output_0, %/model/sem_seg_head/predictor/Constant_163_output_0, %/model/sem_seg_head/predictor/Constant_164_output_0, %/model/sem_seg_head/predictor/Constant_162_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_165_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_165"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_166_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_166"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_167_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_167"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_33_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_33"](%/model/sem_seg_head/predictor/Shape_41_output_0, %/model/sem_seg_head/predictor/Constant_166_output_0, %/model/sem_seg_head/predictor/Constant_167_output_0, %/model/sem_seg_head/predictor/Constant_165_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_168_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_168"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_39_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_39"](%/model/sem_seg_head/predictor/Slice_32_output_0, %/model/sem_seg_head/predictor/Constant_168_output_0, %/model/sem_seg_head/predictor/Slice_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_19_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_19"](%/model/sem_seg_head/predictor/Tile_8_output_0, %/model/sem_seg_head/predictor/Concat_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_169_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_169"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_6_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_6"](%/model/sem_seg_head/predictor/Reshape_19_output_0, %/model/sem_seg_head/predictor/Constant_169_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_19_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_19"](%/model/sem_seg_head/predictor/Less_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_20_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_20"](%/model/sem_seg_head/predictor/Cast_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_6_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_6"](%/model/sem_seg_head/predictor/Cast_20_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_42_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_42"](%/model/sem_seg_head/predictor/Cast_19_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_170_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_170"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_13_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_13"](%/model/sem_seg_head/predictor/Shape_42_output_0, %/model/sem_seg_head/predictor/Constant_170_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_6_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_6"](%/model/sem_seg_head/predictor/ReduceSum_6_output_0, %/model/sem_seg_head/predictor/Gather_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_171_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_171"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_35_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_35"](%/model/sem_seg_head/predictor/Equal_6_output_0, %/model/sem_seg_head/predictor/Constant_171_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_6_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_6"](%/model/sem_seg_head/predictor/Unsqueeze_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_6_output_0 : Bool(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_6"](%/model/sem_seg_head/predictor/Cast_19_output_0, %/model/sem_seg_head/predictor/Not_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.5/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Where_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_output_0, %onnx::MatMul_7615), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add"](%onnx::Add_7610, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.0/Add_1_output_0, %onnx::MatMul_7616), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_1"](%onnx::Add_7612, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_1_output_0, %onnx::MatMul_7617), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_2"](%onnx::Add_7614, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5648), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5650 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5650), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5652 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5652), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5660 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_5660), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5662 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5662), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5664 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5664), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_5671), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5673), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5675 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5675), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[204800, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_5693 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_5693), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5695 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_5695), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_5703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5703), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5705 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_5705), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_5707), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_1"](%/model/sem_seg_head/predictor/transformer_ffn_layers.5/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/Add_1_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.6/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_output_0, %onnx::MatMul_7640), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add"](%onnx::Add_7635, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_output_0, %onnx::MatMul_7641), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_1"](%onnx::Add_7637, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/norm/LayerNormalization_output_0, %onnx::MatMul_7642), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_2"](%onnx::Add_7639, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5772 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_output_0, %onnx::Unsqueeze_5772), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5774 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_output_0, %onnx::Unsqueeze_5774), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5776 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5776), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5784 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_3_output_0, %onnx::Unsqueeze_5784), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_output_0, %onnx::Unsqueeze_5786), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5788 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5788), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5795 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_4_output_0, %onnx::Unsqueeze_5795), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5797 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_output_0, %onnx::Unsqueeze_5797), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5799 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Cast_1_output_0, %onnx::Unsqueeze_5799), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_5812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Mul_2_output_0, %onnx::Unsqueeze_5812), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_2_output_0, %onnx::Unsqueeze_5814), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_5822 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_output_0, %onnx::Unsqueeze_5822), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5824 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_1_output_0, %onnx::Unsqueeze_5824), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_5826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gather_5_output_0, %onnx::Unsqueeze_5826), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.6/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.6/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.6/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.6.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.6.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.6/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/norm/LayerNormalization_output_0, %onnx::MatMul_7643), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.6.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.6/Relu_output_0, %onnx::MatMul_7644), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.6.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.6/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.6/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.6/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.6/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.6/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.6.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.6.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.6/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_7/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_7/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.6/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_13_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_13"](%/model/sem_seg_head/predictor/decoder_norm_7/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_7/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_7/MatMul"](%/model/sem_seg_head/predictor/Transpose_13_output_0, %onnx::MatMul_7645), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_7/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_7/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_7/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_7/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_7/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_7/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_7/MatMul"](%/model/sem_seg_head/predictor/mask_embed_7/Relu_output_0, %onnx::MatMul_7646), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_7/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_7/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_7/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_7/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_7/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_7/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_7/MatMul"](%/model/sem_seg_head/predictor/mask_embed_7/Relu_1_output_0, %onnx::MatMul_7647), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_7/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_7/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_7/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_7_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_7"](%/model/sem_seg_head/predictor/mask_embed/layers.2_7/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/sem_seg_head/predictor/Shape_43_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_43"](%/model/sem_seg_head/predictor/Einsum_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_172_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_172"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_173_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_173"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_174_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_174"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_34_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_34"](%/model/sem_seg_head/predictor/Shape_43_output_0, %/model/sem_seg_head/predictor/Constant_173_output_0, %/model/sem_seg_head/predictor/Constant_174_output_0, %/model/sem_seg_head/predictor/Constant_172_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_21"](%/model/sem_seg_head/predictor/Concat_18_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_40_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_40"](%/model/sem_seg_head/predictor/Slice_34_output_0, %/model/sem_seg_head/predictor/Cast_21_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_5862 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_5863 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_7_output_0 : Float(*, *, *, *, strides=[819200, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_7"](%/model/sem_seg_head/predictor/Einsum_7_output_0, %onnx::Resize_5862, %onnx::Resize_5863, %/model/sem_seg_head/predictor/Concat_40_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_7_output_0 : Float(*, *, *, *, strides=[819200, 8192, 128, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_7"](%/model/sem_seg_head/predictor/Resize_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_44_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_44"](%/model/sem_seg_head/predictor/Sigmoid_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_175_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_175"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_176_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_176"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_177_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_177"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_35_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_35"](%/model/sem_seg_head/predictor/Shape_44_output_0, %/model/sem_seg_head/predictor/Constant_176_output_0, %/model/sem_seg_head/predictor/Constant_177_output_0, %/model/sem_seg_head/predictor/Constant_175_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_178_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_178"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_41_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_41"](%/model/sem_seg_head/predictor/Slice_35_output_0, %/model/sem_seg_head/predictor/Constant_178_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_20_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_20"](%/model/sem_seg_head/predictor/Sigmoid_7_output_0, %/model/sem_seg_head/predictor/Concat_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_179_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_179"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_36_output_0 : Float(*, 1, *, *, strides=[819200, 819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_36"](%/model/sem_seg_head/predictor/Reshape_20_output_0, %/model/sem_seg_head/predictor/Constant_179_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_180_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_180"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_9"](%/model/sem_seg_head/predictor/Constant_180_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_9_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_9"](%/model/sem_seg_head/predictor/Unsqueeze_36_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_9_output_0 : Float(*, 8, *, *, strides=[6553600, 819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_9"](%/model/sem_seg_head/predictor/Expand_9_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_45_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_45"](%/model/sem_seg_head/predictor/Tile_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_181_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_181"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_182_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_182"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_183_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_183"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_36_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_36"](%/model/sem_seg_head/predictor/Shape_45_output_0, %/model/sem_seg_head/predictor/Constant_182_output_0, %/model/sem_seg_head/predictor/Constant_183_output_0, %/model/sem_seg_head/predictor/Constant_181_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_184_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_184"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_185_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_185"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_186_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_186"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_37_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_37"](%/model/sem_seg_head/predictor/Shape_45_output_0, %/model/sem_seg_head/predictor/Constant_185_output_0, %/model/sem_seg_head/predictor/Constant_186_output_0, %/model/sem_seg_head/predictor/Constant_184_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_187_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_187"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_42_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_42"](%/model/sem_seg_head/predictor/Slice_36_output_0, %/model/sem_seg_head/predictor/Constant_187_output_0, %/model/sem_seg_head/predictor/Slice_37_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_21_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_21"](%/model/sem_seg_head/predictor/Tile_9_output_0, %/model/sem_seg_head/predictor/Concat_42_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_188_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_188"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_7_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_7"](%/model/sem_seg_head/predictor/Reshape_21_output_0, %/model/sem_seg_head/predictor/Constant_188_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_22_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_22"](%/model/sem_seg_head/predictor/Less_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_23_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_23"](%/model/sem_seg_head/predictor/Cast_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_7_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_7"](%/model/sem_seg_head/predictor/Cast_23_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_46_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_46"](%/model/sem_seg_head/predictor/Cast_22_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_189_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_189"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_14_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_14"](%/model/sem_seg_head/predictor/Shape_46_output_0, %/model/sem_seg_head/predictor/Constant_189_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_7_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_7"](%/model/sem_seg_head/predictor/ReduceSum_7_output_0, %/model/sem_seg_head/predictor/Gather_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_190_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_190"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_37_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_37"](%/model/sem_seg_head/predictor/Equal_7_output_0, %/model/sem_seg_head/predictor/Constant_190_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_7_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_7"](%/model/sem_seg_head/predictor/Unsqueeze_37_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_7_output_0 : Bool(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_7"](%/model/sem_seg_head/predictor/Cast_22_output_0, %/model/sem_seg_head/predictor/Not_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.6/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Where_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_output_0, %onnx::MatMul_7669), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add"](%onnx::Add_7664, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.1/Add_1_output_0, %onnx::MatMul_7670), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_1"](%onnx::Add_7666, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_3_output_0, %onnx::MatMul_7671), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_2"](%onnx::Add_7668, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_5969 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_output_0, %onnx::Unsqueeze_5969), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5971), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5973 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5973), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_5981 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_5981), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5983), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5985), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_5992 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_5992), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5994 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_output_0, %onnx::Unsqueeze_5994), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_5996 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_5996), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[819200, 8192, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_6014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_6014), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6016 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_6016), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_6024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_output_0, %onnx::Unsqueeze_6024), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6026 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_6026), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6028 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_6028), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_1"](%/model/sem_seg_head/predictor/transformer_ffn_layers.6/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/Add_1_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.7/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_output_0, %onnx::MatMul_7694), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add"](%onnx::Add_7689, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_output_0, %onnx::MatMul_7695), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_1"](%onnx::Add_7691, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/norm/LayerNormalization_output_0, %onnx::MatMul_7696), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_2"](%onnx::Add_7693, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_6093 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_output_0, %onnx::Unsqueeze_6093), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6095 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_output_0, %onnx::Unsqueeze_6095), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6097 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_1_output_0, %onnx::Unsqueeze_6097), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_6105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_3_output_0, %onnx::Unsqueeze_6105), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6107 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_output_0, %onnx::Unsqueeze_6107), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_1_output_0, %onnx::Unsqueeze_6109), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_6116 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_4_output_0, %onnx::Unsqueeze_6116), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6118 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_output_0, %onnx::Unsqueeze_6118), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6120 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Cast_1_output_0, %onnx::Unsqueeze_6120), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_6133 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Mul_2_output_0, %onnx::Unsqueeze_6133), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6135 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_2_output_0, %onnx::Unsqueeze_6135), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_6143 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_output_0, %onnx::Unsqueeze_6143), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6145 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_1_output_0, %onnx::Unsqueeze_6145), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6147 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gather_5_output_0, %onnx::Unsqueeze_6147), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.7/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.7/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.7/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.7.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.7.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.7/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/norm/LayerNormalization_output_0, %onnx::MatMul_7697), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.7.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.7/Relu_output_0, %onnx::MatMul_7698), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.7.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.7/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.7/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.7/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.7/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.7/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.7.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.7.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.7/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_8/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_8/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.7/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_14_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_14"](%/model/sem_seg_head/predictor/decoder_norm_8/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_8/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_8/MatMul"](%/model/sem_seg_head/predictor/Transpose_14_output_0, %onnx::MatMul_7699), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_8/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_8/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_8/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_8/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_8/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_8/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_8/MatMul"](%/model/sem_seg_head/predictor/mask_embed_8/Relu_output_0, %onnx::MatMul_7700), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_8/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_8/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_8/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_8/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_8/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_8/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_8/MatMul"](%/model/sem_seg_head/predictor/mask_embed_8/Relu_1_output_0, %onnx::MatMul_7701), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_8/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_8/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_8/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_8_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_8"](%/model/sem_seg_head/predictor/mask_embed/layers.2_8/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/sem_seg_head/predictor/Shape_47_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_47"](%/model/sem_seg_head/predictor/Einsum_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_191_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_191"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_192_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_192"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Constant_193_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_193"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Slice_38_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_38"](%/model/sem_seg_head/predictor/Shape_47_output_0, %/model/sem_seg_head/predictor/Constant_192_output_0, %/model/sem_seg_head/predictor/Constant_193_output_0, %/model/sem_seg_head/predictor/Constant_191_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Cast_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_24"](%/model/sem_seg_head/predictor/Concat_24_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Concat_43_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_43"](%/model/sem_seg_head/predictor/Slice_38_output_0, %/model/sem_seg_head/predictor/Cast_24_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_6183 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_6184 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Resize_8_output_0 : Float(*, *, *, *, strides=[3276800, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/sem_seg_head/predictor/Resize_8"](%/model/sem_seg_head/predictor/Einsum_8_output_0, %onnx::Resize_6183, %onnx::Resize_6184, %/model/sem_seg_head/predictor/Concat_43_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/sem_seg_head/predictor/Sigmoid_8_output_0 : Float(*, *, *, *, strides=[3276800, 32768, 256, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/sem_seg_head/predictor/Sigmoid_8"](%/model/sem_seg_head/predictor/Resize_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_48_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_48"](%/model/sem_seg_head/predictor/Sigmoid_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_194_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_194"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_195_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_195"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_196_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_196"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_39_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_39"](%/model/sem_seg_head/predictor/Shape_48_output_0, %/model/sem_seg_head/predictor/Constant_195_output_0, %/model/sem_seg_head/predictor/Constant_196_output_0, %/model/sem_seg_head/predictor/Constant_194_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_197_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_197"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_44_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_44"](%/model/sem_seg_head/predictor/Slice_39_output_0, %/model/sem_seg_head/predictor/Constant_197_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_22_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_22"](%/model/sem_seg_head/predictor/Sigmoid_8_output_0, %/model/sem_seg_head/predictor/Concat_44_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_198_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/Constant_198"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Unsqueeze_38_output_0 : Float(*, 1, *, *, strides=[3276800, 3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_38"](%/model/sem_seg_head/predictor/Reshape_22_output_0, %/model/sem_seg_head/predictor/Constant_198_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_199_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_199"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/ConstantOfShape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/sem_seg_head/predictor/ConstantOfShape_10"](%/model/sem_seg_head/predictor/Constant_199_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Expand_10_output_0 : Float(*, 1, *, *, device=cpu) = onnx::Expand[onnx_name="/model/sem_seg_head/predictor/Expand_10"](%/model/sem_seg_head/predictor/Unsqueeze_38_output_0, %/model/sem_seg_head/predictor/ConstantOfShape_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Tile_10_output_0 : Float(*, 8, *, *, strides=[26214400, 3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Tile[onnx_name="/model/sem_seg_head/predictor/Tile_10"](%/model/sem_seg_head/predictor/Expand_10_output_0, %onnx::Tile_3595), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Shape_49_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_49"](%/model/sem_seg_head/predictor/Tile_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_200_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_200"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_201_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_201"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_202_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_202"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_40_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_40"](%/model/sem_seg_head/predictor/Shape_49_output_0, %/model/sem_seg_head/predictor/Constant_201_output_0, %/model/sem_seg_head/predictor/Constant_202_output_0, %/model/sem_seg_head/predictor/Constant_200_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_203_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/Constant_203"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_204_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_204"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_205_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/model/sem_seg_head/predictor/Constant_205"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Slice_41_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/sem_seg_head/predictor/Slice_41"](%/model/sem_seg_head/predictor/Shape_49_output_0, %/model/sem_seg_head/predictor/Constant_204_output_0, %/model/sem_seg_head/predictor/Constant_205_output_0, %/model/sem_seg_head/predictor/Constant_203_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_206_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_206"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Concat_45_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/Concat_45"](%/model/sem_seg_head/predictor/Slice_40_output_0, %/model/sem_seg_head/predictor/Constant_206_output_0, %/model/sem_seg_head/predictor/Slice_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Reshape_23_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/Reshape_23"](%/model/sem_seg_head/predictor/Tile_10_output_0, %/model/sem_seg_head/predictor/Concat_45_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Constant_207_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/sem_seg_head/predictor/Constant_207"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Less_8_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Less[onnx_name="/model/sem_seg_head/predictor/Less_8"](%/model/sem_seg_head/predictor/Reshape_23_output_0, %/model/sem_seg_head/predictor/Constant_207_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_25_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/Cast_25"](%/model/sem_seg_head/predictor/Less_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:454:0
  %/model/sem_seg_head/predictor/Cast_26_output_0 : Long(*, *, *, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/Cast_26"](%/model/sem_seg_head/predictor/Cast_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/ReduceSum_8_output_0 : Long(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::ReduceSum[keepdims=0, onnx_name="/model/sem_seg_head/predictor/ReduceSum_8"](%/model/sem_seg_head/predictor/Cast_26_output_0, %onnx::ReduceSum_1779), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:400:0
  %/model/sem_seg_head/predictor/Shape_50_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/Shape_50"](%/model/sem_seg_head/predictor/Cast_25_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_208_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/Constant_208"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Gather_15_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/Gather_15"](%/model/sem_seg_head/predictor/Shape_50_output_0, %/model/sem_seg_head/predictor/Constant_208_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Equal_8_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/sem_seg_head/predictor/Equal_8"](%/model/sem_seg_head/predictor/ReduceSum_8_output_0, %/model/sem_seg_head/predictor/Gather_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:401:0
  %/model/sem_seg_head/predictor/Constant_209_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/sem_seg_head/predictor/Constant_209"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Unsqueeze_39_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/Unsqueeze_39"](%/model/sem_seg_head/predictor/Equal_8_output_0, %/model/sem_seg_head/predictor/Constant_209_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/Not_8_output_0 : Bool(*, *, 1, strides=[100, 1, 1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/sem_seg_head/predictor/Not_8"](%/model/sem_seg_head/predictor/Unsqueeze_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/And_8_output_0 : Bool(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/sem_seg_head/predictor/And_8"](%/model/sem_seg_head/predictor/Cast_25_output_0, %/model/sem_seg_head/predictor/Not_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:405:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add"](%/model/sem_seg_head/predictor/transformer_ffn_layers.7/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:96:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape"](%/model/sem_seg_head/predictor/And_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/ConstantOfShape_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/ConstantOfShape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_output_0 : Bool(*, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast"](%/model/sem_seg_head/predictor/And_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Where_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Where"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/ConstantOfShape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5854:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Div"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_output_0, %onnx::MatMul_7723), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add"](%onnx::Add_7718, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.2/Add_1_output_0, %onnx::MatMul_7724), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_1"](%onnx::Add_7720, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_2"](%/model/sem_seg_head/predictor/Transpose_5_output_0, %onnx::MatMul_7725), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_2"](%onnx::Add_7722, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_6290 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_output_0, %onnx::Unsqueeze_6290), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6292 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_output_0, %onnx::Unsqueeze_6292), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6294 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_6294), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_6302 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_3_output_0, %onnx::Unsqueeze_6302), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6304 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_output_0, %onnx::Unsqueeze_6304), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6306 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_6306), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_7_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_6313 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_4_output_0, %onnx::Unsqueeze_6313), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6315 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_output_0, %onnx::Unsqueeze_6315), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6317 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Cast_2_output_0, %onnx::Unsqueeze_6317), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6238:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_3_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_9"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_2_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_10"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Where_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_3_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_2_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6237:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Softmax_output_0 : Float(*, *, *, strides=[3276800, 32768, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Add_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_6335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Mul_4_output_0, %onnx::Unsqueeze_6335), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_2_output_0, %onnx::Unsqueeze_6337), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_6"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_11"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Shape_6_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Constant_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_6345 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_output_0, %onnx::Unsqueeze_6345), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6347 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_1_output_0, %onnx::Unsqueeze_6347), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %onnx::Unsqueeze_6349 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gather_5_output_0, %onnx::Unsqueeze_6349), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_1"](%/model/sem_seg_head/predictor/transformer_ffn_layers.7/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/multihead_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:107:0
  %/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/Add_1_output_0, %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.weight, %model.sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.CrossAttentionLayer::transformer_cross_attention_layers.8/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/Tile_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:38:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_1"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_2"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6030:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_3"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Div"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Div_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6074:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_output_0, %onnx::MatMul_7748), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add"](%onnx::Add_7743, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_1_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_output_0, %onnx::MatMul_7749), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_1_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_1"](%onnx::Add_7745, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_2_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_2"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/norm/LayerNormalization_output_0, %onnx::MatMul_7750), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_2_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_2"](%onnx::Add_7747, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:5535:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_4"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %onnx::Unsqueeze_6414 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_output_0, %onnx::Unsqueeze_6414), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6416 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_output_0, %onnx::Unsqueeze_6416), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6418 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_1_output_0, %onnx::Unsqueeze_6418), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6163:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_5"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %onnx::Unsqueeze_6426 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_3_output_0, %onnx::Unsqueeze_6426), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6428 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_output_0, %onnx::Unsqueeze_6428), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6430 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_1_output_0, %onnx::Unsqueeze_6430), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6165:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_6_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_6"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_4_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %onnx::Unsqueeze_6437 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_6"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_4_output_0, %onnx::Unsqueeze_6437), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6439 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_7"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_output_0, %onnx::Unsqueeze_6439), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6441 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_8"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Cast_1_output_0, %onnx::Unsqueeze_6441), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_6_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_7_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Add_2_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6176:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_7"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_1_output_0 : Float(*, *, *, strides=[32, 256, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_1"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6230:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[32, 1, 256], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 2, 0], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_3_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_1_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6241:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Softmax_output_0 : Float(*, *, *, strides=[10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Softmax"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_4_output_0 : Float(*, *, *, strides=[3200, 32, 1], requires_grad=0, device=cuda:0) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Softmax_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6246:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[256, 32, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/MatMul_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_2"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %onnx::Unsqueeze_6454 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_9"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Mul_2_output_0, %onnx::Unsqueeze_6454), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6456 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_10"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_2_output_0, %onnx::Unsqueeze_6456), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_9_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_3_output_0 : Float(*, *, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_3"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Transpose_3_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6249:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gemm_output_0 : Float(*, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gemm"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_3_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6251:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gemm_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_8_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_8"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_5"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Shape_5_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Constant_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %onnx::Unsqueeze_6464 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_11"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_output_0, %onnx::Unsqueeze_6464), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6466 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_12"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_1_output_0, %onnx::Unsqueeze_6466), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %onnx::Unsqueeze_6468 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_13"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gather_5_output_0, %onnx::Unsqueeze_6468), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_11_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_12_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Unsqueeze_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_4_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_4"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Gemm_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:6252:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_1_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_1"](%/model/sem_seg_head/predictor/transformer_cross_attention_layers.8/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/self_attn/Reshape_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:47:0
  %/model/sem_seg_head/predictor/transformer_self_attention_layers.8/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_self_attention_layers.8/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/Add_1_output_0, %model.sem_seg_head.predictor.transformer_self_attention_layers.8.norm.weight, %model.sem_seg_head.predictor.transformer_self_attention_layers.8.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.SelfAttentionLayer::transformer_self_attention_layers.8/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear1/MatMul_output_0 : Float(*, *, 2048, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear1/MatMul"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/norm/LayerNormalization_output_0, %onnx::MatMul_7751), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear1/Add_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear1/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.8.linear1.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear1/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8/torch.nn.modules.linear.Linear::linear1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/Relu_output_0 : Float(*, *, 2048, strides=[2048, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/Relu"](%/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear1/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear2/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear2/MatMul"](%/model/sem_seg_head/predictor/transformer_ffn_layers.8/Relu_output_0, %onnx::MatMul_7752), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear2/Add_output_0 : Float(*, *, 256, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear2/Add"](%model.sem_seg_head.predictor.transformer_ffn_layers.8.linear2.bias, %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear2/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8/torch.nn.modules.linear.Linear::linear2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/Add_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/Add"](%/model/sem_seg_head/predictor/transformer_self_attention_layers.8/norm/LayerNormalization_output_0, %/model/sem_seg_head/predictor/transformer_ffn_layers.8/linear2/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8 # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:165:0
  %/model/sem_seg_head/predictor/transformer_ffn_layers.8/norm/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/transformer_ffn_layers.8/norm/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.8/Add_output_0, %model.sem_seg_head.predictor.transformer_ffn_layers.8.norm.weight, %model.sem_seg_head.predictor.transformer_ffn_layers.8.norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.FFNLayer::transformer_ffn_layers.8/torch.nn.modules.normalization.LayerNorm::norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/decoder_norm_9/LayerNormalization_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/model/sem_seg_head/predictor/decoder_norm_9/LayerNormalization"](%/model/sem_seg_head/predictor/transformer_ffn_layers.8/norm/LayerNormalization_output_0, %model.sem_seg_head.predictor.decoder_norm.weight, %model.sem_seg_head.predictor.decoder_norm.bias), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.normalization.LayerNorm::decoder_norm # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2900:0
  %/model/sem_seg_head/predictor/Transpose_15_output_0 : Float(*, *, *, strides=[256, 256, 1], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/model/sem_seg_head/predictor/Transpose_15"](%/model/sem_seg_head/predictor/decoder_norm_9/LayerNormalization_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/Diplomski/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py:444:0
  %/model/sem_seg_head/predictor/class_embed/MatMul_output_0 : Float(*, *, 20, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/class_embed/MatMul"](%/model/sem_seg_head/predictor/Transpose_15_output_0, %onnx::MatMul_7753), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.linear.Linear::class_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/class_embed/Add_output_0 : Float(*, *, 20, strides=[2000, 20, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/class_embed/Add"](%model.sem_seg_head.predictor.class_embed.bias, %/model/sem_seg_head/predictor/class_embed/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/torch.nn.modules.linear.Linear::class_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_9/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_9/MatMul"](%/model/sem_seg_head/predictor/Transpose_15_output_0, %onnx::MatMul_7754), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.0_9/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.0_9/Add"](%model.sem_seg_head.predictor.mask_embed.layers.0.bias, %/model/sem_seg_head/predictor/mask_embed/layers.0_9/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.0 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_9/Relu_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_9/Relu"](%/model/sem_seg_head/predictor/mask_embed/layers.0_9/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_9/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_9/MatMul"](%/model/sem_seg_head/predictor/mask_embed_9/Relu_output_0, %onnx::MatMul_7755), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.1_9/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.1_9/Add"](%model.sem_seg_head.predictor.mask_embed.layers.1.bias, %/model/sem_seg_head/predictor/mask_embed/layers.1_9/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.1 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed_9/Relu_1_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name="/model/sem_seg_head/predictor/mask_embed_9/Relu_1"](%/model/sem_seg_head/predictor/mask_embed/layers.1_9/Add_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:1704:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_9/MatMul_output_0 : Float(*, *, 256, device=cpu) = onnx::MatMul[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_9/MatMul"](%/model/sem_seg_head/predictor/mask_embed_9/Relu_1_output_0, %onnx::MatMul_7756), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/mask_embed/layers.2_9/Add_output_0 : Float(*, *, 256, strides=[25600, 256, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name="/model/sem_seg_head/predictor/mask_embed/layers.2_9/Add"](%model.sem_seg_head.predictor.mask_embed.layers.2.bias, %/model/sem_seg_head/predictor/mask_embed/layers.2_9/MatMul_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MLP::mask_embed/torch.nn.modules.linear.Linear::layers.2 # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/linear.py:125:0
  %/model/sem_seg_head/predictor/Einsum_9_output_0 : Float(*, *, *, *, strides=[13107200, 131072, 512, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="bqc,bchw->bqhw", onnx_name="/model/sem_seg_head/predictor/Einsum_9"](%/model/sem_seg_head/predictor/mask_embed/layers.2_9/Add_output_0, %/model/sem_seg_head/mask_features/Conv_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model/mask2former.modeling.meta_arch.mask_former_head.MaskFormerHead::sem_seg_head/mask2former.modeling.transformer_decoder.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder::predictor # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape_1"](%/model/Unsqueeze_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:226:0
  %/model/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_33"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:226:0
  %/model/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather_3"](%/model/Shape_1_output_0, %/model/Constant_33_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:226:0
  %/model/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape_2"](%/model/Unsqueeze_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:226:0
  %/model/Constant_34_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name="/model/Constant_34"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:226:0
  %/model/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather_4"](%/model/Shape_2_output_0, %/model/Constant_34_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:226:0
  %onnx::Unsqueeze_6506 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_5"](%/model/Gather_3_output_0, %onnx::Unsqueeze_6506), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %onnx::Unsqueeze_6508 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_6"](%/model/Gather_4_output_0, %onnx::Unsqueeze_6508), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat_3"](%/model/Unsqueeze_5_output_0, %/model/Unsqueeze_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape_3"](%/model/sem_seg_head/predictor/Einsum_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_35"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_36"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_37"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Slice_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/Slice_1"](%/model/Shape_3_output_0, %/model/Constant_36_output_0, %/model/Constant_37_output_0, %/model/Constant_35_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Cast_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/model/Cast_3"](%/model/Concat_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat_4"](%/model/Slice_1_output_0, %/model/Cast_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_6518 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_6519 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Resize_output_0 : Float(*, *, *, *, strides=[209715200, 2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/Resize"](%/model/sem_seg_head/predictor/Einsum_9_output_0, %onnx::Resize_6518, %onnx::Resize_6519, %/model/Concat_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_38"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Split_output_0 : Float(*, *, 20, device=cpu) = onnx::Split[axis=0, onnx_name="/model/Split"](%/model/sem_seg_head/predictor/class_embed/Add_output_0, %/model/Constant_38_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_39"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Squeeze_output_0 : Float(*, 20, strides=[20, 1], requires_grad=0, device=cuda:0) = onnx::Squeeze[onnx_name="/model/Squeeze"](%/model/Split_output_0, %/model/Constant_39_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_40"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Split_1_output_0 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name="/model/Split_1"](%/model/Resize_output_0, %/model/Constant_40_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Constant_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_41"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Squeeze_1_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Squeeze[onnx_name="/model/Squeeze_1"](%/model/Split_1_output_0, %/model/Constant_41_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:1119:0
  %/model/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_42"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_43"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1024}, onnx_name="/model/Constant_44"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_45"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Slice_2_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/Slice_2"](%/model/Squeeze_1_output_0, %/model/Constant_43_output_0, %/model/Constant_44_output_0, %/model/Constant_42_output_0, %/model/Constant_45_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_46"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_47"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_48_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2048}, onnx_name="/model/Constant_48"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_49_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_49"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Slice_3_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/Slice_3"](%/model/Slice_2_output_0, %/model/Constant_47_output_0, %/model/Constant_48_output_0, %/model/Constant_46_output_0, %/model/Constant_49_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_50_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/Constant_50"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/ConstantOfShape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/model/ConstantOfShape_1"](%/model/Constant_50_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_51_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_51"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/model/Mul_1"](%/model/ConstantOfShape_1_output_0, %/model/Constant_51_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_52_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1 -1 -1 [ CPULongType{4} ], onnx_name="/model/Constant_52"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/model/Equal_1"](%/model/Constant_52_output_0, %/model/Mul_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Constant_53_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1 -1 -1 [ CPULongType{4} ], onnx_name="/model/Constant_53"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/model/Where_1"](%/model/Equal_1_output_0, %/model/ConstantOfShape_1_output_0, %/model/Constant_53_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Expand_output_0 : Float(1, *, *, *, strides=[209715200, 2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Expand[onnx_name="/model/Expand"](%/model/Slice_3_output_0, %/model/Where_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:96:0
  %/model/Shape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape_4"](%/model/Expand_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_54_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_54"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_55_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_55"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_56_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_56"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Slice_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name="/model/Slice_4"](%/model/Shape_4_output_0, %/model/Constant_55_output_0, %/model/Constant_56_output_0, %/model/Constant_54_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Constant_57_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1024  2048 [ CPULongType{2} ], onnx_name="/model/Constant_57"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat_5"](%/model/Slice_4_output_0, %/model/Constant_57_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_6569 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %onnx::Resize_6570 : Tensor? = prim::Constant(), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Resize_1_output_0 : Float(*, *, *, *, strides=[209715200, 2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Resize[coordinate_transformation_mode="half_pixel", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor", onnx_name="/model/Resize_1"](%/model/Expand_output_0, %onnx::Resize_6569, %onnx::Resize_6570, %/model/Concat_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:4580:0
  %/model/Gather_5_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_5"](%/model/Resize_1_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/detectron2/modeling/postprocessing.py:97:0
  %/model/Cast_4_output_0 : Float(*, 20, strides=[20, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1, onnx_name="/model/Cast_4"](%/model/Squeeze_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:245:0
  %/model/Softmax_output_0 : Float(*, 20, strides=[20, 1], requires_grad=0, device=cuda:0) = onnx::Softmax[axis=-1, onnx_name="/model/Softmax"](%/model/Cast_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/functional.py:2140:0
  %/model/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_58"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:285:0
  %/model/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_59"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:285:0
  %/model/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_60"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:285:0
  %/model/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_61"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:285:0
  %/model/Slice_5_output_0 : Float(*, 19, strides=[20, 1], requires_grad=0, device=cuda:0) = onnx::Slice[onnx_name="/model/Slice_5"](%/model/Softmax_output_0, %/model/Constant_59_output_0, %/model/Constant_60_output_0, %/model/Constant_58_output_0, %/model/Constant_61_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:285:0
  %/model/Sigmoid_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name="/model/Sigmoid"](%/model/Gather_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:286:0
  %/model/Einsum_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Einsum[equation="qc,qhw->chw", onnx_name="/model/Einsum"](%/model/Slice_5_output_0, %/model/Sigmoid_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:402:0
  %/model/Constant_62_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/model/Constant_62"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:291:0
  %/model/ReduceMax_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ReduceMax[keepdims=0, onnx_name="/model/ReduceMax_1"](%/model/Softmax_output_0, %/model/Constant_62_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:291:0
  %/model/ArgMax_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ArgMax[axis=-1, keepdims=0, onnx_name="/model/ArgMax"](%/model/Softmax_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:291:0
  %/model/Constant_63_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={19}, onnx_name="/model/Constant_63"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:294:0
  %/model/Equal_2_output_0 : Bool(*, device=cpu) = onnx::Equal[onnx_name="/model/Equal_2"](%/model/ArgMax_output_0, %/model/Constant_63_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:294:0
  %/model/Not_1_output_0 : Bool(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Not[onnx_name="/model/Not_1"](%/model/Equal_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:294:0
  %/model/Constant_64_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.8}, onnx_name="/model/Constant_64"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:294:0
  %/model/Greater_output_0 : Bool(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Greater[onnx_name="/model/Greater"](%/model/ReduceMax_1_output_0, %/model/Constant_64_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:294:0
  %/model/And_1_output_0 : Bool(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_1"](%/model/Not_1_output_0, %/model/Greater_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:294:0
  %/model/NonZero_output_0 : Long(1, *, device=cpu) = onnx::NonZero[onnx_name="/model/NonZero"](%/model/And_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:295:0
  %/model/Transpose_1_output_0 : Long(*, 1, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/model/Transpose_1"](%/model/NonZero_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:295:0
  %/model/GatherND_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::GatherND[onnx_name="/model/GatherND"](%/model/ReduceMax_1_output_0, %/model/Transpose_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:295:0
  %/model/NonZero_1_output_0 : Long(1, *, device=cpu) = onnx::NonZero[onnx_name="/model/NonZero_1"](%/model/And_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:297:0
  %/model/Transpose_2_output_0 : Long(*, 1, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/model/Transpose_2"](%/model/NonZero_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:297:0
  %/model/GatherND_1_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::GatherND[onnx_name="/model/GatherND_1"](%/model/Sigmoid_output_0, %/model/Transpose_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:297:0
  %/model/Constant_65_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ], onnx_name="/model/Constant_65"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:301:0
  %/model/Reshape_2_output_0 : Float(*, *, *, strides=[1, 1, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[allowzero=0, onnx_name="/model/Reshape_2"](%/model/GatherND_output_0, %/model/Constant_65_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:301:0
  %/model/Mul_2_output_0 : Float(*, *, *, strides=[2097152, 2048, 1], requires_grad=0, device=cuda:0) = onnx::Mul[onnx_name="/model/Mul_2"](%/model/Reshape_2_output_0, %/model/GatherND_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:301:0
  %/model/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape_5"](%/model/GatherND_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:303:0
  %/model/Constant_66_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_66"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:303:0
  %/model/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather_6"](%/model/Shape_5_output_0, %/model/Constant_66_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:303:0
  %/model/Shape_6_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/model/Shape_6"](%/model/GatherND_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:303:0
  %/model/Constant_67_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_67"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:303:0
  %/model/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/model/Gather_7"](%/model/Shape_6_output_0, %/model/Constant_67_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:303:0
  %onnx::Unsqueeze_6610 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_7"](%/model/Gather_6_output_0, %onnx::Unsqueeze_6610), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %onnx::Unsqueeze_6612 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/model/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/model/Unsqueeze_8"](%/model/Gather_7_output_0, %onnx::Unsqueeze_6612), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Concat_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/model/Concat_6"](%/model/Unsqueeze_7_output_0, %/model/Unsqueeze_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:304:0
  %/model/ArgMax_1_output_0 : Long(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::ArgMax[axis=0, keepdims=0, select_last_index=0, onnx_name="/model/ArgMax_1"](%/model/Mul_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:314:0
  %/model/Constant_68_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/model/Constant_68"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_3_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_3"](%/model/ArgMax_1_output_0, %/model/Constant_68_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_8_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_8"](%/model/GatherND_1_output_0, %/model/Constant_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_69_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_69"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual"](%/model/Gather_8_output_0, %/model/Constant_69_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_2_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_2"](%/model/Equal_3_output_0, %/model/GreaterOrEqual_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/ConstantOfShape_2_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name="/model/ConstantOfShape_2"](%/model/Concat_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:304:0
  %/model/Constant_70_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_70"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_4_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_4"](%/model/ArgMax_1_output_0, %/model/Constant_70_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_9_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_9"](%/model/GatherND_1_output_0, %/model/Constant_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_71_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_71"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_1_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_1"](%/model/Gather_9_output_0, %/model/Constant_71_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_3_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_3"](%/model/Equal_4_output_0, %/model/GreaterOrEqual_1_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_5_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_5"](%/model/And_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_72_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/model/Constant_72"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_2_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_2"](%/model/Cast_5_output_0, %/model/Constant_72_output_0, %/model/ConstantOfShape_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_73_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/Constant_73"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_5_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_5"](%/model/ArgMax_1_output_0, %/model/Constant_73_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_10_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_10"](%/model/GatherND_1_output_0, %/model/sem_seg_head/pe_layer/Constant_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_74_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_74"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_2_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_2"](%/model/Gather_10_output_0, %/model/Constant_74_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_4_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_4"](%/model/Equal_5_output_0, %/model/GreaterOrEqual_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_6_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_6"](%/model/And_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_75_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/model/Constant_75"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_3_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_3"](%/model/Cast_6_output_0, %/model/Constant_75_output_0, %/model/Where_2_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_76_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/Constant_76"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_6_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_6"](%/model/ArgMax_1_output_0, %/model/Constant_76_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_11_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_11"](%/model/GatherND_1_output_0, %/model/sem_seg_head/pe_layer/Constant_31_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_77_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_77"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_3_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_3"](%/model/Gather_11_output_0, %/model/Constant_77_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_5_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_5"](%/model/Equal_6_output_0, %/model/GreaterOrEqual_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_7_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_7"](%/model/And_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_78_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/model/Constant_78"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_4_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_4"](%/model/Cast_7_output_0, %/model/Constant_78_output_0, %/model/Where_3_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_79_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/Constant_79"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_7_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_7"](%/model/ArgMax_1_output_0, %/model/Constant_79_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_12_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_12"](%/model/GatherND_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_80_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_80"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_4_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_4"](%/model/Gather_12_output_0, %/model/Constant_80_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_6_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_6"](%/model/Equal_7_output_0, %/model/GreaterOrEqual_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_8_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_8"](%/model/And_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_81_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/model/Constant_81"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_5_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_5"](%/model/Cast_8_output_0, %/model/Constant_81_output_0, %/model/Where_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_82_output_0 : Long(device=cpu) = onnx::Constant[value={9}, onnx_name="/model/Constant_82"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_83_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={9}, onnx_name="/model/Constant_83"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_8_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_8"](%/model/ArgMax_1_output_0, %/model/Constant_83_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_13_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_13"](%/model/GatherND_1_output_0, %/model/Constant_82_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_84"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_5_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_5"](%/model/Gather_13_output_0, %/model/Constant_84_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_7_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_7"](%/model/Equal_8_output_0, %/model/GreaterOrEqual_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_9_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_9"](%/model/And_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_85_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/model/Constant_85"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_6_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_6"](%/model/Cast_9_output_0, %/model/Constant_85_output_0, %/model/Where_5_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_86_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={11}, onnx_name="/model/Constant_86"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_9_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_9"](%/model/ArgMax_1_output_0, %/model/Constant_86_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_14_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_14"](%/model/GatherND_1_output_0, %/model/sem_seg_head/pe_layer/Constant_4_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_87_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_87"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_6_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_6"](%/model/Gather_14_output_0, %/model/Constant_87_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_8_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_8"](%/model/Equal_9_output_0, %/model/GreaterOrEqual_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_10_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_10"](%/model/And_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_88_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/model/Constant_88"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_7_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_7"](%/model/Cast_10_output_0, %/model/Constant_88_output_0, %/model/Where_6_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_89_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/Constant_89"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_10_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_10"](%/model/ArgMax_1_output_0, %/model/Constant_89_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_15_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_15"](%/model/GatherND_1_output_0, %/model/sem_seg_head/transformer/encoder/layers.0/self_attn/Constant_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_90_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_90"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_7_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_7"](%/model/Gather_15_output_0, %/model/Constant_90_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_9_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_9"](%/model/Equal_10_output_0, %/model/GreaterOrEqual_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_11_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_11"](%/model/And_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_91_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={7}, onnx_name="/model/Constant_91"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_8_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_8"](%/model/Cast_11_output_0, %/model/Constant_91_output_0, %/model/Where_7_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_92_output_0 : Long(device=cpu) = onnx::Constant[value={14}, onnx_name="/model/Constant_92"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_93_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name="/model/Constant_93"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_11_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_11"](%/model/ArgMax_1_output_0, %/model/Constant_93_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_16_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_16"](%/model/GatherND_1_output_0, %/model/Constant_92_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_94_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_94"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_8_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_8"](%/model/Gather_16_output_0, %/model/Constant_94_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_10_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_10"](%/model/Equal_11_output_0, %/model/GreaterOrEqual_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_12_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_12"](%/model/And_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_95_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/model/Constant_95"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_9_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_9"](%/model/Cast_12_output_0, %/model/Constant_95_output_0, %/model/Where_8_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_96_output_0 : Long(device=cpu) = onnx::Constant[value={15}, onnx_name="/model/Constant_96"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_97_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={15}, onnx_name="/model/Constant_97"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_12_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_12"](%/model/ArgMax_1_output_0, %/model/Constant_97_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_17_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_17"](%/model/GatherND_1_output_0, %/model/Constant_96_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_98_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_98"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_9_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_9"](%/model/Gather_17_output_0, %/model/Constant_98_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_11_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_11"](%/model/Equal_12_output_0, %/model/GreaterOrEqual_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_13_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_13"](%/model/And_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_99_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={9}, onnx_name="/model/Constant_99"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_10_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_10"](%/model/Cast_13_output_0, %/model/Constant_99_output_0, %/model/Where_9_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_100_output_0 : Long(device=cpu) = onnx::Constant[value={17}, onnx_name="/model/Constant_100"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_101_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={17}, onnx_name="/model/Constant_101"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_13_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_13"](%/model/ArgMax_1_output_0, %/model/Constant_101_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_18_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_18"](%/model/GatherND_1_output_0, %/model/Constant_100_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_102_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_102"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_10_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_10"](%/model/Gather_18_output_0, %/model/Constant_102_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_12_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_12"](%/model/Equal_13_output_0, %/model/GreaterOrEqual_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_14_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_14"](%/model/And_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_103_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/model/Constant_103"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_11_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_11"](%/model/Cast_14_output_0, %/model/Constant_103_output_0, %/model/Where_10_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_104_output_0 : Long(device=cpu) = onnx::Constant[value={22}, onnx_name="/model/Constant_104"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_105_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={22}, onnx_name="/model/Constant_105"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_14_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_14"](%/model/ArgMax_1_output_0, %/model/Constant_105_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_19_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_19"](%/model/GatherND_1_output_0, %/model/Constant_104_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_106_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_106"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_11_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_11"](%/model/Gather_19_output_0, %/model/Constant_106_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_13_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_13"](%/model/Equal_14_output_0, %/model/GreaterOrEqual_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_15_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_15"](%/model/And_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_107_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={11}, onnx_name="/model/Constant_107"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_12_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_12"](%/model/Cast_15_output_0, %/model/Constant_107_output_0, %/model/Where_11_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_108_output_0 : Long(device=cpu) = onnx::Constant[value={23}, onnx_name="/model/Constant_108"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_109_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={23}, onnx_name="/model/Constant_109"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_15_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_15"](%/model/ArgMax_1_output_0, %/model/Constant_109_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_20_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_20"](%/model/GatherND_1_output_0, %/model/Constant_108_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_110_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_110"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_12_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_12"](%/model/Gather_20_output_0, %/model/Constant_110_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_14_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_14"](%/model/Equal_15_output_0, %/model/GreaterOrEqual_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_16_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_16"](%/model/And_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_111_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={12}, onnx_name="/model/Constant_111"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_13_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_13"](%/model/Cast_16_output_0, %/model/Constant_111_output_0, %/model/Where_12_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_112_output_0 : Long(device=cpu) = onnx::Constant[value={26}, onnx_name="/model/Constant_112"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model
  %/model/Constant_113_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={26}, onnx_name="/model/Constant_113"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Equal_16_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Equal[onnx_name="/model/Equal_16"](%/model/ArgMax_1_output_0, %/model/Constant_113_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Gather_21_output_0 : Float(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name="/model/Gather_21"](%/model/GatherND_1_output_0, %/model/Constant_112_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Constant_114_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/model/Constant_114"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/GreaterOrEqual_13_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::GreaterOrEqual[onnx_name="/model/GreaterOrEqual_13"](%/model/Gather_21_output_0, %/model/Constant_114_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/And_15_output_0 : Bool(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::And[onnx_name="/model/And_15"](%/model/Equal_16_output_0, %/model/GreaterOrEqual_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:321:0
  %/model/Cast_17_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_17"](%/model/And_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_115_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={13}, onnx_name="/model/Constant_115"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Where_14_output_0 : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_14"](%/model/Cast_17_output_0, %/model/Constant_115_output_0, %/model/Where_13_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Cast_18_output_0 : Bool(*, *, device=cpu) = onnx::Cast[to=9, onnx_name="/model/Cast_18"](%/model/And_15_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %/model/Constant_116_output_0 : Int(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name="/model/Constant_116"](), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %panoptic_seg : Int(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::Where[onnx_name="/model/Where_15"](%/model/Cast_18_output_0, %/model/Constant_116_output_0, %/model/Where_14_output_0), scope: __main__.Mask2FormerONNXWrapper::/mask2former.maskformer_model.MaskFormer::model # /home/vmoskov/Diplomski/Mask2Former/mask2former/maskformer_model.py:336:0
  %sem_seg : Long(*, *, strides=[2048, 1], requires_grad=0, device=cuda:0) = onnx::ArgMax[axis=0, keepdims=0, select_last_index=0, onnx_name="/ArgMax"](%/model/Einsum_output_0), scope: __main__.Mask2FormerONNXWrapper:: # /home/vmoskov/Diplomski/Mask2Former/train_net.py:444:0
  return (%sem_seg, %panoptic_seg)

Number of devices: 3
Number of current device: 0
Using device: NVIDIA RTX A6000
Length of colormap: 256
Model successfully exported to model.onnx
